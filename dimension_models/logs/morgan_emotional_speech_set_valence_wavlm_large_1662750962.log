Using learning rate: 0.001
Using sequence aggregation method: mean
Using optimizer: adam
Using cpu device
DimensionPredictor(
  (softmax): Softmax(dim=0)
  (first_projection): Linear(in_features=1024, out_features=256, bias=True)
  (second_projection): Linear(in_features=256, out_features=1, bias=True)
)
loss: 1.042180  [    0/ 1575]
loss: 32.545100  [  160/ 1575]
loss: 19.919145  [  320/ 1575]
loss: 10.839001  [  480/ 1575]
loss: 1.919497  [  640/ 1575]
loss: 0.196375  [  800/ 1575]
loss: 1.845610  [  960/ 1575]
loss: 1.492571  [ 1120/ 1575]
loss: 0.428485  [ 1280/ 1575]
loss: 0.077865  [ 1440/ 1575]
Test Error: 
MSE: 1491.772900
RMSE: 38.623476
MAE: 5.636426
R^2: -3.663782987222418
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_wavlm_large_1662750962_BEST.pt
loss: 0.120675  [    0/ 1575]
loss: 0.216976  [  160/ 1575]
loss: 0.227410  [  320/ 1575]
loss: 0.058390  [  480/ 1575]
loss: 0.047584  [  640/ 1575]
loss: 0.041440  [  800/ 1575]
loss: 0.036595  [  960/ 1575]
loss: 0.021401  [ 1120/ 1575]
loss: 0.043223  [ 1280/ 1575]
loss: 0.052336  [ 1440/ 1575]
Test Error: 
MSE: 339.475530
RMSE: 18.424862
MAE: 3.813820
R^2: -0.06131449434120628
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_wavlm_large_1662750962_BEST.pt
loss: 0.018916  [    0/ 1575]
loss: 0.020604  [  160/ 1575]
loss: 0.034188  [  320/ 1575]
loss: 0.011972  [  480/ 1575]
loss: 0.020285  [  640/ 1575]
loss: 0.012120  [  800/ 1575]
loss: 0.014170  [  960/ 1575]
loss: 0.009028  [ 1120/ 1575]
loss: 0.020376  [ 1280/ 1575]
loss: 0.014379  [ 1440/ 1575]
