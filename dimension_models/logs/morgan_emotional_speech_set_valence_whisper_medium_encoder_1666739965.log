Using learning rate: 1e-05
Using sequence aggregation method: mean
Using optimizer: adam
Using cuda device
DimensionPredictor(
  (softmax): Softmax(dim=0)
  (first_projection): Linear(in_features=1024, out_features=256, bias=True)
  (second_projection): Linear(in_features=256, out_features=1, bias=True)
)
loss: 0.081999  [    0/ 1575]
loss: 0.038029  [  160/ 1575]
loss: 0.038198  [  320/ 1575]
loss: 0.036692  [  480/ 1575]
loss: 0.031846  [  640/ 1575]
loss: 0.033624  [  800/ 1575]
loss: 0.026267  [  960/ 1575]
loss: 0.032283  [ 1120/ 1575]
loss: 0.029355  [ 1280/ 1575]
loss: 0.032733  [ 1440/ 1575]
Test Error: 
MSE: 328.973600
RMSE: 18.137629
MAE: 4.038049
R^2: -0.028481936850677236
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.026614  [    0/ 1575]
loss: 0.026222  [  160/ 1575]
loss: 0.040479  [  320/ 1575]
loss: 0.039237  [  480/ 1575]
loss: 0.021893  [  640/ 1575]
loss: 0.031631  [  800/ 1575]
loss: 0.028225  [  960/ 1575]
loss: 0.022964  [ 1120/ 1575]
loss: 0.028435  [ 1280/ 1575]
loss: 0.046760  [ 1440/ 1575]
Test Error: 
MSE: 314.519481
RMSE: 17.734697
MAE: 4.010469
R^2: 0.016706494115366177
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.032335  [    0/ 1575]
loss: 0.027169  [  160/ 1575]
loss: 0.033234  [  320/ 1575]
loss: 0.028654  [  480/ 1575]
loss: 0.032252  [  640/ 1575]
loss: 0.024861  [  800/ 1575]
loss: 0.023478  [  960/ 1575]
loss: 0.026272  [ 1120/ 1575]
loss: 0.031595  [ 1280/ 1575]
loss: 0.028071  [ 1440/ 1575]
Test Error: 
MSE: 304.637962
RMSE: 17.453881
MAE: 3.977138
R^2: 0.047599439308877445
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.023703  [    0/ 1575]
loss: 0.026914  [  160/ 1575]
loss: 0.027700  [  320/ 1575]
loss: 0.033723  [  480/ 1575]
loss: 0.031511  [  640/ 1575]
loss: 0.026198  [  800/ 1575]
loss: 0.027473  [  960/ 1575]
loss: 0.024677  [ 1120/ 1575]
loss: 0.033469  [ 1280/ 1575]
loss: 0.031880  [ 1440/ 1575]
Test Error: 
MSE: 292.279358
RMSE: 17.096180
MAE: 3.919081
R^2: 0.08623658583675675
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.038779  [    0/ 1575]
loss: 0.029875  [  160/ 1575]
loss: 0.023188  [  320/ 1575]
loss: 0.029486  [  480/ 1575]
loss: 0.026907  [  640/ 1575]
loss: 0.028880  [  800/ 1575]
loss: 0.033905  [  960/ 1575]
loss: 0.029927  [ 1120/ 1575]
loss: 0.030834  [ 1280/ 1575]
loss: 0.025375  [ 1440/ 1575]
Test Error: 
MSE: 276.983792
RMSE: 16.642830
MAE: 3.883513
R^2: 0.134055662823652
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.026822  [    0/ 1575]
loss: 0.034057  [  160/ 1575]
loss: 0.026461  [  320/ 1575]
loss: 0.026746  [  480/ 1575]
loss: 0.027408  [  640/ 1575]
loss: 0.030004  [  800/ 1575]
loss: 0.032875  [  960/ 1575]
loss: 0.021263  [ 1120/ 1575]
loss: 0.023799  [ 1280/ 1575]
loss: 0.024887  [ 1440/ 1575]
Test Error: 
MSE: 262.918156
RMSE: 16.214751
MAE: 3.833137
R^2: 0.17802956387601776
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.028291  [    0/ 1575]
loss: 0.014778  [  160/ 1575]
loss: 0.026205  [  320/ 1575]
loss: 0.026513  [  480/ 1575]
loss: 0.026051  [  640/ 1575]
loss: 0.026823  [  800/ 1575]
loss: 0.027474  [  960/ 1575]
loss: 0.020221  [ 1120/ 1575]
loss: 0.021622  [ 1280/ 1575]
loss: 0.028569  [ 1440/ 1575]
Test Error: 
MSE: 259.130926
RMSE: 16.097544
MAE: 3.793303
R^2: 0.18986971410194986
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.024402  [    0/ 1575]
loss: 0.026279  [  160/ 1575]
loss: 0.026354  [  320/ 1575]
loss: 0.028290  [  480/ 1575]
loss: 0.025855  [  640/ 1575]
loss: 0.026826  [  800/ 1575]
loss: 0.020513  [  960/ 1575]
loss: 0.027504  [ 1120/ 1575]
loss: 0.026813  [ 1280/ 1575]
loss: 0.016192  [ 1440/ 1575]
Test Error: 
MSE: 241.918799
RMSE: 15.553739
MAE: 3.746111
R^2: 0.24368060366394761
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.025948  [    0/ 1575]
loss: 0.025143  [  160/ 1575]
loss: 0.023890  [  320/ 1575]
loss: 0.024228  [  480/ 1575]
loss: 0.025521  [  640/ 1575]
loss: 0.024998  [  800/ 1575]
loss: 0.026958  [  960/ 1575]
loss: 0.023891  [ 1120/ 1575]
loss: 0.020646  [ 1280/ 1575]
loss: 0.025178  [ 1440/ 1575]
Test Error: 
MSE: 232.769976
RMSE: 15.256801
MAE: 3.705857
R^2: 0.27228289658914284
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.022384  [    0/ 1575]
loss: 0.017317  [  160/ 1575]
loss: 0.018253  [  320/ 1575]
loss: 0.025264  [  480/ 1575]
loss: 0.025635  [  640/ 1575]
loss: 0.020554  [  800/ 1575]
loss: 0.019589  [  960/ 1575]
loss: 0.020418  [ 1120/ 1575]
loss: 0.022169  [ 1280/ 1575]
loss: 0.026927  [ 1440/ 1575]
Test Error: 
MSE: 231.631809
RMSE: 15.219455
MAE: 3.692068
R^2: 0.2758411891418143
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.026290  [    0/ 1575]
loss: 0.017280  [  160/ 1575]
loss: 0.022353  [  320/ 1575]
loss: 0.025311  [  480/ 1575]
loss: 0.021726  [  640/ 1575]
loss: 0.021115  [  800/ 1575]
loss: 0.019565  [  960/ 1575]
loss: 0.023493  [ 1120/ 1575]
loss: 0.021068  [ 1280/ 1575]
loss: 0.019647  [ 1440/ 1575]
Test Error: 
MSE: 216.571287
RMSE: 14.716361
MAE: 3.633812
R^2: 0.32292543726138456
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.022630  [    0/ 1575]
loss: 0.011979  [  160/ 1575]
loss: 0.029086  [  320/ 1575]
loss: 0.019523  [  480/ 1575]
loss: 0.021974  [  640/ 1575]
loss: 0.021671  [  800/ 1575]
loss: 0.020489  [  960/ 1575]
loss: 0.019265  [ 1120/ 1575]
loss: 0.018690  [ 1280/ 1575]
loss: 0.021463  [ 1440/ 1575]
Test Error: 
MSE: 207.045273
RMSE: 14.389068
MAE: 3.590139
R^2: 0.3527069562058508
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.016864  [    0/ 1575]
loss: 0.020314  [  160/ 1575]
loss: 0.021786  [  320/ 1575]
loss: 0.022396  [  480/ 1575]
loss: 0.015473  [  640/ 1575]
loss: 0.019935  [  800/ 1575]
loss: 0.020966  [  960/ 1575]
loss: 0.020274  [ 1120/ 1575]
loss: 0.021382  [ 1280/ 1575]
loss: 0.022013  [ 1440/ 1575]
Test Error: 
MSE: 205.842009
RMSE: 14.347195
MAE: 3.571966
R^2: 0.35646876214879286
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.021121  [    0/ 1575]
loss: 0.019708  [  160/ 1575]
loss: 0.018102  [  320/ 1575]
loss: 0.014813  [  480/ 1575]
loss: 0.020306  [  640/ 1575]
loss: 0.023260  [  800/ 1575]
loss: 0.017987  [  960/ 1575]
loss: 0.017828  [ 1120/ 1575]
loss: 0.019768  [ 1280/ 1575]
loss: 0.019985  [ 1440/ 1575]
Test Error: 
MSE: 191.779642
RMSE: 13.848453
MAE: 3.513532
R^2: 0.40043244453044025
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.013997  [    0/ 1575]
loss: 0.020475  [  160/ 1575]
loss: 0.014734  [  320/ 1575]
loss: 0.021410  [  480/ 1575]
loss: 0.017517  [  640/ 1575]
loss: 0.016730  [  800/ 1575]
loss: 0.019918  [  960/ 1575]
loss: 0.015340  [ 1120/ 1575]
loss: 0.019815  [ 1280/ 1575]
loss: 0.017458  [ 1440/ 1575]
Test Error: 
MSE: 189.571160
RMSE: 13.768484
MAE: 3.486069
R^2: 0.4073369014873035
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.016483  [    0/ 1575]
loss: 0.018091  [  160/ 1575]
loss: 0.019020  [  320/ 1575]
loss: 0.019516  [  480/ 1575]
loss: 0.019512  [  640/ 1575]
loss: 0.017175  [  800/ 1575]
loss: 0.018109  [  960/ 1575]
loss: 0.020961  [ 1120/ 1575]
loss: 0.016148  [ 1280/ 1575]
loss: 0.021153  [ 1440/ 1575]
Test Error: 
MSE: 178.488262
RMSE: 13.359950
MAE: 3.442597
R^2: 0.44198576017474245
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.016325  [    0/ 1575]
loss: 0.021100  [  160/ 1575]
loss: 0.021035  [  320/ 1575]
loss: 0.016711  [  480/ 1575]
loss: 0.017457  [  640/ 1575]
loss: 0.013880  [  800/ 1575]
loss: 0.012756  [  960/ 1575]
loss: 0.017204  [ 1120/ 1575]
loss: 0.016922  [ 1280/ 1575]
loss: 0.016582  [ 1440/ 1575]
Test Error: 
MSE: 176.152144
RMSE: 13.272232
MAE: 3.416525
R^2: 0.44928925131900876
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.019636  [    0/ 1575]
loss: 0.014802  [  160/ 1575]
loss: 0.015122  [  320/ 1575]
loss: 0.015051  [  480/ 1575]
loss: 0.012658  [  640/ 1575]
loss: 0.018725  [  800/ 1575]
loss: 0.014855  [  960/ 1575]
loss: 0.016054  [ 1120/ 1575]
loss: 0.017391  [ 1280/ 1575]
loss: 0.017825  [ 1440/ 1575]
Test Error: 
MSE: 166.892846
RMSE: 12.918701
MAE: 3.375773
R^2: 0.47823692471539414
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.020828  [    0/ 1575]
loss: 0.020624  [  160/ 1575]
loss: 0.018879  [  320/ 1575]
loss: 0.013612  [  480/ 1575]
loss: 0.022908  [  640/ 1575]
loss: 0.017008  [  800/ 1575]
loss: 0.018250  [  960/ 1575]
loss: 0.019872  [ 1120/ 1575]
loss: 0.017784  [ 1280/ 1575]
loss: 0.012807  [ 1440/ 1575]
Test Error: 
MSE: 164.398255
RMSE: 12.821788
MAE: 3.348844
R^2: 0.486035853762101
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.020644  [    0/ 1575]
loss: 0.016364  [  160/ 1575]
loss: 0.014365  [  320/ 1575]
loss: 0.012661  [  480/ 1575]
loss: 0.015892  [  640/ 1575]
loss: 0.013845  [  800/ 1575]
loss: 0.017901  [  960/ 1575]
loss: 0.014201  [ 1120/ 1575]
loss: 0.011686  [ 1280/ 1575]
loss: 0.019007  [ 1440/ 1575]
Test Error: 
MSE: 157.986539
RMSE: 12.569270
MAE: 3.313754
R^2: 0.5060810297784895
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.013722  [    0/ 1575]
loss: 0.016142  [  160/ 1575]
loss: 0.017407  [  320/ 1575]
loss: 0.024160  [  480/ 1575]
loss: 0.016893  [  640/ 1575]
loss: 0.014211  [  800/ 1575]
loss: 0.018614  [  960/ 1575]
loss: 0.015560  [ 1120/ 1575]
loss: 0.016855  [ 1280/ 1575]
loss: 0.019193  [ 1440/ 1575]
Test Error: 
MSE: 159.975703
RMSE: 12.648150
MAE: 3.302180
R^2: 0.49986223551904607
loss: 0.018069  [    0/ 1575]
loss: 0.014947  [  160/ 1575]
loss: 0.018452  [  320/ 1575]
loss: 0.013532  [  480/ 1575]
loss: 0.011941  [  640/ 1575]
loss: 0.015122  [  800/ 1575]
loss: 0.011119  [  960/ 1575]
loss: 0.015984  [ 1120/ 1575]
loss: 0.018048  [ 1280/ 1575]
loss: 0.012862  [ 1440/ 1575]
Test Error: 
MSE: 149.334270
RMSE: 12.220240
MAE: 3.256362
R^2: 0.5331309275745735
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.016917  [    0/ 1575]
loss: 0.019743  [  160/ 1575]
loss: 0.016026  [  320/ 1575]
loss: 0.010049  [  480/ 1575]
loss: 0.015420  [  640/ 1575]
loss: 0.011985  [  800/ 1575]
loss: 0.010672  [  960/ 1575]
loss: 0.016531  [ 1120/ 1575]
loss: 0.014314  [ 1280/ 1575]
loss: 0.014834  [ 1440/ 1575]
Test Error: 
MSE: 147.261941
RMSE: 12.135153
MAE: 3.234056
R^2: 0.5396097239472919
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.014636  [    0/ 1575]
loss: 0.010862  [  160/ 1575]
loss: 0.017306  [  320/ 1575]
loss: 0.012807  [  480/ 1575]
loss: 0.016614  [  640/ 1575]
loss: 0.010495  [  800/ 1575]
loss: 0.014059  [  960/ 1575]
loss: 0.011607  [ 1120/ 1575]
loss: 0.015256  [ 1280/ 1575]
loss: 0.011045  [ 1440/ 1575]
Test Error: 
MSE: 139.112489
RMSE: 11.794596
MAE: 3.190731
R^2: 0.5650876475996469
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.011665  [    0/ 1575]
loss: 0.015438  [  160/ 1575]
loss: 0.018410  [  320/ 1575]
loss: 0.010415  [  480/ 1575]
loss: 0.014260  [  640/ 1575]
loss: 0.016676  [  800/ 1575]
loss: 0.008665  [  960/ 1575]
loss: 0.016858  [ 1120/ 1575]
loss: 0.015388  [ 1280/ 1575]
loss: 0.010060  [ 1440/ 1575]
Test Error: 
MSE: 143.632804
RMSE: 11.984690
MAE: 3.199359
R^2: 0.5509556263342039
loss: 0.013285  [    0/ 1575]
loss: 0.010810  [  160/ 1575]
loss: 0.016626  [  320/ 1575]
loss: 0.012578  [  480/ 1575]
loss: 0.013170  [  640/ 1575]
loss: 0.013985  [  800/ 1575]
loss: 0.010997  [  960/ 1575]
loss: 0.018757  [ 1120/ 1575]
loss: 0.012076  [ 1280/ 1575]
loss: 0.015944  [ 1440/ 1575]
Test Error: 
MSE: 130.713972
RMSE: 11.433021
MAE: 3.134218
R^2: 0.5913442326982616
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.010791  [    0/ 1575]
loss: 0.014217  [  160/ 1575]
loss: 0.012662  [  320/ 1575]
loss: 0.013524  [  480/ 1575]
loss: 0.012619  [  640/ 1575]
loss: 0.010004  [  800/ 1575]
loss: 0.009868  [  960/ 1575]
loss: 0.011267  [ 1120/ 1575]
loss: 0.014522  [ 1280/ 1575]
loss: 0.013917  [ 1440/ 1575]
Test Error: 
MSE: 137.146679
RMSE: 11.710964
MAE: 3.133966
R^2: 0.5712334317412717
loss: 0.019269  [    0/ 1575]
loss: 0.012081  [  160/ 1575]
loss: 0.010220  [  320/ 1575]
loss: 0.009360  [  480/ 1575]
loss: 0.012646  [  640/ 1575]
loss: 0.009677  [  800/ 1575]
loss: 0.010093  [  960/ 1575]
loss: 0.014014  [ 1120/ 1575]
loss: 0.016726  [ 1280/ 1575]
loss: 0.010502  [ 1440/ 1575]
Test Error: 
MSE: 123.994049
RMSE: 11.135262
MAE: 3.085659
R^2: 0.6123529683554484
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.014444  [    0/ 1575]
loss: 0.009541  [  160/ 1575]
loss: 0.012726  [  320/ 1575]
loss: 0.013612  [  480/ 1575]
loss: 0.010752  [  640/ 1575]
loss: 0.010167  [  800/ 1575]
loss: 0.012685  [  960/ 1575]
loss: 0.010949  [ 1120/ 1575]
loss: 0.011737  [ 1280/ 1575]
loss: 0.012835  [ 1440/ 1575]
Test Error: 
MSE: 120.352930
RMSE: 10.970548
MAE: 3.059780
R^2: 0.623736329136911
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.008171  [    0/ 1575]
loss: 0.021318  [  160/ 1575]
loss: 0.010787  [  320/ 1575]
loss: 0.013107  [  480/ 1575]
loss: 0.009031  [  640/ 1575]
loss: 0.011182  [  800/ 1575]
loss: 0.014193  [  960/ 1575]
loss: 0.009509  [ 1120/ 1575]
loss: 0.009273  [ 1280/ 1575]
loss: 0.010543  [ 1440/ 1575]
Test Error: 
MSE: 116.660894
RMSE: 10.800967
MAE: 3.031439
R^2: 0.6352788735996138
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.010772  [    0/ 1575]
loss: 0.016040  [  160/ 1575]
loss: 0.009415  [  320/ 1575]
loss: 0.013686  [  480/ 1575]
loss: 0.011771  [  640/ 1575]
loss: 0.011783  [  800/ 1575]
loss: 0.008344  [  960/ 1575]
loss: 0.012330  [ 1120/ 1575]
loss: 0.011116  [ 1280/ 1575]
loss: 0.011177  [ 1440/ 1575]
Test Error: 
MSE: 113.499646
RMSE: 10.653621
MAE: 3.006406
R^2: 0.6451619958179561
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.008809  [    0/ 1575]
loss: 0.013745  [  160/ 1575]
loss: 0.012055  [  320/ 1575]
loss: 0.007365  [  480/ 1575]
loss: 0.011918  [  640/ 1575]
loss: 0.005778  [  800/ 1575]
loss: 0.013380  [  960/ 1575]
loss: 0.007493  [ 1120/ 1575]
loss: 0.009741  [ 1280/ 1575]
loss: 0.012348  [ 1440/ 1575]
Test Error: 
MSE: 110.540988
RMSE: 10.513847
MAE: 2.982254
R^2: 0.6544117539214871
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.012059  [    0/ 1575]
loss: 0.010120  [  160/ 1575]
loss: 0.007367  [  320/ 1575]
loss: 0.012358  [  480/ 1575]
loss: 0.007888  [  640/ 1575]
loss: 0.009617  [  800/ 1575]
loss: 0.009221  [  960/ 1575]
loss: 0.011949  [ 1120/ 1575]
loss: 0.007181  [ 1280/ 1575]
loss: 0.007749  [ 1440/ 1575]
Test Error: 
MSE: 108.797912
RMSE: 10.430624
MAE: 2.972017
R^2: 0.659861195393047
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.009641  [    0/ 1575]
loss: 0.015066  [  160/ 1575]
loss: 0.007160  [  320/ 1575]
loss: 0.011968  [  480/ 1575]
loss: 0.008411  [  640/ 1575]
loss: 0.012055  [  800/ 1575]
loss: 0.009890  [  960/ 1575]
loss: 0.008960  [ 1120/ 1575]
loss: 0.011930  [ 1280/ 1575]
loss: 0.011205  [ 1440/ 1575]
Test Error: 
MSE: 119.380876
RMSE: 10.926156
MAE: 2.986501
R^2: 0.626775296621312
loss: 0.011675  [    0/ 1575]
loss: 0.010977  [  160/ 1575]
loss: 0.011330  [  320/ 1575]
loss: 0.009585  [  480/ 1575]
loss: 0.006767  [  640/ 1575]
loss: 0.010843  [  800/ 1575]
loss: 0.008165  [  960/ 1575]
loss: 0.010611  [ 1120/ 1575]
loss: 0.006436  [ 1280/ 1575]
loss: 0.009041  [ 1440/ 1575]
Test Error: 
MSE: 102.501047
RMSE: 10.124280
MAE: 2.919072
R^2: 0.6795473103241083
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.011650  [    0/ 1575]
loss: 0.010083  [  160/ 1575]
loss: 0.010243  [  320/ 1575]
loss: 0.009292  [  480/ 1575]
loss: 0.008743  [  640/ 1575]
loss: 0.011826  [  800/ 1575]
loss: 0.007212  [  960/ 1575]
loss: 0.014165  [ 1120/ 1575]
loss: 0.008587  [ 1280/ 1575]
loss: 0.010901  [ 1440/ 1575]
Test Error: 
MSE: 105.229963
RMSE: 10.258166
MAE: 2.933042
R^2: 0.6710158007892031
loss: 0.011853  [    0/ 1575]
loss: 0.007466  [  160/ 1575]
loss: 0.010899  [  320/ 1575]
loss: 0.008979  [  480/ 1575]
loss: 0.011372  [  640/ 1575]
loss: 0.010574  [  800/ 1575]
loss: 0.011224  [  960/ 1575]
loss: 0.007956  [ 1120/ 1575]
loss: 0.007819  [ 1280/ 1575]
loss: 0.011197  [ 1440/ 1575]
Test Error: 
MSE: 103.225623
RMSE: 10.160001
MAE: 2.915410
R^2: 0.6772820403648292
loss: 0.009175  [    0/ 1575]
loss: 0.005945  [  160/ 1575]
loss: 0.012065  [  320/ 1575]
loss: 0.009095  [  480/ 1575]
loss: 0.006638  [  640/ 1575]
loss: 0.004025  [  800/ 1575]
loss: 0.008248  [  960/ 1575]
loss: 0.009559  [ 1120/ 1575]
loss: 0.008963  [ 1280/ 1575]
loss: 0.006084  [ 1440/ 1575]
Test Error: 
MSE: 95.332178
RMSE: 9.763820
MAE: 2.851371
R^2: 0.7019596003675002
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.014056  [    0/ 1575]
loss: 0.009358  [  160/ 1575]
loss: 0.006739  [  320/ 1575]
loss: 0.008500  [  480/ 1575]
loss: 0.007121  [  640/ 1575]
loss: 0.009325  [  800/ 1575]
loss: 0.010631  [  960/ 1575]
loss: 0.007255  [ 1120/ 1575]
loss: 0.008909  [ 1280/ 1575]
loss: 0.009857  [ 1440/ 1575]
Test Error: 
MSE: 96.026258
RMSE: 9.799299
MAE: 2.838178
R^2: 0.6997896732241882
loss: 0.008011  [    0/ 1575]
loss: 0.010873  [  160/ 1575]
loss: 0.010084  [  320/ 1575]
loss: 0.009244  [  480/ 1575]
loss: 0.012466  [  640/ 1575]
loss: 0.010892  [  800/ 1575]
loss: 0.011632  [  960/ 1575]
loss: 0.009692  [ 1120/ 1575]
loss: 0.007948  [ 1280/ 1575]
loss: 0.007977  [ 1440/ 1575]
Test Error: 
MSE: 91.969013
RMSE: 9.590048
MAE: 2.814243
R^2: 0.7124739857780082
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.006109  [    0/ 1575]
loss: 0.007469  [  160/ 1575]
loss: 0.015592  [  320/ 1575]
loss: 0.008511  [  480/ 1575]
loss: 0.009540  [  640/ 1575]
loss: 0.008946  [  800/ 1575]
loss: 0.008624  [  960/ 1575]
loss: 0.010609  [ 1120/ 1575]
loss: 0.007718  [ 1280/ 1575]
loss: 0.007721  [ 1440/ 1575]
Test Error: 
MSE: 96.497476
RMSE: 9.823313
MAE: 2.829109
R^2: 0.6983164873224669
loss: 0.009969  [    0/ 1575]
loss: 0.010168  [  160/ 1575]
loss: 0.007647  [  320/ 1575]
loss: 0.011792  [  480/ 1575]
loss: 0.005151  [  640/ 1575]
loss: 0.008853  [  800/ 1575]
loss: 0.006843  [  960/ 1575]
loss: 0.009394  [ 1120/ 1575]
loss: 0.008186  [ 1280/ 1575]
loss: 0.006512  [ 1440/ 1575]
Test Error: 
MSE: 94.433721
RMSE: 9.717701
MAE: 2.836597
R^2: 0.7047684804483596
loss: 0.010709  [    0/ 1575]
loss: 0.008438  [  160/ 1575]
loss: 0.008140  [  320/ 1575]
loss: 0.010348  [  480/ 1575]
loss: 0.008141  [  640/ 1575]
loss: 0.006890  [  800/ 1575]
loss: 0.006933  [  960/ 1575]
loss: 0.004676  [ 1120/ 1575]
loss: 0.007532  [ 1280/ 1575]
loss: 0.005411  [ 1440/ 1575]
Test Error: 
MSE: 85.292036
RMSE: 9.235369
MAE: 2.760656
R^2: 0.7333484553237367
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.009594  [    0/ 1575]
loss: 0.008551  [  160/ 1575]
loss: 0.006244  [  320/ 1575]
loss: 0.009708  [  480/ 1575]
loss: 0.006592  [  640/ 1575]
loss: 0.008537  [  800/ 1575]
loss: 0.008538  [  960/ 1575]
loss: 0.009648  [ 1120/ 1575]
loss: 0.004506  [ 1280/ 1575]
loss: 0.008952  [ 1440/ 1575]
Test Error: 
MSE: 94.965924
RMSE: 9.745046
MAE: 2.809237
R^2: 0.7031046349690108
loss: 0.011610  [    0/ 1575]
loss: 0.010386  [  160/ 1575]
loss: 0.009343  [  320/ 1575]
loss: 0.009265  [  480/ 1575]
loss: 0.008347  [  640/ 1575]
loss: 0.012256  [  800/ 1575]
loss: 0.006990  [  960/ 1575]
loss: 0.005060  [ 1120/ 1575]
loss: 0.006724  [ 1280/ 1575]
loss: 0.008408  [ 1440/ 1575]
Test Error: 
MSE: 81.669239
RMSE: 9.037103
MAE: 2.731630
R^2: 0.7446745356376052
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.007978  [    0/ 1575]
loss: 0.006722  [  160/ 1575]
loss: 0.006655  [  320/ 1575]
loss: 0.010244  [  480/ 1575]
loss: 0.009635  [  640/ 1575]
loss: 0.010848  [  800/ 1575]
loss: 0.008975  [  960/ 1575]
loss: 0.008879  [ 1120/ 1575]
loss: 0.004613  [ 1280/ 1575]
loss: 0.006842  [ 1440/ 1575]
Test Error: 
MSE: 80.001171
RMSE: 8.944337
MAE: 2.716334
R^2: 0.7498894767592904
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.008804  [    0/ 1575]
loss: 0.006630  [  160/ 1575]
loss: 0.007625  [  320/ 1575]
loss: 0.004906  [  480/ 1575]
loss: 0.007873  [  640/ 1575]
loss: 0.008578  [  800/ 1575]
loss: 0.008860  [  960/ 1575]
loss: 0.009131  [ 1120/ 1575]
loss: 0.010885  [ 1280/ 1575]
loss: 0.007702  [ 1440/ 1575]
Test Error: 
MSE: 81.739445
RMSE: 9.040987
MAE: 2.719989
R^2: 0.7444550489063309
loss: 0.006931  [    0/ 1575]
loss: 0.005069  [  160/ 1575]
loss: 0.006746  [  320/ 1575]
loss: 0.007757  [  480/ 1575]
loss: 0.006471  [  640/ 1575]
loss: 0.009041  [  800/ 1575]
loss: 0.006775  [  960/ 1575]
loss: 0.009458  [ 1120/ 1575]
loss: 0.010330  [ 1280/ 1575]
loss: 0.009779  [ 1440/ 1575]
Test Error: 
MSE: 77.235859
RMSE: 8.788393
MAE: 2.691835
R^2: 0.758534770074951
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.008955  [    0/ 1575]
loss: 0.009426  [  160/ 1575]
loss: 0.007228  [  320/ 1575]
loss: 0.010623  [  480/ 1575]
loss: 0.007018  [  640/ 1575]
loss: 0.004291  [  800/ 1575]
loss: 0.010179  [  960/ 1575]
loss: 0.007924  [ 1120/ 1575]
loss: 0.007144  [ 1280/ 1575]
loss: 0.007473  [ 1440/ 1575]
Test Error: 
MSE: 86.575765
RMSE: 9.304610
MAE: 2.747064
R^2: 0.7293350873783124
loss: 0.008592  [    0/ 1575]
loss: 0.009239  [  160/ 1575]
loss: 0.010267  [  320/ 1575]
loss: 0.004835  [  480/ 1575]
loss: 0.004827  [  640/ 1575]
loss: 0.005738  [  800/ 1575]
loss: 0.009172  [  960/ 1575]
loss: 0.004871  [ 1120/ 1575]
loss: 0.010329  [ 1280/ 1575]
loss: 0.006889  [ 1440/ 1575]
Test Error: 
MSE: 74.152764
RMSE: 8.611200
MAE: 2.662521
R^2: 0.7681735603403518
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.006297  [    0/ 1575]
loss: 0.008927  [  160/ 1575]
loss: 0.007057  [  320/ 1575]
loss: 0.009383  [  480/ 1575]
loss: 0.006874  [  640/ 1575]
loss: 0.007338  [  800/ 1575]
loss: 0.006240  [  960/ 1575]
loss: 0.007639  [ 1120/ 1575]
loss: 0.006383  [ 1280/ 1575]
loss: 0.005533  [ 1440/ 1575]
Test Error: 
MSE: 75.288481
RMSE: 8.676894
MAE: 2.664351
R^2: 0.764622926774811
loss: 0.007256  [    0/ 1575]
loss: 0.003459  [  160/ 1575]
loss: 0.006184  [  320/ 1575]
loss: 0.008014  [  480/ 1575]
loss: 0.005015  [  640/ 1575]
loss: 0.004590  [  800/ 1575]
loss: 0.007892  [  960/ 1575]
loss: 0.008194  [ 1120/ 1575]
loss: 0.005319  [ 1280/ 1575]
loss: 0.008137  [ 1440/ 1575]
Test Error: 
MSE: 73.933914
RMSE: 8.598483
MAE: 2.656450
R^2: 0.7688577606502446
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.005998  [    0/ 1575]
loss: 0.007449  [  160/ 1575]
loss: 0.006863  [  320/ 1575]
loss: 0.003895  [  480/ 1575]
loss: 0.005944  [  640/ 1575]
loss: 0.005523  [  800/ 1575]
loss: 0.007185  [  960/ 1575]
loss: 0.007110  [ 1120/ 1575]
loss: 0.007645  [ 1280/ 1575]
loss: 0.010711  [ 1440/ 1575]
Test Error: 
MSE: 75.893990
RMSE: 8.711716
MAE: 2.667314
R^2: 0.7627299026293617
loss: 0.006628  [    0/ 1575]
loss: 0.007925  [  160/ 1575]
loss: 0.008450  [  320/ 1575]
loss: 0.007393  [  480/ 1575]
loss: 0.012969  [  640/ 1575]
loss: 0.005549  [  800/ 1575]
loss: 0.004515  [  960/ 1575]
loss: 0.007465  [ 1120/ 1575]
loss: 0.006122  [ 1280/ 1575]
loss: 0.008223  [ 1440/ 1575]
Test Error: 
MSE: 70.523130
RMSE: 8.397805
MAE: 2.621614
R^2: 0.7795210168692039
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.006385  [    0/ 1575]
loss: 0.004494  [  160/ 1575]
loss: 0.005738  [  320/ 1575]
loss: 0.007903  [  480/ 1575]
loss: 0.008567  [  640/ 1575]
loss: 0.006620  [  800/ 1575]
loss: 0.006502  [  960/ 1575]
loss: 0.006221  [ 1120/ 1575]
loss: 0.004759  [ 1280/ 1575]
loss: 0.006032  [ 1440/ 1575]
Test Error: 
MSE: 68.185821
RMSE: 8.257471
MAE: 2.603084
R^2: 0.7868282273103476
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.009689  [    0/ 1575]
loss: 0.007032  [  160/ 1575]
loss: 0.006874  [  320/ 1575]
loss: 0.007468  [  480/ 1575]
loss: 0.007278  [  640/ 1575]
loss: 0.006316  [  800/ 1575]
loss: 0.004785  [  960/ 1575]
loss: 0.005402  [ 1120/ 1575]
loss: 0.005784  [ 1280/ 1575]
loss: 0.007013  [ 1440/ 1575]
Test Error: 
MSE: 67.419185
RMSE: 8.210919
MAE: 2.595404
R^2: 0.7892249887643767
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.008639  [    0/ 1575]
loss: 0.004693  [  160/ 1575]
loss: 0.006954  [  320/ 1575]
loss: 0.007256  [  480/ 1575]
loss: 0.005450  [  640/ 1575]
loss: 0.007528  [  800/ 1575]
loss: 0.007278  [  960/ 1575]
loss: 0.004963  [ 1120/ 1575]
loss: 0.005023  [ 1280/ 1575]
loss: 0.007356  [ 1440/ 1575]
Test Error: 
MSE: 75.131065
RMSE: 8.667818
MAE: 2.653888
R^2: 0.7651150649643574
loss: 0.006291  [    0/ 1575]
loss: 0.004930  [  160/ 1575]
loss: 0.008183  [  320/ 1575]
loss: 0.007141  [  480/ 1575]
loss: 0.006527  [  640/ 1575]
loss: 0.004716  [  800/ 1575]
loss: 0.005806  [  960/ 1575]
loss: 0.004053  [ 1120/ 1575]
loss: 0.007420  [ 1280/ 1575]
loss: 0.003788  [ 1440/ 1575]
Test Error: 
MSE: 74.800714
RMSE: 8.648741
MAE: 2.649556
R^2: 0.766147851566719
loss: 0.004427  [    0/ 1575]
loss: 0.009595  [  160/ 1575]
loss: 0.008535  [  320/ 1575]
loss: 0.008224  [  480/ 1575]
loss: 0.007211  [  640/ 1575]
loss: 0.006749  [  800/ 1575]
loss: 0.008048  [  960/ 1575]
loss: 0.004104  [ 1120/ 1575]
loss: 0.006193  [ 1280/ 1575]
loss: 0.007260  [ 1440/ 1575]
Test Error: 
MSE: 70.056229
RMSE: 8.369960
MAE: 2.611453
R^2: 0.7809807034821832
loss: 0.006211  [    0/ 1575]
loss: 0.005081  [  160/ 1575]
loss: 0.007259  [  320/ 1575]
loss: 0.006925  [  480/ 1575]
loss: 0.006153  [  640/ 1575]
loss: 0.004026  [  800/ 1575]
loss: 0.007876  [  960/ 1575]
loss: 0.005835  [ 1120/ 1575]
loss: 0.011858  [ 1280/ 1575]
loss: 0.008155  [ 1440/ 1575]
Test Error: 
MSE: 71.517285
RMSE: 8.456789
MAE: 2.620887
R^2: 0.7764129536022664
loss: 0.006563  [    0/ 1575]
loss: 0.004046  [  160/ 1575]
loss: 0.007970  [  320/ 1575]
loss: 0.005689  [  480/ 1575]
loss: 0.004141  [  640/ 1575]
loss: 0.007067  [  800/ 1575]
loss: 0.005642  [  960/ 1575]
loss: 0.003919  [ 1120/ 1575]
loss: 0.004324  [ 1280/ 1575]
loss: 0.007704  [ 1440/ 1575]
Test Error: 
MSE: 62.847710
RMSE: 7.927655
MAE: 2.549711
R^2: 0.8035169558864453
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003746  [    0/ 1575]
loss: 0.008209  [  160/ 1575]
loss: 0.006637  [  320/ 1575]
loss: 0.006346  [  480/ 1575]
loss: 0.005973  [  640/ 1575]
loss: 0.006194  [  800/ 1575]
loss: 0.006005  [  960/ 1575]
loss: 0.005060  [ 1120/ 1575]
loss: 0.007971  [ 1280/ 1575]
loss: 0.004410  [ 1440/ 1575]
Test Error: 
MSE: 67.103776
RMSE: 8.191689
MAE: 2.584080
R^2: 0.7902110641966007
loss: 0.005396  [    0/ 1575]
loss: 0.008151  [  160/ 1575]
loss: 0.008233  [  320/ 1575]
loss: 0.006767  [  480/ 1575]
loss: 0.004679  [  640/ 1575]
loss: 0.006319  [  800/ 1575]
loss: 0.006847  [  960/ 1575]
loss: 0.006942  [ 1120/ 1575]
loss: 0.008188  [ 1280/ 1575]
loss: 0.003786  [ 1440/ 1575]
Test Error: 
MSE: 64.357361
RMSE: 8.022304
MAE: 2.560071
R^2: 0.7987972812741262
loss: 0.003083  [    0/ 1575]
loss: 0.007297  [  160/ 1575]
loss: 0.006765  [  320/ 1575]
loss: 0.005116  [  480/ 1575]
loss: 0.004048  [  640/ 1575]
loss: 0.007922  [  800/ 1575]
loss: 0.006390  [  960/ 1575]
loss: 0.005155  [ 1120/ 1575]
loss: 0.007128  [ 1280/ 1575]
loss: 0.007379  [ 1440/ 1575]
Test Error: 
MSE: 65.085680
RMSE: 8.067570
MAE: 2.564417
R^2: 0.7965203105361102
loss: 0.008190  [    0/ 1575]
loss: 0.007843  [  160/ 1575]
loss: 0.006205  [  320/ 1575]
loss: 0.005261  [  480/ 1575]
loss: 0.005604  [  640/ 1575]
loss: 0.006852  [  800/ 1575]
loss: 0.004370  [  960/ 1575]
loss: 0.004981  [ 1120/ 1575]
loss: 0.008769  [ 1280/ 1575]
loss: 0.004148  [ 1440/ 1575]
Test Error: 
MSE: 59.310915
RMSE: 7.701358
MAE: 2.512411
R^2: 0.8145741654771358
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004367  [    0/ 1575]
loss: 0.007017  [  160/ 1575]
loss: 0.004270  [  320/ 1575]
loss: 0.007833  [  480/ 1575]
loss: 0.005964  [  640/ 1575]
loss: 0.002887  [  800/ 1575]
loss: 0.004075  [  960/ 1575]
loss: 0.007751  [ 1120/ 1575]
loss: 0.004009  [ 1280/ 1575]
loss: 0.002802  [ 1440/ 1575]
Test Error: 
MSE: 58.568602
RMSE: 7.653013
MAE: 2.505402
R^2: 0.8168948848759174
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003578  [    0/ 1575]
loss: 0.005409  [  160/ 1575]
loss: 0.008158  [  320/ 1575]
loss: 0.004162  [  480/ 1575]
loss: 0.005027  [  640/ 1575]
loss: 0.005186  [  800/ 1575]
loss: 0.005978  [  960/ 1575]
loss: 0.003950  [ 1120/ 1575]
loss: 0.005557  [ 1280/ 1575]
loss: 0.003830  [ 1440/ 1575]
Test Error: 
MSE: 58.760834
RMSE: 7.665562
MAE: 2.507078
R^2: 0.8162939024086175
loss: 0.005417  [    0/ 1575]
loss: 0.007251  [  160/ 1575]
loss: 0.005072  [  320/ 1575]
loss: 0.004223  [  480/ 1575]
loss: 0.005557  [  640/ 1575]
loss: 0.004535  [  800/ 1575]
loss: 0.006793  [  960/ 1575]
loss: 0.005418  [ 1120/ 1575]
loss: 0.004580  [ 1280/ 1575]
loss: 0.007594  [ 1440/ 1575]
Test Error: 
MSE: 63.205030
RMSE: 7.950159
MAE: 2.542636
R^2: 0.8023998536577226
loss: 0.004584  [    0/ 1575]
loss: 0.009363  [  160/ 1575]
loss: 0.004811  [  320/ 1575]
loss: 0.005346  [  480/ 1575]
loss: 0.004110  [  640/ 1575]
loss: 0.005757  [  800/ 1575]
loss: 0.005087  [  960/ 1575]
loss: 0.006031  [ 1120/ 1575]
loss: 0.003091  [ 1280/ 1575]
loss: 0.003309  [ 1440/ 1575]
Test Error: 
MSE: 60.012077
RMSE: 7.746746
MAE: 2.514188
R^2: 0.812382097642349
loss: 0.006328  [    0/ 1575]
loss: 0.004490  [  160/ 1575]
loss: 0.003839  [  320/ 1575]
loss: 0.003141  [  480/ 1575]
loss: 0.005115  [  640/ 1575]
loss: 0.005638  [  800/ 1575]
loss: 0.005111  [  960/ 1575]
loss: 0.008118  [ 1120/ 1575]
loss: 0.005260  [ 1280/ 1575]
loss: 0.007590  [ 1440/ 1575]
Test Error: 
MSE: 56.137616
RMSE: 7.492504
MAE: 2.480411
R^2: 0.824494962170345
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.006592  [    0/ 1575]
loss: 0.005836  [  160/ 1575]
loss: 0.004100  [  320/ 1575]
loss: 0.004341  [  480/ 1575]
loss: 0.004894  [  640/ 1575]
loss: 0.003809  [  800/ 1575]
loss: 0.010033  [  960/ 1575]
loss: 0.004502  [ 1120/ 1575]
loss: 0.005049  [ 1280/ 1575]
loss: 0.002755  [ 1440/ 1575]
Test Error: 
MSE: 65.138119
RMSE: 8.070819
MAE: 2.559044
R^2: 0.7963563677080707
loss: 0.006697  [    0/ 1575]
loss: 0.006356  [  160/ 1575]
loss: 0.005068  [  320/ 1575]
loss: 0.004404  [  480/ 1575]
loss: 0.003572  [  640/ 1575]
loss: 0.003381  [  800/ 1575]
loss: 0.003900  [  960/ 1575]
loss: 0.004803  [ 1120/ 1575]
loss: 0.004445  [ 1280/ 1575]
loss: 0.007006  [ 1440/ 1575]
Test Error: 
MSE: 54.902922
RMSE: 7.409651
MAE: 2.466347
R^2: 0.8283550302838947
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004283  [    0/ 1575]
loss: 0.004871  [  160/ 1575]
loss: 0.007008  [  320/ 1575]
loss: 0.003446  [  480/ 1575]
loss: 0.004235  [  640/ 1575]
loss: 0.004353  [  800/ 1575]
loss: 0.004905  [  960/ 1575]
loss: 0.004586  [ 1120/ 1575]
loss: 0.004300  [ 1280/ 1575]
loss: 0.003601  [ 1440/ 1575]
Test Error: 
MSE: 55.042880
RMSE: 7.419089
MAE: 2.468146
R^2: 0.8279174745282473
loss: 0.005056  [    0/ 1575]
loss: 0.003791  [  160/ 1575]
loss: 0.006566  [  320/ 1575]
loss: 0.003169  [  480/ 1575]
loss: 0.005323  [  640/ 1575]
loss: 0.002050  [  800/ 1575]
loss: 0.003416  [  960/ 1575]
loss: 0.004420  [ 1120/ 1575]
loss: 0.004670  [ 1280/ 1575]
loss: 0.006617  [ 1440/ 1575]
Test Error: 
MSE: 55.212333
RMSE: 7.430500
MAE: 2.467761
R^2: 0.8273877077351244
loss: 0.007259  [    0/ 1575]
loss: 0.004186  [  160/ 1575]
loss: 0.004268  [  320/ 1575]
loss: 0.005057  [  480/ 1575]
loss: 0.003507  [  640/ 1575]
loss: 0.004445  [  800/ 1575]
loss: 0.003635  [  960/ 1575]
loss: 0.004307  [ 1120/ 1575]
loss: 0.004423  [ 1280/ 1575]
loss: 0.004176  [ 1440/ 1575]
Test Error: 
MSE: 54.556384
RMSE: 7.386229
MAE: 2.461004
R^2: 0.8294384244815033
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003643  [    0/ 1575]
loss: 0.005477  [  160/ 1575]
loss: 0.005287  [  320/ 1575]
loss: 0.003224  [  480/ 1575]
loss: 0.004249  [  640/ 1575]
loss: 0.005074  [  800/ 1575]
loss: 0.004736  [  960/ 1575]
loss: 0.004920  [ 1120/ 1575]
loss: 0.006734  [ 1280/ 1575]
loss: 0.006638  [ 1440/ 1575]
Test Error: 
MSE: 53.926735
RMSE: 7.343483
MAE: 2.454406
R^2: 0.831406917649369
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003778  [    0/ 1575]
loss: 0.004211  [  160/ 1575]
loss: 0.006742  [  320/ 1575]
loss: 0.006005  [  480/ 1575]
loss: 0.003270  [  640/ 1575]
loss: 0.004671  [  800/ 1575]
loss: 0.003060  [  960/ 1575]
loss: 0.003692  [ 1120/ 1575]
loss: 0.009878  [ 1280/ 1575]
loss: 0.007683  [ 1440/ 1575]
Test Error: 
MSE: 52.495809
RMSE: 7.245399
MAE: 2.436624
R^2: 0.8358804754141733
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003084  [    0/ 1575]
loss: 0.004623  [  160/ 1575]
loss: 0.005103  [  320/ 1575]
loss: 0.006576  [  480/ 1575]
loss: 0.005637  [  640/ 1575]
loss: 0.003293  [  800/ 1575]
loss: 0.005135  [  960/ 1575]
loss: 0.006052  [ 1120/ 1575]
loss: 0.005624  [ 1280/ 1575]
loss: 0.007590  [ 1440/ 1575]
Test Error: 
MSE: 53.279782
RMSE: 7.299300
MAE: 2.445716
R^2: 0.8334295126958802
loss: 0.003369  [    0/ 1575]
loss: 0.004696  [  160/ 1575]
loss: 0.006912  [  320/ 1575]
loss: 0.004565  [  480/ 1575]
loss: 0.004693  [  640/ 1575]
loss: 0.003348  [  800/ 1575]
loss: 0.004085  [  960/ 1575]
loss: 0.007996  [ 1120/ 1575]
loss: 0.007026  [ 1280/ 1575]
loss: 0.004797  [ 1440/ 1575]
Test Error: 
MSE: 51.675948
RMSE: 7.188598
MAE: 2.426045
R^2: 0.8384436363815477
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004074  [    0/ 1575]
loss: 0.005124  [  160/ 1575]
loss: 0.006250  [  320/ 1575]
loss: 0.004274  [  480/ 1575]
loss: 0.004407  [  640/ 1575]
loss: 0.003447  [  800/ 1575]
loss: 0.005676  [  960/ 1575]
loss: 0.007619  [ 1120/ 1575]
loss: 0.007060  [ 1280/ 1575]
loss: 0.003106  [ 1440/ 1575]
Test Error: 
MSE: 52.226715
RMSE: 7.226805
MAE: 2.433678
R^2: 0.8367217510358592
loss: 0.006429  [    0/ 1575]
loss: 0.005262  [  160/ 1575]
loss: 0.003257  [  320/ 1575]
loss: 0.006246  [  480/ 1575]
loss: 0.006134  [  640/ 1575]
loss: 0.006030  [  800/ 1575]
loss: 0.003394  [  960/ 1575]
loss: 0.005970  [ 1120/ 1575]
loss: 0.006722  [ 1280/ 1575]
loss: 0.002372  [ 1440/ 1575]
Test Error: 
MSE: 50.749743
RMSE: 7.123885
MAE: 2.414392
R^2: 0.8413392630760541
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.005610  [    0/ 1575]
loss: 0.006030  [  160/ 1575]
loss: 0.003467  [  320/ 1575]
loss: 0.003397  [  480/ 1575]
loss: 0.003468  [  640/ 1575]
loss: 0.003448  [  800/ 1575]
loss: 0.004565  [  960/ 1575]
loss: 0.005724  [ 1120/ 1575]
loss: 0.005100  [ 1280/ 1575]
loss: 0.004796  [ 1440/ 1575]
Test Error: 
MSE: 50.813817
RMSE: 7.128381
MAE: 2.413240
R^2: 0.8411389448874652
loss: 0.004919  [    0/ 1575]
loss: 0.004681  [  160/ 1575]
loss: 0.004072  [  320/ 1575]
loss: 0.004459  [  480/ 1575]
loss: 0.003917  [  640/ 1575]
loss: 0.005411  [  800/ 1575]
loss: 0.006105  [  960/ 1575]
loss: 0.003925  [ 1120/ 1575]
loss: 0.006452  [ 1280/ 1575]
loss: 0.002972  [ 1440/ 1575]
Test Error: 
MSE: 62.086455
RMSE: 7.879496
MAE: 2.518281
R^2: 0.8058968953990566
loss: 0.007881  [    0/ 1575]
loss: 0.003134  [  160/ 1575]
loss: 0.003995  [  320/ 1575]
loss: 0.004933  [  480/ 1575]
loss: 0.003096  [  640/ 1575]
loss: 0.004396  [  800/ 1575]
loss: 0.005046  [  960/ 1575]
loss: 0.006208  [ 1120/ 1575]
loss: 0.006249  [ 1280/ 1575]
loss: 0.003614  [ 1440/ 1575]
Test Error: 
MSE: 49.728858
RMSE: 7.051869
MAE: 2.400741
R^2: 0.8445308907412339
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.006682  [    0/ 1575]
loss: 0.004868  [  160/ 1575]
loss: 0.005608  [  320/ 1575]
loss: 0.005582  [  480/ 1575]
loss: 0.004461  [  640/ 1575]
loss: 0.005460  [  800/ 1575]
loss: 0.003225  [  960/ 1575]
loss: 0.003378  [ 1120/ 1575]
loss: 0.006044  [ 1280/ 1575]
loss: 0.004349  [ 1440/ 1575]
Test Error: 
MSE: 49.850541
RMSE: 7.060492
MAE: 2.404599
R^2: 0.8441504707718609
loss: 0.003005  [    0/ 1575]
loss: 0.004841  [  160/ 1575]
loss: 0.002969  [  320/ 1575]
loss: 0.002867  [  480/ 1575]
loss: 0.006762  [  640/ 1575]
loss: 0.005224  [  800/ 1575]
loss: 0.002120  [  960/ 1575]
loss: 0.005824  [ 1120/ 1575]
loss: 0.005627  [ 1280/ 1575]
loss: 0.003728  [ 1440/ 1575]
Test Error: 
MSE: 48.870713
RMSE: 6.990759
MAE: 2.390194
R^2: 0.8472137403923655
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003807  [    0/ 1575]
loss: 0.005433  [  160/ 1575]
loss: 0.004360  [  320/ 1575]
loss: 0.004832  [  480/ 1575]
loss: 0.006173  [  640/ 1575]
loss: 0.008308  [  800/ 1575]
loss: 0.004628  [  960/ 1575]
loss: 0.006462  [ 1120/ 1575]
loss: 0.003654  [ 1280/ 1575]
loss: 0.007284  [ 1440/ 1575]
Test Error: 
MSE: 55.790543
RMSE: 7.469307
MAE: 2.464914
R^2: 0.8255800292786478
loss: 0.004930  [    0/ 1575]
loss: 0.006150  [  160/ 1575]
loss: 0.005224  [  320/ 1575]
loss: 0.006832  [  480/ 1575]
loss: 0.003819  [  640/ 1575]
loss: 0.002949  [  800/ 1575]
loss: 0.008418  [  960/ 1575]
loss: 0.005895  [ 1120/ 1575]
loss: 0.003322  [ 1280/ 1575]
loss: 0.002785  [ 1440/ 1575]
Test Error: 
MSE: 48.223226
RMSE: 6.944294
MAE: 2.381266
R^2: 0.8492380047350832
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003306  [    0/ 1575]
loss: 0.005745  [  160/ 1575]
loss: 0.004433  [  320/ 1575]
loss: 0.003791  [  480/ 1575]
loss: 0.004891  [  640/ 1575]
loss: 0.004189  [  800/ 1575]
loss: 0.005020  [  960/ 1575]
loss: 0.003020  [ 1120/ 1575]
loss: 0.003833  [ 1280/ 1575]
loss: 0.004617  [ 1440/ 1575]
Test Error: 
MSE: 47.850863
RMSE: 6.917432
MAE: 2.376600
R^2: 0.8504021335107437
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.007127  [    0/ 1575]
loss: 0.004752  [  160/ 1575]
loss: 0.005427  [  320/ 1575]
loss: 0.004237  [  480/ 1575]
loss: 0.005020  [  640/ 1575]
loss: 0.004825  [  800/ 1575]
loss: 0.005383  [  960/ 1575]
loss: 0.004071  [ 1120/ 1575]
loss: 0.002782  [ 1280/ 1575]
loss: 0.003977  [ 1440/ 1575]
Test Error: 
MSE: 48.753261
RMSE: 6.982354
MAE: 2.384518
R^2: 0.8475809365180462
loss: 0.005975  [    0/ 1575]
loss: 0.005756  [  160/ 1575]
loss: 0.003795  [  320/ 1575]
loss: 0.002900  [  480/ 1575]
loss: 0.004926  [  640/ 1575]
loss: 0.002850  [  800/ 1575]
loss: 0.004352  [  960/ 1575]
loss: 0.005581  [ 1120/ 1575]
loss: 0.003989  [ 1280/ 1575]
loss: 0.005220  [ 1440/ 1575]
Test Error: 
MSE: 47.416981
RMSE: 6.885999
MAE: 2.371812
R^2: 0.8517585950064017
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.001781  [    0/ 1575]
loss: 0.004469  [  160/ 1575]
loss: 0.002995  [  320/ 1575]
loss: 0.002254  [  480/ 1575]
loss: 0.003711  [  640/ 1575]
loss: 0.006870  [  800/ 1575]
loss: 0.007977  [  960/ 1575]
loss: 0.003650  [ 1120/ 1575]
loss: 0.003348  [ 1280/ 1575]
loss: 0.004396  [ 1440/ 1575]
Test Error: 
MSE: 50.152536
RMSE: 7.081846
MAE: 2.400454
R^2: 0.8432063310703843
loss: 0.003497  [    0/ 1575]
loss: 0.004592  [  160/ 1575]
loss: 0.002468  [  320/ 1575]
loss: 0.004563  [  480/ 1575]
loss: 0.004925  [  640/ 1575]
loss: 0.005244  [  800/ 1575]
loss: 0.005879  [  960/ 1575]
loss: 0.007089  [ 1120/ 1575]
loss: 0.005506  [ 1280/ 1575]
loss: 0.006535  [ 1440/ 1575]
Test Error: 
MSE: 54.213615
RMSE: 7.362990
MAE: 2.437497
R^2: 0.8305100364642174
loss: 0.008325  [    0/ 1575]
loss: 0.005503  [  160/ 1575]
loss: 0.003845  [  320/ 1575]
loss: 0.008565  [  480/ 1575]
loss: 0.004447  [  640/ 1575]
loss: 0.003090  [  800/ 1575]
loss: 0.003111  [  960/ 1575]
loss: 0.005603  [ 1120/ 1575]
loss: 0.005950  [ 1280/ 1575]
loss: 0.004363  [ 1440/ 1575]
Test Error: 
MSE: 46.431140
RMSE: 6.814040
MAE: 2.355349
R^2: 0.8548406663903965
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003429  [    0/ 1575]
loss: 0.005550  [  160/ 1575]
loss: 0.005223  [  320/ 1575]
loss: 0.005080  [  480/ 1575]
loss: 0.004402  [  640/ 1575]
loss: 0.003346  [  800/ 1575]
loss: 0.004997  [  960/ 1575]
loss: 0.005792  [ 1120/ 1575]
loss: 0.003635  [ 1280/ 1575]
loss: 0.004434  [ 1440/ 1575]
Test Error: 
MSE: 49.598667
RMSE: 7.042632
MAE: 2.391755
R^2: 0.8449379112977
loss: 0.002155  [    0/ 1575]
loss: 0.006254  [  160/ 1575]
loss: 0.004857  [  320/ 1575]
loss: 0.002651  [  480/ 1575]
loss: 0.007872  [  640/ 1575]
loss: 0.003362  [  800/ 1575]
loss: 0.003309  [  960/ 1575]
loss: 0.005327  [ 1120/ 1575]
loss: 0.001760  [ 1280/ 1575]
loss: 0.004073  [ 1440/ 1575]
Test Error: 
MSE: 47.200781
RMSE: 6.870282
MAE: 2.367672
R^2: 0.8524345099640398
loss: 0.003910  [    0/ 1575]
loss: 0.004318  [  160/ 1575]
loss: 0.004438  [  320/ 1575]
loss: 0.006172  [  480/ 1575]
loss: 0.003767  [  640/ 1575]
loss: 0.004687  [  800/ 1575]
loss: 0.003958  [  960/ 1575]
loss: 0.002563  [ 1120/ 1575]
loss: 0.004769  [ 1280/ 1575]
loss: 0.004701  [ 1440/ 1575]
Test Error: 
MSE: 46.034731
RMSE: 6.784890
MAE: 2.348233
R^2: 0.8560799723561481
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.006403  [    0/ 1575]
loss: 0.004459  [  160/ 1575]
loss: 0.004521  [  320/ 1575]
loss: 0.005271  [  480/ 1575]
loss: 0.004521  [  640/ 1575]
loss: 0.003742  [  800/ 1575]
loss: 0.003471  [  960/ 1575]
loss: 0.002436  [ 1120/ 1575]
loss: 0.006786  [ 1280/ 1575]
loss: 0.004208  [ 1440/ 1575]
Test Error: 
MSE: 46.910040
RMSE: 6.849090
MAE: 2.362607
R^2: 0.8533434622050511
loss: 0.003661  [    0/ 1575]
loss: 0.003032  [  160/ 1575]
loss: 0.003338  [  320/ 1575]
loss: 0.004375  [  480/ 1575]
loss: 0.004938  [  640/ 1575]
loss: 0.002466  [  800/ 1575]
loss: 0.004784  [  960/ 1575]
loss: 0.006126  [ 1120/ 1575]
loss: 0.005063  [ 1280/ 1575]
loss: 0.002749  [ 1440/ 1575]
Test Error: 
MSE: 47.246257
RMSE: 6.873591
MAE: 2.364472
R^2: 0.8522923358888009
loss: 0.004026  [    0/ 1575]
loss: 0.006543  [  160/ 1575]
loss: 0.004634  [  320/ 1575]
loss: 0.003503  [  480/ 1575]
loss: 0.004134  [  640/ 1575]
loss: 0.006451  [  800/ 1575]
loss: 0.005844  [  960/ 1575]
loss: 0.003322  [ 1120/ 1575]
loss: 0.005114  [ 1280/ 1575]
loss: 0.003560  [ 1440/ 1575]
Test Error: 
MSE: 44.752351
RMSE: 6.689720
MAE: 2.331725
R^2: 0.8600891233120881
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.005862  [    0/ 1575]
loss: 0.003886  [  160/ 1575]
loss: 0.003185  [  320/ 1575]
loss: 0.003728  [  480/ 1575]
loss: 0.005957  [  640/ 1575]
loss: 0.003781  [  800/ 1575]
loss: 0.006095  [  960/ 1575]
loss: 0.005322  [ 1120/ 1575]
loss: 0.007320  [ 1280/ 1575]
loss: 0.007266  [ 1440/ 1575]
Test Error: 
MSE: 45.557534
RMSE: 6.749632
MAE: 2.342262
R^2: 0.8575718521992806
loss: 0.004443  [    0/ 1575]
loss: 0.006098  [  160/ 1575]
loss: 0.004398  [  320/ 1575]
loss: 0.002691  [  480/ 1575]
loss: 0.002977  [  640/ 1575]
loss: 0.004357  [  800/ 1575]
loss: 0.005909  [  960/ 1575]
loss: 0.004849  [ 1120/ 1575]
loss: 0.003889  [ 1280/ 1575]
loss: 0.004262  [ 1440/ 1575]
Test Error: 
MSE: 45.111372
RMSE: 6.716500
MAE: 2.338648
R^2: 0.8589667029134338
loss: 0.004628  [    0/ 1575]
loss: 0.003671  [  160/ 1575]
loss: 0.002749  [  320/ 1575]
loss: 0.003451  [  480/ 1575]
loss: 0.004691  [  640/ 1575]
loss: 0.004347  [  800/ 1575]
loss: 0.006394  [  960/ 1575]
loss: 0.003554  [ 1120/ 1575]
loss: 0.001434  [ 1280/ 1575]
loss: 0.003046  [ 1440/ 1575]
Test Error: 
MSE: 44.108348
RMSE: 6.641412
MAE: 2.323503
R^2: 0.8621024939165655
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.005339  [    0/ 1575]
loss: 0.004288  [  160/ 1575]
loss: 0.002896  [  320/ 1575]
loss: 0.003880  [  480/ 1575]
loss: 0.002610  [  640/ 1575]
loss: 0.005625  [  800/ 1575]
loss: 0.002613  [  960/ 1575]
loss: 0.005118  [ 1120/ 1575]
loss: 0.004057  [ 1280/ 1575]
loss: 0.002289  [ 1440/ 1575]
Test Error: 
MSE: 43.754829
RMSE: 6.614743
MAE: 2.317197
R^2: 0.8632077134187615
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004542  [    0/ 1575]
loss: 0.004745  [  160/ 1575]
loss: 0.003516  [  320/ 1575]
loss: 0.003038  [  480/ 1575]
loss: 0.005749  [  640/ 1575]
loss: 0.003429  [  800/ 1575]
loss: 0.003406  [  960/ 1575]
loss: 0.004333  [ 1120/ 1575]
loss: 0.004374  [ 1280/ 1575]
loss: 0.005122  [ 1440/ 1575]
Test Error: 
MSE: 43.613735
RMSE: 6.604070
MAE: 2.315780
R^2: 0.8636488198462847
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004371  [    0/ 1575]
loss: 0.004156  [  160/ 1575]
loss: 0.004493  [  320/ 1575]
loss: 0.003622  [  480/ 1575]
loss: 0.007509  [  640/ 1575]
loss: 0.007236  [  800/ 1575]
loss: 0.001984  [  960/ 1575]
loss: 0.005302  [ 1120/ 1575]
loss: 0.004240  [ 1280/ 1575]
loss: 0.004776  [ 1440/ 1575]
Test Error: 
MSE: 44.165047
RMSE: 6.645679
MAE: 2.324773
R^2: 0.8619252339570385
loss: 0.003163  [    0/ 1575]
loss: 0.006654  [  160/ 1575]
loss: 0.005086  [  320/ 1575]
loss: 0.002535  [  480/ 1575]
loss: 0.004790  [  640/ 1575]
loss: 0.003467  [  800/ 1575]
loss: 0.005369  [  960/ 1575]
loss: 0.004644  [ 1120/ 1575]
loss: 0.004635  [ 1280/ 1575]
loss: 0.003146  [ 1440/ 1575]
Test Error: 
MSE: 43.893116
RMSE: 6.625188
MAE: 2.318979
R^2: 0.8627753823741388
loss: 0.002787  [    0/ 1575]
loss: 0.002366  [  160/ 1575]
loss: 0.003914  [  320/ 1575]
loss: 0.003808  [  480/ 1575]
loss: 0.002990  [  640/ 1575]
loss: 0.003288  [  800/ 1575]
loss: 0.003068  [  960/ 1575]
loss: 0.005774  [ 1120/ 1575]
loss: 0.002346  [ 1280/ 1575]
loss: 0.004837  [ 1440/ 1575]
Test Error: 
MSE: 44.787767
RMSE: 6.692366
MAE: 2.330436
R^2: 0.8599784009726292
loss: 0.005327  [    0/ 1575]
loss: 0.004677  [  160/ 1575]
loss: 0.003154  [  320/ 1575]
loss: 0.004591  [  480/ 1575]
loss: 0.004773  [  640/ 1575]
loss: 0.003135  [  800/ 1575]
loss: 0.004609  [  960/ 1575]
loss: 0.003538  [ 1120/ 1575]
loss: 0.004641  [ 1280/ 1575]
loss: 0.003105  [ 1440/ 1575]
Test Error: 
MSE: 50.287923
RMSE: 7.091398
MAE: 2.391231
R^2: 0.8427830670331962
loss: 0.003044  [    0/ 1575]
loss: 0.003480  [  160/ 1575]
loss: 0.004381  [  320/ 1575]
loss: 0.005288  [  480/ 1575]
loss: 0.003520  [  640/ 1575]
loss: 0.004743  [  800/ 1575]
loss: 0.004281  [  960/ 1575]
loss: 0.006097  [ 1120/ 1575]
loss: 0.002021  [ 1280/ 1575]
loss: 0.004395  [ 1440/ 1575]
Test Error: 
MSE: 43.128001
RMSE: 6.567191
MAE: 2.309080
R^2: 0.8651673889343923
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.006152  [    0/ 1575]
loss: 0.003704  [  160/ 1575]
loss: 0.003122  [  320/ 1575]
loss: 0.004186  [  480/ 1575]
loss: 0.004675  [  640/ 1575]
loss: 0.003842  [  800/ 1575]
loss: 0.003772  [  960/ 1575]
loss: 0.004145  [ 1120/ 1575]
loss: 0.006593  [ 1280/ 1575]
loss: 0.007377  [ 1440/ 1575]
Test Error: 
MSE: 62.186256
RMSE: 7.885826
MAE: 2.513476
R^2: 0.8055848828271517
loss: 0.004364  [    0/ 1575]
loss: 0.003830  [  160/ 1575]
loss: 0.004239  [  320/ 1575]
loss: 0.003228  [  480/ 1575]
loss: 0.003111  [  640/ 1575]
loss: 0.003862  [  800/ 1575]
loss: 0.003755  [  960/ 1575]
loss: 0.002097  [ 1120/ 1575]
loss: 0.002148  [ 1280/ 1575]
loss: 0.003692  [ 1440/ 1575]
Test Error: 
MSE: 43.696825
RMSE: 6.610357
MAE: 2.315729
R^2: 0.8633890514463312
loss: 0.003656  [    0/ 1575]
loss: 0.002611  [  160/ 1575]
loss: 0.003520  [  320/ 1575]
loss: 0.003015  [  480/ 1575]
loss: 0.003184  [  640/ 1575]
loss: 0.002937  [  800/ 1575]
loss: 0.005438  [  960/ 1575]
loss: 0.005664  [ 1120/ 1575]
loss: 0.003875  [ 1280/ 1575]
loss: 0.006050  [ 1440/ 1575]
Test Error: 
MSE: 42.009810
RMSE: 6.481497
MAE: 2.291319
R^2: 0.8686632289925732
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004494  [    0/ 1575]
loss: 0.004543  [  160/ 1575]
loss: 0.004338  [  320/ 1575]
loss: 0.004526  [  480/ 1575]
loss: 0.001755  [  640/ 1575]
loss: 0.003649  [  800/ 1575]
loss: 0.004397  [  960/ 1575]
loss: 0.004530  [ 1120/ 1575]
loss: 0.003797  [ 1280/ 1575]
loss: 0.005264  [ 1440/ 1575]
Test Error: 
MSE: 46.810551
RMSE: 6.841824
MAE: 2.350255
R^2: 0.8536544981575405
loss: 0.002870  [    0/ 1575]
loss: 0.006947  [  160/ 1575]
loss: 0.003821  [  320/ 1575]
loss: 0.005148  [  480/ 1575]
loss: 0.007004  [  640/ 1575]
loss: 0.003946  [  800/ 1575]
loss: 0.003367  [  960/ 1575]
loss: 0.003655  [ 1120/ 1575]
loss: 0.004095  [ 1280/ 1575]
loss: 0.004598  [ 1440/ 1575]
Test Error: 
MSE: 41.575544
RMSE: 6.447910
MAE: 2.284553
R^2: 0.8700208899640425
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003918  [    0/ 1575]
loss: 0.004204  [  160/ 1575]
loss: 0.002927  [  320/ 1575]
loss: 0.003460  [  480/ 1575]
loss: 0.004992  [  640/ 1575]
loss: 0.003515  [  800/ 1575]
loss: 0.005445  [  960/ 1575]
loss: 0.003831  [ 1120/ 1575]
loss: 0.003350  [ 1280/ 1575]
loss: 0.004450  [ 1440/ 1575]
Test Error: 
MSE: 43.015579
RMSE: 6.558626
MAE: 2.307097
R^2: 0.8655188572455239
loss: 0.004246  [    0/ 1575]
loss: 0.004329  [  160/ 1575]
loss: 0.003959  [  320/ 1575]
loss: 0.003189  [  480/ 1575]
loss: 0.005882  [  640/ 1575]
loss: 0.004317  [  800/ 1575]
loss: 0.004220  [  960/ 1575]
loss: 0.004326  [ 1120/ 1575]
loss: 0.003045  [ 1280/ 1575]
loss: 0.001842  [ 1440/ 1575]
Test Error: 
MSE: 41.632053
RMSE: 6.452291
MAE: 2.287567
R^2: 0.86984422395997
loss: 0.004564  [    0/ 1575]
loss: 0.003598  [  160/ 1575]
loss: 0.003865  [  320/ 1575]
loss: 0.003814  [  480/ 1575]
loss: 0.004265  [  640/ 1575]
loss: 0.002418  [  800/ 1575]
loss: 0.005834  [  960/ 1575]
loss: 0.004462  [ 1120/ 1575]
loss: 0.003972  [ 1280/ 1575]
loss: 0.002527  [ 1440/ 1575]
Test Error: 
MSE: 45.293688
RMSE: 6.730059
MAE: 2.331688
R^2: 0.8583967238424319
loss: 0.005540  [    0/ 1575]
loss: 0.005148  [  160/ 1575]
loss: 0.003127  [  320/ 1575]
loss: 0.002992  [  480/ 1575]
loss: 0.002645  [  640/ 1575]
loss: 0.005123  [  800/ 1575]
loss: 0.002161  [  960/ 1575]
loss: 0.004231  [ 1120/ 1575]
loss: 0.004595  [ 1280/ 1575]
loss: 0.005666  [ 1440/ 1575]
Test Error: 
MSE: 40.954113
RMSE: 6.399540
MAE: 2.277118
R^2: 0.871963690830889
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004749  [    0/ 1575]
loss: 0.004615  [  160/ 1575]
loss: 0.005457  [  320/ 1575]
loss: 0.006624  [  480/ 1575]
loss: 0.004220  [  640/ 1575]
loss: 0.003430  [  800/ 1575]
loss: 0.006229  [  960/ 1575]
loss: 0.003574  [ 1120/ 1575]
loss: 0.005187  [ 1280/ 1575]
loss: 0.004089  [ 1440/ 1575]
Test Error: 
MSE: 40.786416
RMSE: 6.386424
MAE: 2.274606
R^2: 0.872487968651318
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002961  [    0/ 1575]
loss: 0.005418  [  160/ 1575]
loss: 0.002168  [  320/ 1575]
loss: 0.003344  [  480/ 1575]
loss: 0.003604  [  640/ 1575]
loss: 0.004672  [  800/ 1575]
loss: 0.003657  [  960/ 1575]
loss: 0.003112  [ 1120/ 1575]
loss: 0.003041  [ 1280/ 1575]
loss: 0.002035  [ 1440/ 1575]
Test Error: 
MSE: 44.901528
RMSE: 6.700860
MAE: 2.325983
R^2: 0.8596227455514669
loss: 0.003133  [    0/ 1575]
loss: 0.004515  [  160/ 1575]
loss: 0.004439  [  320/ 1575]
loss: 0.002497  [  480/ 1575]
loss: 0.003251  [  640/ 1575]
loss: 0.003200  [  800/ 1575]
loss: 0.005884  [  960/ 1575]
loss: 0.003954  [ 1120/ 1575]
loss: 0.003588  [ 1280/ 1575]
loss: 0.003504  [ 1440/ 1575]
Test Error: 
MSE: 47.524021
RMSE: 6.893767
MAE: 2.364951
R^2: 0.8514239544192854
loss: 0.004675  [    0/ 1575]
loss: 0.005438  [  160/ 1575]
loss: 0.004940  [  320/ 1575]
loss: 0.003012  [  480/ 1575]
loss: 0.004865  [  640/ 1575]
loss: 0.003531  [  800/ 1575]
loss: 0.002860  [  960/ 1575]
loss: 0.003655  [ 1120/ 1575]
loss: 0.004967  [ 1280/ 1575]
loss: 0.003675  [ 1440/ 1575]
Test Error: 
MSE: 42.690925
RMSE: 6.533829
MAE: 2.297618
R^2: 0.8665338352314452
loss: 0.004509  [    0/ 1575]
loss: 0.003075  [  160/ 1575]
loss: 0.003049  [  320/ 1575]
loss: 0.004023  [  480/ 1575]
loss: 0.002222  [  640/ 1575]
loss: 0.003837  [  800/ 1575]
loss: 0.004204  [  960/ 1575]
loss: 0.002545  [ 1120/ 1575]
loss: 0.003341  [ 1280/ 1575]
loss: 0.005953  [ 1440/ 1575]
Test Error: 
MSE: 52.110487
RMSE: 7.218759
MAE: 2.408353
R^2: 0.8370851204743172
loss: 0.004954  [    0/ 1575]
loss: 0.004060  [  160/ 1575]
loss: 0.003003  [  320/ 1575]
loss: 0.004166  [  480/ 1575]
loss: 0.005832  [  640/ 1575]
loss: 0.004869  [  800/ 1575]
loss: 0.003781  [  960/ 1575]
loss: 0.004138  [ 1120/ 1575]
loss: 0.002341  [ 1280/ 1575]
loss: 0.005939  [ 1440/ 1575]
Test Error: 
MSE: 44.140943
RMSE: 6.643865
MAE: 2.315549
R^2: 0.8620005908491997
loss: 0.005124  [    0/ 1575]
loss: 0.005440  [  160/ 1575]
loss: 0.003860  [  320/ 1575]
loss: 0.005764  [  480/ 1575]
loss: 0.005227  [  640/ 1575]
loss: 0.003032  [  800/ 1575]
loss: 0.003575  [  960/ 1575]
loss: 0.002925  [ 1120/ 1575]
loss: 0.004665  [ 1280/ 1575]
loss: 0.005104  [ 1440/ 1575]
Test Error: 
MSE: 40.499804
RMSE: 6.363946
MAE: 2.266661
R^2: 0.8733840138560814
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004281  [    0/ 1575]
loss: 0.003311  [  160/ 1575]
loss: 0.002740  [  320/ 1575]
loss: 0.003636  [  480/ 1575]
loss: 0.004078  [  640/ 1575]
loss: 0.002915  [  800/ 1575]
loss: 0.002255  [  960/ 1575]
loss: 0.003600  [ 1120/ 1575]
loss: 0.002784  [ 1280/ 1575]
loss: 0.004773  [ 1440/ 1575]
Test Error: 
MSE: 39.650330
RMSE: 6.296851
MAE: 2.255792
R^2: 0.8760397554712699
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003223  [    0/ 1575]
loss: 0.003858  [  160/ 1575]
loss: 0.003829  [  320/ 1575]
loss: 0.003885  [  480/ 1575]
loss: 0.004329  [  640/ 1575]
loss: 0.003459  [  800/ 1575]
loss: 0.003925  [  960/ 1575]
loss: 0.003998  [ 1120/ 1575]
loss: 0.004196  [ 1280/ 1575]
loss: 0.003907  [ 1440/ 1575]
Test Error: 
MSE: 41.639958
RMSE: 6.452903
MAE: 2.285671
R^2: 0.869819510334093
loss: 0.004755  [    0/ 1575]
loss: 0.003373  [  160/ 1575]
loss: 0.004032  [  320/ 1575]
loss: 0.004380  [  480/ 1575]
loss: 0.002047  [  640/ 1575]
loss: 0.005409  [  800/ 1575]
loss: 0.004122  [  960/ 1575]
loss: 0.004556  [ 1120/ 1575]
loss: 0.003842  [ 1280/ 1575]
loss: 0.004209  [ 1440/ 1575]
Test Error: 
MSE: 40.640652
RMSE: 6.375002
MAE: 2.267990
R^2: 0.8729436746692942
loss: 0.004617  [    0/ 1575]
loss: 0.004701  [  160/ 1575]
loss: 0.003763  [  320/ 1575]
loss: 0.003938  [  480/ 1575]
loss: 0.002963  [  640/ 1575]
loss: 0.003175  [  800/ 1575]
loss: 0.003609  [  960/ 1575]
loss: 0.003402  [ 1120/ 1575]
loss: 0.004316  [ 1280/ 1575]
loss: 0.001901  [ 1440/ 1575]
Test Error: 
MSE: 39.429507
RMSE: 6.279292
MAE: 2.254275
R^2: 0.8767301207182375
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004008  [    0/ 1575]
loss: 0.003669  [  160/ 1575]
loss: 0.002291  [  320/ 1575]
loss: 0.003224  [  480/ 1575]
loss: 0.004319  [  640/ 1575]
loss: 0.006375  [  800/ 1575]
loss: 0.004609  [  960/ 1575]
loss: 0.004321  [ 1120/ 1575]
loss: 0.005105  [ 1280/ 1575]
loss: 0.005097  [ 1440/ 1575]
Test Error: 
MSE: 39.115107
RMSE: 6.254207
MAE: 2.245482
R^2: 0.8777130416130571
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003208  [    0/ 1575]
loss: 0.003100  [  160/ 1575]
loss: 0.002925  [  320/ 1575]
loss: 0.004503  [  480/ 1575]
loss: 0.003768  [  640/ 1575]
loss: 0.003344  [  800/ 1575]
loss: 0.005112  [  960/ 1575]
loss: 0.002124  [ 1120/ 1575]
loss: 0.002480  [ 1280/ 1575]
loss: 0.003137  [ 1440/ 1575]
Test Error: 
MSE: 49.081379
RMSE: 7.005810
MAE: 2.373679
R^2: 0.8465551281753532
loss: 0.003071  [    0/ 1575]
loss: 0.005340  [  160/ 1575]
loss: 0.003493  [  320/ 1575]
loss: 0.003247  [  480/ 1575]
loss: 0.004841  [  640/ 1575]
loss: 0.004518  [  800/ 1575]
loss: 0.002704  [  960/ 1575]
loss: 0.003434  [ 1120/ 1575]
loss: 0.005725  [ 1280/ 1575]
loss: 0.003816  [ 1440/ 1575]
Test Error: 
MSE: 38.963874
RMSE: 6.242105
MAE: 2.247145
R^2: 0.8781858451387475
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003598  [    0/ 1575]
loss: 0.003655  [  160/ 1575]
loss: 0.003824  [  320/ 1575]
loss: 0.004116  [  480/ 1575]
loss: 0.002283  [  640/ 1575]
loss: 0.005205  [  800/ 1575]
loss: 0.003595  [  960/ 1575]
loss: 0.003395  [ 1120/ 1575]
loss: 0.003369  [ 1280/ 1575]
loss: 0.002890  [ 1440/ 1575]
Test Error: 
MSE: 40.956340
RMSE: 6.399714
MAE: 2.270699
R^2: 0.8719567282641132
loss: 0.003454  [    0/ 1575]
loss: 0.002929  [  160/ 1575]
loss: 0.005148  [  320/ 1575]
loss: 0.005118  [  480/ 1575]
loss: 0.002784  [  640/ 1575]
loss: 0.003677  [  800/ 1575]
loss: 0.002776  [  960/ 1575]
loss: 0.005206  [ 1120/ 1575]
loss: 0.003609  [ 1280/ 1575]
loss: 0.003337  [ 1440/ 1575]
Test Error: 
MSE: 44.487819
RMSE: 6.669919
MAE: 2.317416
R^2: 0.8609161408084028
loss: 0.004060  [    0/ 1575]
loss: 0.005741  [  160/ 1575]
loss: 0.004803  [  320/ 1575]
loss: 0.006040  [  480/ 1575]
loss: 0.007225  [  640/ 1575]
loss: 0.002645  [  800/ 1575]
loss: 0.004508  [  960/ 1575]
loss: 0.003359  [ 1120/ 1575]
loss: 0.003470  [ 1280/ 1575]
loss: 0.003569  [ 1440/ 1575]
Test Error: 
MSE: 38.942859
RMSE: 6.240421
MAE: 2.242814
R^2: 0.8782515452413683
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003996  [    0/ 1575]
loss: 0.003492  [  160/ 1575]
loss: 0.003918  [  320/ 1575]
loss: 0.004807  [  480/ 1575]
loss: 0.002841  [  640/ 1575]
loss: 0.003909  [  800/ 1575]
loss: 0.003412  [  960/ 1575]
loss: 0.005074  [ 1120/ 1575]
loss: 0.004213  [ 1280/ 1575]
loss: 0.004477  [ 1440/ 1575]
Test Error: 
MSE: 39.878816
RMSE: 6.314968
MAE: 2.259594
R^2: 0.8753254317514705
loss: 0.002937  [    0/ 1575]
loss: 0.003822  [  160/ 1575]
loss: 0.003236  [  320/ 1575]
loss: 0.004811  [  480/ 1575]
loss: 0.003654  [  640/ 1575]
loss: 0.004872  [  800/ 1575]
loss: 0.004755  [  960/ 1575]
loss: 0.003679  [ 1120/ 1575]
loss: 0.006204  [ 1280/ 1575]
loss: 0.004052  [ 1440/ 1575]
Test Error: 
MSE: 39.511773
RMSE: 6.285839
MAE: 2.254573
R^2: 0.876472931432316
loss: 0.005822  [    0/ 1575]
loss: 0.003107  [  160/ 1575]
loss: 0.003935  [  320/ 1575]
loss: 0.007062  [  480/ 1575]
loss: 0.003002  [  640/ 1575]
loss: 0.005152  [  800/ 1575]
loss: 0.002716  [  960/ 1575]
loss: 0.001896  [ 1120/ 1575]
loss: 0.005320  [ 1280/ 1575]
loss: 0.005435  [ 1440/ 1575]
Test Error: 
MSE: 44.896443
RMSE: 6.700481
MAE: 2.323115
R^2: 0.859638642541189
loss: 0.005383  [    0/ 1575]
loss: 0.003974  [  160/ 1575]
loss: 0.004000  [  320/ 1575]
loss: 0.003949  [  480/ 1575]
loss: 0.002108  [  640/ 1575]
loss: 0.003771  [  800/ 1575]
loss: 0.002770  [  960/ 1575]
loss: 0.003069  [ 1120/ 1575]
loss: 0.004194  [ 1280/ 1575]
loss: 0.004952  [ 1440/ 1575]
Test Error: 
MSE: 38.110699
RMSE: 6.173386
MAE: 2.233784
R^2: 0.8808531589893595
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002901  [    0/ 1575]
loss: 0.004323  [  160/ 1575]
loss: 0.004104  [  320/ 1575]
loss: 0.004521  [  480/ 1575]
loss: 0.004405  [  640/ 1575]
loss: 0.003260  [  800/ 1575]
loss: 0.004511  [  960/ 1575]
loss: 0.004157  [ 1120/ 1575]
loss: 0.003131  [ 1280/ 1575]
loss: 0.002590  [ 1440/ 1575]
Test Error: 
MSE: 37.794734
RMSE: 6.147742
MAE: 2.227164
R^2: 0.881840969470185
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004023  [    0/ 1575]
loss: 0.003419  [  160/ 1575]
loss: 0.005765  [  320/ 1575]
loss: 0.003861  [  480/ 1575]
loss: 0.001921  [  640/ 1575]
loss: 0.003264  [  800/ 1575]
loss: 0.003222  [  960/ 1575]
loss: 0.004054  [ 1120/ 1575]
loss: 0.002873  [ 1280/ 1575]
loss: 0.001736  [ 1440/ 1575]
Test Error: 
MSE: 37.807162
RMSE: 6.148753
MAE: 2.225137
R^2: 0.8818021159906619
loss: 0.003069  [    0/ 1575]
loss: 0.004512  [  160/ 1575]
loss: 0.003863  [  320/ 1575]
loss: 0.004022  [  480/ 1575]
loss: 0.002410  [  640/ 1575]
loss: 0.002560  [  800/ 1575]
loss: 0.002487  [  960/ 1575]
loss: 0.003214  [ 1120/ 1575]
loss: 0.003434  [ 1280/ 1575]
loss: 0.002555  [ 1440/ 1575]
Test Error: 
MSE: 38.524386
RMSE: 6.206802
MAE: 2.235417
R^2: 0.8795598342285182
loss: 0.005418  [    0/ 1575]
loss: 0.003991  [  160/ 1575]
loss: 0.003786  [  320/ 1575]
loss: 0.002973  [  480/ 1575]
loss: 0.002371  [  640/ 1575]
loss: 0.001322  [  800/ 1575]
loss: 0.005169  [  960/ 1575]
loss: 0.003508  [ 1120/ 1575]
loss: 0.004473  [ 1280/ 1575]
loss: 0.004958  [ 1440/ 1575]
Test Error: 
MSE: 41.342083
RMSE: 6.429781
MAE: 2.274068
R^2: 0.8707507679594474
loss: 0.002550  [    0/ 1575]
loss: 0.005097  [  160/ 1575]
loss: 0.001832  [  320/ 1575]
loss: 0.003196  [  480/ 1575]
loss: 0.004649  [  640/ 1575]
loss: 0.003900  [  800/ 1575]
loss: 0.003311  [  960/ 1575]
loss: 0.001732  [ 1120/ 1575]
loss: 0.004238  [ 1280/ 1575]
loss: 0.004667  [ 1440/ 1575]
Test Error: 
MSE: 37.343825
RMSE: 6.110959
MAE: 2.220723
R^2: 0.8832506634661991
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003210  [    0/ 1575]
loss: 0.003337  [  160/ 1575]
loss: 0.002658  [  320/ 1575]
loss: 0.002452  [  480/ 1575]
loss: 0.005033  [  640/ 1575]
loss: 0.003331  [  800/ 1575]
loss: 0.003041  [  960/ 1575]
loss: 0.003940  [ 1120/ 1575]
loss: 0.002419  [ 1280/ 1575]
loss: 0.002747  [ 1440/ 1575]
Test Error: 
MSE: 37.271553
RMSE: 6.105043
MAE: 2.218304
R^2: 0.8834766097785957
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003296  [    0/ 1575]
loss: 0.003268  [  160/ 1575]
loss: 0.003997  [  320/ 1575]
loss: 0.004124  [  480/ 1575]
loss: 0.004684  [  640/ 1575]
loss: 0.003502  [  800/ 1575]
loss: 0.005124  [  960/ 1575]
loss: 0.004161  [ 1120/ 1575]
loss: 0.002858  [ 1280/ 1575]
loss: 0.002714  [ 1440/ 1575]
Test Error: 
MSE: 38.399851
RMSE: 6.196761
MAE: 2.232838
R^2: 0.8799491725290438
loss: 0.004173  [    0/ 1575]
loss: 0.001712  [  160/ 1575]
loss: 0.005348  [  320/ 1575]
loss: 0.003369  [  480/ 1575]
loss: 0.002838  [  640/ 1575]
loss: 0.004115  [  800/ 1575]
loss: 0.004105  [  960/ 1575]
loss: 0.002565  [ 1120/ 1575]
loss: 0.003227  [ 1280/ 1575]
loss: 0.004169  [ 1440/ 1575]
Test Error: 
MSE: 38.194718
RMSE: 6.180188
MAE: 2.234599
R^2: 0.880590486563009
loss: 0.005028  [    0/ 1575]
loss: 0.002564  [  160/ 1575]
loss: 0.005980  [  320/ 1575]
loss: 0.003158  [  480/ 1575]
loss: 0.003475  [  640/ 1575]
loss: 0.002953  [  800/ 1575]
loss: 0.003601  [  960/ 1575]
loss: 0.003585  [ 1120/ 1575]
loss: 0.003375  [ 1280/ 1575]
loss: 0.002368  [ 1440/ 1575]
Test Error: 
MSE: 36.949735
RMSE: 6.078629
MAE: 2.213811
R^2: 0.8844827208915358
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004200  [    0/ 1575]
loss: 0.002848  [  160/ 1575]
loss: 0.004095  [  320/ 1575]
loss: 0.003966  [  480/ 1575]
loss: 0.003488  [  640/ 1575]
loss: 0.004100  [  800/ 1575]
loss: 0.003902  [  960/ 1575]
loss: 0.002287  [ 1120/ 1575]
loss: 0.003177  [ 1280/ 1575]
loss: 0.004197  [ 1440/ 1575]
Test Error: 
MSE: 37.831249
RMSE: 6.150711
MAE: 2.228970
R^2: 0.8817268117889407
loss: 0.003263  [    0/ 1575]
loss: 0.003076  [  160/ 1575]
loss: 0.004547  [  320/ 1575]
loss: 0.002123  [  480/ 1575]
loss: 0.004677  [  640/ 1575]
loss: 0.002420  [  800/ 1575]
loss: 0.005277  [  960/ 1575]
loss: 0.004376  [ 1120/ 1575]
loss: 0.004093  [ 1280/ 1575]
loss: 0.003257  [ 1440/ 1575]
Test Error: 
MSE: 36.738014
RMSE: 6.061189
MAE: 2.210199
R^2: 0.8851446323994127
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003446  [    0/ 1575]
loss: 0.003072  [  160/ 1575]
loss: 0.003493  [  320/ 1575]
loss: 0.005130  [  480/ 1575]
loss: 0.002531  [  640/ 1575]
loss: 0.002721  [  800/ 1575]
loss: 0.004158  [  960/ 1575]
loss: 0.005098  [ 1120/ 1575]
loss: 0.003327  [ 1280/ 1575]
loss: 0.003691  [ 1440/ 1575]
Test Error: 
MSE: 36.624612
RMSE: 6.051827
MAE: 2.209046
R^2: 0.885499166392755
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003122  [    0/ 1575]
loss: 0.004402  [  160/ 1575]
loss: 0.005240  [  320/ 1575]
loss: 0.001944  [  480/ 1575]
loss: 0.004207  [  640/ 1575]
loss: 0.003589  [  800/ 1575]
loss: 0.004702  [  960/ 1575]
loss: 0.003031  [ 1120/ 1575]
loss: 0.002946  [ 1280/ 1575]
loss: 0.003844  [ 1440/ 1575]
Test Error: 
MSE: 37.059299
RMSE: 6.087635
MAE: 2.211435
R^2: 0.8841401881150076
loss: 0.002646  [    0/ 1575]
loss: 0.002649  [  160/ 1575]
loss: 0.003512  [  320/ 1575]
loss: 0.002960  [  480/ 1575]
loss: 0.002151  [  640/ 1575]
loss: 0.003600  [  800/ 1575]
loss: 0.002823  [  960/ 1575]
loss: 0.002338  [ 1120/ 1575]
loss: 0.003255  [ 1280/ 1575]
loss: 0.003648  [ 1440/ 1575]
Test Error: 
MSE: 45.097480
RMSE: 6.715466
MAE: 2.328675
R^2: 0.8590101340248028
loss: 0.004861  [    0/ 1575]
loss: 0.004641  [  160/ 1575]
loss: 0.003476  [  320/ 1575]
loss: 0.005490  [  480/ 1575]
loss: 0.005551  [  640/ 1575]
loss: 0.002203  [  800/ 1575]
loss: 0.002596  [  960/ 1575]
loss: 0.004354  [ 1120/ 1575]
loss: 0.003401  [ 1280/ 1575]
loss: 0.002643  [ 1440/ 1575]
Test Error: 
MSE: 46.571154
RMSE: 6.824306
MAE: 2.347830
R^2: 0.8544029364039717
loss: 0.002940  [    0/ 1575]
loss: 0.003771  [  160/ 1575]
loss: 0.003709  [  320/ 1575]
loss: 0.002856  [  480/ 1575]
loss: 0.004770  [  640/ 1575]
loss: 0.002075  [  800/ 1575]
loss: 0.005092  [  960/ 1575]
loss: 0.005313  [ 1120/ 1575]
loss: 0.002549  [ 1280/ 1575]
loss: 0.002484  [ 1440/ 1575]
Test Error: 
MSE: 37.697153
RMSE: 6.139801
MAE: 2.224546
R^2: 0.8821460405694823
loss: 0.002630  [    0/ 1575]
loss: 0.001621  [  160/ 1575]
loss: 0.003414  [  320/ 1575]
loss: 0.003998  [  480/ 1575]
loss: 0.003767  [  640/ 1575]
loss: 0.005744  [  800/ 1575]
loss: 0.003944  [  960/ 1575]
loss: 0.003743  [ 1120/ 1575]
loss: 0.002433  [ 1280/ 1575]
loss: 0.003792  [ 1440/ 1575]
Test Error: 
MSE: 46.058863
RMSE: 6.786668
MAE: 2.342109
R^2: 0.8560045278163118
loss: 0.003585  [    0/ 1575]
loss: 0.004202  [  160/ 1575]
loss: 0.005412  [  320/ 1575]
loss: 0.003877  [  480/ 1575]
loss: 0.001864  [  640/ 1575]
loss: 0.003423  [  800/ 1575]
loss: 0.003210  [  960/ 1575]
loss: 0.003192  [ 1120/ 1575]
loss: 0.002656  [ 1280/ 1575]
loss: 0.004194  [ 1440/ 1575]
Test Error: 
MSE: 35.990763
RMSE: 5.999230
MAE: 2.198604
R^2: 0.8874807913639086
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004083  [    0/ 1575]
loss: 0.002956  [  160/ 1575]
loss: 0.003395  [  320/ 1575]
loss: 0.003662  [  480/ 1575]
loss: 0.003278  [  640/ 1575]
loss: 0.003437  [  800/ 1575]
loss: 0.003994  [  960/ 1575]
loss: 0.004860  [ 1120/ 1575]
loss: 0.004067  [ 1280/ 1575]
loss: 0.002855  [ 1440/ 1575]
Test Error: 
MSE: 38.215222
RMSE: 6.181846
MAE: 2.227859
R^2: 0.8805263849321409
loss: 0.003578  [    0/ 1575]
loss: 0.003645  [  160/ 1575]
loss: 0.003861  [  320/ 1575]
loss: 0.003662  [  480/ 1575]
loss: 0.003225  [  640/ 1575]
loss: 0.001882  [  800/ 1575]
loss: 0.003906  [  960/ 1575]
loss: 0.002024  [ 1120/ 1575]
loss: 0.003255  [ 1280/ 1575]
loss: 0.003789  [ 1440/ 1575]
Test Error: 
MSE: 35.759391
RMSE: 5.979916
MAE: 2.194298
R^2: 0.8882041376222073
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003120  [    0/ 1575]
loss: 0.003552  [  160/ 1575]
loss: 0.004521  [  320/ 1575]
loss: 0.003582  [  480/ 1575]
loss: 0.002584  [  640/ 1575]
loss: 0.002896  [  800/ 1575]
loss: 0.004688  [  960/ 1575]
loss: 0.004489  [ 1120/ 1575]
loss: 0.002521  [ 1280/ 1575]
loss: 0.002566  [ 1440/ 1575]
Test Error: 
MSE: 38.379069
RMSE: 6.195084
MAE: 2.230054
R^2: 0.8800141435008219
loss: 0.003353  [    0/ 1575]
loss: 0.003756  [  160/ 1575]
loss: 0.004261  [  320/ 1575]
loss: 0.003191  [  480/ 1575]
loss: 0.004961  [  640/ 1575]
loss: 0.003702  [  800/ 1575]
loss: 0.003986  [  960/ 1575]
loss: 0.004498  [ 1120/ 1575]
loss: 0.005179  [ 1280/ 1575]
loss: 0.003265  [ 1440/ 1575]
Test Error: 
MSE: 41.065349
RMSE: 6.408225
MAE: 2.271994
R^2: 0.871615931550366
loss: 0.004244  [    0/ 1575]
loss: 0.004016  [  160/ 1575]
loss: 0.003621  [  320/ 1575]
loss: 0.003377  [  480/ 1575]
loss: 0.003995  [  640/ 1575]
loss: 0.004751  [  800/ 1575]
loss: 0.001929  [  960/ 1575]
loss: 0.002805  [ 1120/ 1575]
loss: 0.002483  [ 1280/ 1575]
loss: 0.004901  [ 1440/ 1575]
Test Error: 
MSE: 38.212964
RMSE: 6.181664
MAE: 2.227155
R^2: 0.8805334427554361
loss: 0.003026  [    0/ 1575]
loss: 0.004154  [  160/ 1575]
loss: 0.002873  [  320/ 1575]
loss: 0.003653  [  480/ 1575]
loss: 0.004278  [  640/ 1575]
loss: 0.002615  [  800/ 1575]
loss: 0.002644  [  960/ 1575]
loss: 0.004271  [ 1120/ 1575]
loss: 0.003553  [ 1280/ 1575]
loss: 0.003037  [ 1440/ 1575]
Test Error: 
MSE: 35.725971
RMSE: 5.977121
MAE: 2.194677
R^2: 0.8883086182248658
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003384  [    0/ 1575]
loss: 0.003205  [  160/ 1575]
loss: 0.002711  [  320/ 1575]
loss: 0.003468  [  480/ 1575]
loss: 0.003632  [  640/ 1575]
loss: 0.001928  [  800/ 1575]
loss: 0.003822  [  960/ 1575]
loss: 0.003376  [ 1120/ 1575]
loss: 0.002292  [ 1280/ 1575]
loss: 0.003389  [ 1440/ 1575]
Test Error: 
MSE: 35.884465
RMSE: 5.990364
MAE: 2.192965
R^2: 0.8878131142946953
loss: 0.003187  [    0/ 1575]
loss: 0.003977  [  160/ 1575]
loss: 0.003927  [  320/ 1575]
loss: 0.003010  [  480/ 1575]
loss: 0.004122  [  640/ 1575]
loss: 0.002842  [  800/ 1575]
loss: 0.001751  [  960/ 1575]
loss: 0.003591  [ 1120/ 1575]
loss: 0.002802  [ 1280/ 1575]
loss: 0.004475  [ 1440/ 1575]
Test Error: 
MSE: 42.533821
RMSE: 6.521796
MAE: 2.295357
R^2: 0.8670249945463827
loss: 0.002728  [    0/ 1575]
loss: 0.002835  [  160/ 1575]
loss: 0.002646  [  320/ 1575]
loss: 0.002985  [  480/ 1575]
loss: 0.003593  [  640/ 1575]
loss: 0.003923  [  800/ 1575]
loss: 0.004470  [  960/ 1575]
loss: 0.002581  [ 1120/ 1575]
loss: 0.004283  [ 1280/ 1575]
loss: 0.003311  [ 1440/ 1575]
Test Error: 
MSE: 37.961919
RMSE: 6.161324
MAE: 2.223874
R^2: 0.8813182959176956
loss: 0.004246  [    0/ 1575]
loss: 0.003565  [  160/ 1575]
loss: 0.003300  [  320/ 1575]
loss: 0.003432  [  480/ 1575]
loss: 0.003672  [  640/ 1575]
loss: 0.003555  [  800/ 1575]
loss: 0.003846  [  960/ 1575]
loss: 0.004051  [ 1120/ 1575]
loss: 0.003756  [ 1280/ 1575]
loss: 0.004879  [ 1440/ 1575]
Test Error: 
MSE: 38.964494
RMSE: 6.242155
MAE: 2.238246
R^2: 0.8781839077024065
loss: 0.003154  [    0/ 1575]
loss: 0.002604  [  160/ 1575]
loss: 0.002386  [  320/ 1575]
loss: 0.004379  [  480/ 1575]
loss: 0.003391  [  640/ 1575]
loss: 0.004313  [  800/ 1575]
loss: 0.006384  [  960/ 1575]
loss: 0.003472  [ 1120/ 1575]
loss: 0.005056  [ 1280/ 1575]
loss: 0.003882  [ 1440/ 1575]
Test Error: 
MSE: 36.862150
RMSE: 6.071421
MAE: 2.206930
R^2: 0.8847565419302633
loss: 0.003496  [    0/ 1575]
loss: 0.002462  [  160/ 1575]
loss: 0.002186  [  320/ 1575]
loss: 0.003602  [  480/ 1575]
loss: 0.004212  [  640/ 1575]
loss: 0.002924  [  800/ 1575]
loss: 0.002847  [  960/ 1575]
loss: 0.003022  [ 1120/ 1575]
loss: 0.002223  [ 1280/ 1575]
loss: 0.002762  [ 1440/ 1575]
Test Error: 
MSE: 36.592323
RMSE: 6.049159
MAE: 2.205662
R^2: 0.88560011051864
loss: 0.004364  [    0/ 1575]
loss: 0.003692  [  160/ 1575]
loss: 0.002722  [  320/ 1575]
loss: 0.003783  [  480/ 1575]
loss: 0.002439  [  640/ 1575]
loss: 0.003868  [  800/ 1575]
loss: 0.003495  [  960/ 1575]
loss: 0.003464  [ 1120/ 1575]
loss: 0.003304  [ 1280/ 1575]
loss: 0.003026  [ 1440/ 1575]
Test Error: 
MSE: 36.915577
RMSE: 6.075819
MAE: 2.207022
R^2: 0.8845895095917713
loss: 0.002361  [    0/ 1575]
loss: 0.003861  [  160/ 1575]
loss: 0.003972  [  320/ 1575]
loss: 0.005160  [  480/ 1575]
loss: 0.003457  [  640/ 1575]
loss: 0.003407  [  800/ 1575]
loss: 0.002755  [  960/ 1575]
loss: 0.003869  [ 1120/ 1575]
loss: 0.002842  [ 1280/ 1575]
loss: 0.003552  [ 1440/ 1575]
Test Error: 
MSE: 39.175908
RMSE: 6.259066
MAE: 2.240573
R^2: 0.877522956058073
loss: 0.004936  [    0/ 1575]
loss: 0.002573  [  160/ 1575]
loss: 0.002943  [  320/ 1575]
loss: 0.003204  [  480/ 1575]
loss: 0.003851  [  640/ 1575]
loss: 0.003613  [  800/ 1575]
loss: 0.004261  [  960/ 1575]
loss: 0.003219  [ 1120/ 1575]
loss: 0.002731  [ 1280/ 1575]
loss: 0.002801  [ 1440/ 1575]
Test Error: 
MSE: 35.112642
RMSE: 5.925592
MAE: 2.179852
R^2: 0.8902260910400094
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002556  [    0/ 1575]
loss: 0.003885  [  160/ 1575]
loss: 0.002033  [  320/ 1575]
loss: 0.005072  [  480/ 1575]
loss: 0.002544  [  640/ 1575]
loss: 0.003325  [  800/ 1575]
loss: 0.003799  [  960/ 1575]
loss: 0.004524  [ 1120/ 1575]
loss: 0.003616  [ 1280/ 1575]
loss: 0.001889  [ 1440/ 1575]
Test Error: 
MSE: 45.883267
RMSE: 6.773719
MAE: 2.341830
R^2: 0.8565535019483754
loss: 0.004103  [    0/ 1575]
loss: 0.002928  [  160/ 1575]
loss: 0.003153  [  320/ 1575]
loss: 0.002191  [  480/ 1575]
loss: 0.002380  [  640/ 1575]
loss: 0.001615  [  800/ 1575]
loss: 0.003407  [  960/ 1575]
loss: 0.002325  [ 1120/ 1575]
loss: 0.003656  [ 1280/ 1575]
loss: 0.004608  [ 1440/ 1575]
Test Error: 
MSE: 34.999854
RMSE: 5.916067
MAE: 2.181470
R^2: 0.8905787041576637
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002845  [    0/ 1575]
loss: 0.003380  [  160/ 1575]
loss: 0.003926  [  320/ 1575]
loss: 0.003949  [  480/ 1575]
loss: 0.002687  [  640/ 1575]
loss: 0.002627  [  800/ 1575]
loss: 0.002963  [  960/ 1575]
loss: 0.002967  [ 1120/ 1575]
loss: 0.003912  [ 1280/ 1575]
loss: 0.004281  [ 1440/ 1575]
Test Error: 
MSE: 40.970390
RMSE: 6.400812
MAE: 2.273976
R^2: 0.8719128025314483
loss: 0.003102  [    0/ 1575]
loss: 0.002917  [  160/ 1575]
loss: 0.003535  [  320/ 1575]
loss: 0.003528  [  480/ 1575]
loss: 0.002490  [  640/ 1575]
loss: 0.003052  [  800/ 1575]
loss: 0.003286  [  960/ 1575]
loss: 0.003765  [ 1120/ 1575]
loss: 0.004141  [ 1280/ 1575]
loss: 0.002880  [ 1440/ 1575]
Test Error: 
MSE: 38.184917
RMSE: 6.179395
MAE: 2.225271
R^2: 0.8806211278043734
loss: 0.004690  [    0/ 1575]
loss: 0.002534  [  160/ 1575]
loss: 0.003408  [  320/ 1575]
loss: 0.001455  [  480/ 1575]
loss: 0.003733  [  640/ 1575]
loss: 0.002345  [  800/ 1575]
loss: 0.004056  [  960/ 1575]
loss: 0.004222  [ 1120/ 1575]
loss: 0.001824  [ 1280/ 1575]
loss: 0.005141  [ 1440/ 1575]
Test Error: 
MSE: 35.143826
RMSE: 5.928223
MAE: 2.179132
R^2: 0.8901285999659383
loss: 0.002050  [    0/ 1575]
loss: 0.002431  [  160/ 1575]
loss: 0.001943  [  320/ 1575]
loss: 0.002195  [  480/ 1575]
loss: 0.003119  [  640/ 1575]
loss: 0.005305  [  800/ 1575]
loss: 0.002309  [  960/ 1575]
loss: 0.003584  [ 1120/ 1575]
loss: 0.002110  [ 1280/ 1575]
loss: 0.003244  [ 1440/ 1575]
Test Error: 
MSE: 34.832857
RMSE: 5.901937
MAE: 2.174664
R^2: 0.8911007929580346
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002825  [    0/ 1575]
loss: 0.001732  [  160/ 1575]
loss: 0.002763  [  320/ 1575]
loss: 0.003909  [  480/ 1575]
loss: 0.003258  [  640/ 1575]
loss: 0.003600  [  800/ 1575]
loss: 0.004933  [  960/ 1575]
loss: 0.003850  [ 1120/ 1575]
loss: 0.003795  [ 1280/ 1575]
loss: 0.002764  [ 1440/ 1575]
Test Error: 
MSE: 34.485921
RMSE: 5.872471
MAE: 2.169275
R^2: 0.8921854308035649
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003512  [    0/ 1575]
loss: 0.002485  [  160/ 1575]
loss: 0.003379  [  320/ 1575]
loss: 0.002968  [  480/ 1575]
loss: 0.002265  [  640/ 1575]
loss: 0.002804  [  800/ 1575]
loss: 0.005152  [  960/ 1575]
loss: 0.003603  [ 1120/ 1575]
loss: 0.004333  [ 1280/ 1575]
loss: 0.001813  [ 1440/ 1575]
Test Error: 
MSE: 35.164243
RMSE: 5.929945
MAE: 2.178966
R^2: 0.8900647676131053
loss: 0.003286  [    0/ 1575]
loss: 0.004243  [  160/ 1575]
loss: 0.002588  [  320/ 1575]
loss: 0.002538  [  480/ 1575]
loss: 0.003549  [  640/ 1575]
loss: 0.005769  [  800/ 1575]
loss: 0.004614  [  960/ 1575]
loss: 0.004255  [ 1120/ 1575]
loss: 0.004294  [ 1280/ 1575]
loss: 0.002913  [ 1440/ 1575]
Test Error: 
MSE: 34.013503
RMSE: 5.832110
MAE: 2.163603
R^2: 0.8936623672768005
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004936  [    0/ 1575]
loss: 0.002152  [  160/ 1575]
loss: 0.001687  [  320/ 1575]
loss: 0.002181  [  480/ 1575]
loss: 0.003512  [  640/ 1575]
loss: 0.005024  [  800/ 1575]
loss: 0.002078  [  960/ 1575]
loss: 0.003903  [ 1120/ 1575]
loss: 0.002744  [ 1280/ 1575]
loss: 0.002812  [ 1440/ 1575]
Test Error: 
MSE: 34.046346
RMSE: 5.834925
MAE: 2.163823
R^2: 0.8935596894799179
loss: 0.004213  [    0/ 1575]
loss: 0.004043  [  160/ 1575]
loss: 0.004947  [  320/ 1575]
loss: 0.003665  [  480/ 1575]
loss: 0.001740  [  640/ 1575]
loss: 0.002881  [  800/ 1575]
loss: 0.003001  [  960/ 1575]
loss: 0.002875  [ 1120/ 1575]
loss: 0.005300  [ 1280/ 1575]
loss: 0.003892  [ 1440/ 1575]
Test Error: 
MSE: 35.001379
RMSE: 5.916196
MAE: 2.175548
R^2: 0.8905739372417638
loss: 0.003338  [    0/ 1575]
loss: 0.003705  [  160/ 1575]
loss: 0.003478  [  320/ 1575]
loss: 0.002970  [  480/ 1575]
loss: 0.002591  [  640/ 1575]
loss: 0.004199  [  800/ 1575]
loss: 0.002894  [  960/ 1575]
loss: 0.005127  [ 1120/ 1575]
loss: 0.003304  [ 1280/ 1575]
loss: 0.003827  [ 1440/ 1575]
Test Error: 
MSE: 34.339498
RMSE: 5.859991
MAE: 2.165250
R^2: 0.8926432001513707
loss: 0.003473  [    0/ 1575]
loss: 0.003094  [  160/ 1575]
loss: 0.003190  [  320/ 1575]
loss: 0.003662  [  480/ 1575]
loss: 0.003521  [  640/ 1575]
loss: 0.002924  [  800/ 1575]
loss: 0.001794  [  960/ 1575]
loss: 0.003780  [ 1120/ 1575]
loss: 0.002919  [ 1280/ 1575]
loss: 0.004012  [ 1440/ 1575]
Test Error: 
MSE: 35.206782
RMSE: 5.933530
MAE: 2.179358
R^2: 0.8899317770004207
loss: 0.002477  [    0/ 1575]
loss: 0.003635  [  160/ 1575]
loss: 0.005530  [  320/ 1575]
loss: 0.003786  [  480/ 1575]
loss: 0.004333  [  640/ 1575]
loss: 0.003045  [  800/ 1575]
loss: 0.002624  [  960/ 1575]
loss: 0.003264  [ 1120/ 1575]
loss: 0.001875  [ 1280/ 1575]
loss: 0.001448  [ 1440/ 1575]
Test Error: 
MSE: 34.341237
RMSE: 5.860140
MAE: 2.164553
R^2: 0.8926377608231123
loss: 0.005180  [    0/ 1575]
loss: 0.001914  [  160/ 1575]
loss: 0.001914  [  320/ 1575]
loss: 0.004332  [  480/ 1575]
loss: 0.002926  [  640/ 1575]
loss: 0.003060  [  800/ 1575]
loss: 0.002818  [  960/ 1575]
loss: 0.002483  [ 1120/ 1575]
loss: 0.002690  [ 1280/ 1575]
loss: 0.003849  [ 1440/ 1575]
Test Error: 
MSE: 34.190576
RMSE: 5.847271
MAE: 2.162727
R^2: 0.8931087803644369
loss: 0.003570  [    0/ 1575]
loss: 0.003401  [  160/ 1575]
loss: 0.004226  [  320/ 1575]
loss: 0.002216  [  480/ 1575]
loss: 0.003603  [  640/ 1575]
loss: 0.004049  [  800/ 1575]
loss: 0.003583  [  960/ 1575]
loss: 0.003154  [ 1120/ 1575]
loss: 0.001538  [ 1280/ 1575]
loss: 0.002775  [ 1440/ 1575]
Test Error: 
MSE: 35.776783
RMSE: 5.981370
MAE: 2.190086
R^2: 0.8881497622877752
loss: 0.002925  [    0/ 1575]
loss: 0.002917  [  160/ 1575]
loss: 0.002474  [  320/ 1575]
loss: 0.003358  [  480/ 1575]
loss: 0.004965  [  640/ 1575]
loss: 0.002963  [  800/ 1575]
loss: 0.002308  [  960/ 1575]
loss: 0.003059  [ 1120/ 1575]
loss: 0.002888  [ 1280/ 1575]
loss: 0.003246  [ 1440/ 1575]
Test Error: 
MSE: 34.226847
RMSE: 5.850372
MAE: 2.163112
R^2: 0.8929953845812509
loss: 0.002143  [    0/ 1575]
loss: 0.001819  [  160/ 1575]
loss: 0.002514  [  320/ 1575]
loss: 0.003241  [  480/ 1575]
loss: 0.004492  [  640/ 1575]
loss: 0.001410  [  800/ 1575]
loss: 0.002726  [  960/ 1575]
loss: 0.003318  [ 1120/ 1575]
loss: 0.004154  [ 1280/ 1575]
loss: 0.003684  [ 1440/ 1575]
Test Error: 
MSE: 34.064918
RMSE: 5.836516
MAE: 2.160495
R^2: 0.8935016278898837
loss: 0.003467  [    0/ 1575]
loss: 0.002961  [  160/ 1575]
loss: 0.003783  [  320/ 1575]
loss: 0.002576  [  480/ 1575]
loss: 0.003757  [  640/ 1575]
loss: 0.003848  [  800/ 1575]
loss: 0.003745  [  960/ 1575]
loss: 0.003672  [ 1120/ 1575]
loss: 0.002760  [ 1280/ 1575]
loss: 0.003068  [ 1440/ 1575]
Test Error: 
MSE: 33.593863
RMSE: 5.796021
MAE: 2.154047
R^2: 0.8949743038049378
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002564  [    0/ 1575]
loss: 0.003100  [  160/ 1575]
loss: 0.002444  [  320/ 1575]
loss: 0.002805  [  480/ 1575]
loss: 0.003855  [  640/ 1575]
loss: 0.002645  [  800/ 1575]
loss: 0.003013  [  960/ 1575]
loss: 0.003243  [ 1120/ 1575]
loss: 0.002804  [ 1280/ 1575]
loss: 0.003373  [ 1440/ 1575]
Test Error: 
MSE: 33.325458
RMSE: 5.772821
MAE: 2.150239
R^2: 0.8958134284314908
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003629  [    0/ 1575]
loss: 0.003452  [  160/ 1575]
loss: 0.003050  [  320/ 1575]
loss: 0.003162  [  480/ 1575]
loss: 0.003071  [  640/ 1575]
loss: 0.002634  [  800/ 1575]
loss: 0.003356  [  960/ 1575]
loss: 0.003438  [ 1120/ 1575]
loss: 0.002321  [ 1280/ 1575]
loss: 0.002935  [ 1440/ 1575]
Test Error: 
MSE: 33.418763
RMSE: 5.780896
MAE: 2.150952
R^2: 0.8955217258343589
loss: 0.004579  [    0/ 1575]
loss: 0.001502  [  160/ 1575]
loss: 0.003667  [  320/ 1575]
loss: 0.003745  [  480/ 1575]
loss: 0.003246  [  640/ 1575]
loss: 0.002958  [  800/ 1575]
loss: 0.003416  [  960/ 1575]
loss: 0.003187  [ 1120/ 1575]
loss: 0.002853  [ 1280/ 1575]
loss: 0.004793  [ 1440/ 1575]
Test Error: 
MSE: 34.096619
RMSE: 5.839231
MAE: 2.161161
R^2: 0.893402519055982
loss: 0.003424  [    0/ 1575]
loss: 0.003092  [  160/ 1575]
loss: 0.001952  [  320/ 1575]
loss: 0.003104  [  480/ 1575]
loss: 0.003096  [  640/ 1575]
loss: 0.002752  [  800/ 1575]
loss: 0.003588  [  960/ 1575]
loss: 0.003581  [ 1120/ 1575]
loss: 0.002851  [ 1280/ 1575]
loss: 0.002991  [ 1440/ 1575]
Test Error: 
MSE: 39.285840
RMSE: 6.267842
MAE: 2.253784
R^2: 0.8771792717813904
loss: 0.003446  [    0/ 1575]
loss: 0.003554  [  160/ 1575]
loss: 0.004103  [  320/ 1575]
loss: 0.003311  [  480/ 1575]
loss: 0.001974  [  640/ 1575]
loss: 0.003977  [  800/ 1575]
loss: 0.003843  [  960/ 1575]
loss: 0.002062  [ 1120/ 1575]
loss: 0.002728  [ 1280/ 1575]
loss: 0.001409  [ 1440/ 1575]
Test Error: 
MSE: 38.075786
RMSE: 6.170558
MAE: 2.223472
R^2: 0.8809623079613373
loss: 0.003352  [    0/ 1575]
loss: 0.002487  [  160/ 1575]
loss: 0.002912  [  320/ 1575]
loss: 0.004208  [  480/ 1575]
loss: 0.002491  [  640/ 1575]
loss: 0.001855  [  800/ 1575]
loss: 0.003444  [  960/ 1575]
loss: 0.003511  [ 1120/ 1575]
loss: 0.002653  [ 1280/ 1575]
loss: 0.002619  [ 1440/ 1575]
Test Error: 
MSE: 35.134701
RMSE: 5.927453
MAE: 2.181123
R^2: 0.8901571287980988
loss: 0.002963  [    0/ 1575]
loss: 0.003920  [  160/ 1575]
loss: 0.002456  [  320/ 1575]
loss: 0.002481  [  480/ 1575]
loss: 0.002916  [  640/ 1575]
loss: 0.003141  [  800/ 1575]
loss: 0.001595  [  960/ 1575]
loss: 0.002237  [ 1120/ 1575]
loss: 0.004934  [ 1280/ 1575]
loss: 0.003059  [ 1440/ 1575]
Test Error: 
MSE: 34.833872
RMSE: 5.902023
MAE: 2.173131
R^2: 0.8910976202309748
loss: 0.001923  [    0/ 1575]
loss: 0.003768  [  160/ 1575]
loss: 0.005192  [  320/ 1575]
loss: 0.003680  [  480/ 1575]
loss: 0.003611  [  640/ 1575]
loss: 0.002886  [  800/ 1575]
loss: 0.003007  [  960/ 1575]
loss: 0.002445  [ 1120/ 1575]
loss: 0.002731  [ 1280/ 1575]
loss: 0.002711  [ 1440/ 1575]
Test Error: 
MSE: 35.291315
RMSE: 5.940649
MAE: 2.179757
R^2: 0.8896674982333709
loss: 0.006418  [    0/ 1575]
loss: 0.002669  [  160/ 1575]
loss: 0.001930  [  320/ 1575]
loss: 0.003558  [  480/ 1575]
loss: 0.003143  [  640/ 1575]
loss: 0.002627  [  800/ 1575]
loss: 0.002895  [  960/ 1575]
loss: 0.002191  [ 1120/ 1575]
loss: 0.002558  [ 1280/ 1575]
loss: 0.002531  [ 1440/ 1575]
Test Error: 
MSE: 32.766368
RMSE: 5.724191
MAE: 2.139789
R^2: 0.897561332767598
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003482  [    0/ 1575]
loss: 0.003085  [  160/ 1575]
loss: 0.003221  [  320/ 1575]
loss: 0.004102  [  480/ 1575]
loss: 0.003905  [  640/ 1575]
loss: 0.003208  [  800/ 1575]
loss: 0.002898  [  960/ 1575]
loss: 0.004251  [ 1120/ 1575]
loss: 0.002661  [ 1280/ 1575]
loss: 0.002037  [ 1440/ 1575]
Test Error: 
MSE: 32.715060
RMSE: 5.719708
MAE: 2.138847
R^2: 0.8977217376604815
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004473  [    0/ 1575]
loss: 0.004578  [  160/ 1575]
loss: 0.002607  [  320/ 1575]
loss: 0.002394  [  480/ 1575]
loss: 0.003184  [  640/ 1575]
loss: 0.003189  [  800/ 1575]
loss: 0.003773  [  960/ 1575]
loss: 0.002957  [ 1120/ 1575]
loss: 0.002237  [ 1280/ 1575]
loss: 0.001549  [ 1440/ 1575]
Test Error: 
MSE: 34.430314
RMSE: 5.867735
MAE: 2.169637
R^2: 0.8923592783663004
loss: 0.003537  [    0/ 1575]
loss: 0.002020  [  160/ 1575]
loss: 0.002867  [  320/ 1575]
loss: 0.002525  [  480/ 1575]
loss: 0.002793  [  640/ 1575]
loss: 0.002474  [  800/ 1575]
loss: 0.003891  [  960/ 1575]
loss: 0.003161  [ 1120/ 1575]
loss: 0.002170  [ 1280/ 1575]
loss: 0.003060  [ 1440/ 1575]
Test Error: 
MSE: 32.981306
RMSE: 5.742935
MAE: 2.142212
R^2: 0.8968893621379045
loss: 0.003381  [    0/ 1575]
loss: 0.004237  [  160/ 1575]
loss: 0.003827  [  320/ 1575]
loss: 0.003400  [  480/ 1575]
loss: 0.002794  [  640/ 1575]
loss: 0.004529  [  800/ 1575]
loss: 0.002228  [  960/ 1575]
loss: 0.002068  [ 1120/ 1575]
loss: 0.002142  [ 1280/ 1575]
loss: 0.003885  [ 1440/ 1575]
Test Error: 
MSE: 34.592984
RMSE: 5.881580
MAE: 2.173571
R^2: 0.8918507162336466
loss: 0.002548  [    0/ 1575]
loss: 0.003671  [  160/ 1575]
loss: 0.003018  [  320/ 1575]
loss: 0.002438  [  480/ 1575]
loss: 0.001895  [  640/ 1575]
loss: 0.002427  [  800/ 1575]
loss: 0.001789  [  960/ 1575]
loss: 0.002704  [ 1120/ 1575]
loss: 0.002704  [ 1280/ 1575]
loss: 0.003759  [ 1440/ 1575]
Test Error: 
MSE: 37.820774
RMSE: 6.149860
MAE: 2.232529
R^2: 0.8817595600426092
loss: 0.003944  [    0/ 1575]
loss: 0.002283  [  160/ 1575]
loss: 0.003871  [  320/ 1575]
loss: 0.001394  [  480/ 1575]
loss: 0.003029  [  640/ 1575]
loss: 0.003433  [  800/ 1575]
loss: 0.003475  [  960/ 1575]
loss: 0.003434  [ 1120/ 1575]
loss: 0.004365  [ 1280/ 1575]
loss: 0.001706  [ 1440/ 1575]
Test Error: 
MSE: 32.549103
RMSE: 5.705182
MAE: 2.135542
R^2: 0.8982405739261743
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003914  [    0/ 1575]
loss: 0.002992  [  160/ 1575]
loss: 0.002221  [  320/ 1575]
loss: 0.003290  [  480/ 1575]
loss: 0.002942  [  640/ 1575]
loss: 0.002485  [  800/ 1575]
loss: 0.002477  [  960/ 1575]
loss: 0.003490  [ 1120/ 1575]
loss: 0.003696  [ 1280/ 1575]
loss: 0.003278  [ 1440/ 1575]
Test Error: 
MSE: 32.361975
RMSE: 5.688759
MAE: 2.132262
R^2: 0.8988255992532537
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003439  [    0/ 1575]
loss: 0.004348  [  160/ 1575]
loss: 0.004062  [  320/ 1575]
loss: 0.002572  [  480/ 1575]
loss: 0.004273  [  640/ 1575]
loss: 0.002566  [  800/ 1575]
loss: 0.002355  [  960/ 1575]
loss: 0.002690  [ 1120/ 1575]
loss: 0.002736  [ 1280/ 1575]
loss: 0.002640  [ 1440/ 1575]
Test Error: 
MSE: 47.189952
RMSE: 6.869494
MAE: 2.361720
R^2: 0.8524683660012451
loss: 0.002071  [    0/ 1575]
loss: 0.003787  [  160/ 1575]
loss: 0.005276  [  320/ 1575]
loss: 0.002247  [  480/ 1575]
loss: 0.002121  [  640/ 1575]
loss: 0.003325  [  800/ 1575]
loss: 0.003402  [  960/ 1575]
loss: 0.003124  [ 1120/ 1575]
loss: 0.002346  [ 1280/ 1575]
loss: 0.003697  [ 1440/ 1575]
Test Error: 
MSE: 32.339993
RMSE: 5.686826
MAE: 2.131618
R^2: 0.8988943222947351
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002132  [    0/ 1575]
loss: 0.003376  [  160/ 1575]
loss: 0.002810  [  320/ 1575]
loss: 0.005229  [  480/ 1575]
loss: 0.002205  [  640/ 1575]
loss: 0.003394  [  800/ 1575]
loss: 0.004252  [  960/ 1575]
loss: 0.002890  [ 1120/ 1575]
loss: 0.002861  [ 1280/ 1575]
loss: 0.003435  [ 1440/ 1575]
Test Error: 
MSE: 32.709331
RMSE: 5.719207
MAE: 2.138183
R^2: 0.8977396487982375
loss: 0.003346  [    0/ 1575]
loss: 0.003063  [  160/ 1575]
loss: 0.003521  [  320/ 1575]
loss: 0.002229  [  480/ 1575]
loss: 0.004155  [  640/ 1575]
loss: 0.003526  [  800/ 1575]
loss: 0.004006  [  960/ 1575]
loss: 0.002237  [ 1120/ 1575]
loss: 0.004227  [ 1280/ 1575]
loss: 0.003443  [ 1440/ 1575]
Test Error: 
MSE: 33.463244
RMSE: 5.784742
MAE: 2.153707
R^2: 0.8953826624432538
loss: 0.002879  [    0/ 1575]
loss: 0.003277  [  160/ 1575]
loss: 0.002919  [  320/ 1575]
loss: 0.004270  [  480/ 1575]
loss: 0.003762  [  640/ 1575]
loss: 0.002124  [  800/ 1575]
loss: 0.001939  [  960/ 1575]
loss: 0.002541  [ 1120/ 1575]
loss: 0.002912  [ 1280/ 1575]
loss: 0.001680  [ 1440/ 1575]
Test Error: 
MSE: 36.164632
RMSE: 6.013704
MAE: 2.204805
R^2: 0.8869372158620891
loss: 0.001824  [    0/ 1575]
loss: 0.003189  [  160/ 1575]
loss: 0.003090  [  320/ 1575]
loss: 0.002749  [  480/ 1575]
loss: 0.003906  [  640/ 1575]
loss: 0.002940  [  800/ 1575]
loss: 0.002063  [  960/ 1575]
loss: 0.002989  [ 1120/ 1575]
loss: 0.003199  [ 1280/ 1575]
loss: 0.003532  [ 1440/ 1575]
Test Error: 
MSE: 38.683903
RMSE: 6.219638
MAE: 2.230206
R^2: 0.8790611305136701
loss: 0.004640  [    0/ 1575]
loss: 0.006298  [  160/ 1575]
loss: 0.003706  [  320/ 1575]
loss: 0.003749  [  480/ 1575]
loss: 0.002319  [  640/ 1575]
loss: 0.002731  [  800/ 1575]
loss: 0.002432  [  960/ 1575]
loss: 0.004284  [ 1120/ 1575]
loss: 0.002367  [ 1280/ 1575]
loss: 0.002508  [ 1440/ 1575]
Test Error: 
MSE: 34.718510
RMSE: 5.892242
MAE: 2.178711
R^2: 0.8914582800305512
loss: 0.003871  [    0/ 1575]
loss: 0.002483  [  160/ 1575]
loss: 0.003209  [  320/ 1575]
loss: 0.002538  [  480/ 1575]
loss: 0.003045  [  640/ 1575]
loss: 0.003690  [  800/ 1575]
loss: 0.003442  [  960/ 1575]
loss: 0.003930  [ 1120/ 1575]
loss: 0.003477  [ 1280/ 1575]
loss: 0.002610  [ 1440/ 1575]
Test Error: 
MSE: 35.325928
RMSE: 5.943562
MAE: 2.190148
R^2: 0.8895592862349277
loss: 0.002482  [    0/ 1575]
loss: 0.003496  [  160/ 1575]
loss: 0.003708  [  320/ 1575]
loss: 0.003396  [  480/ 1575]
loss: 0.002036  [  640/ 1575]
loss: 0.002642  [  800/ 1575]
loss: 0.003554  [  960/ 1575]
loss: 0.003906  [ 1120/ 1575]
loss: 0.003253  [ 1280/ 1575]
loss: 0.004809  [ 1440/ 1575]
Test Error: 
MSE: 31.862951
RMSE: 5.644728
MAE: 2.122045
R^2: 0.9003857176205811
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003945  [    0/ 1575]
loss: 0.002368  [  160/ 1575]
loss: 0.002242  [  320/ 1575]
loss: 0.003370  [  480/ 1575]
loss: 0.002338  [  640/ 1575]
loss: 0.001987  [  800/ 1575]
loss: 0.003511  [  960/ 1575]
loss: 0.003209  [ 1120/ 1575]
loss: 0.004069  [ 1280/ 1575]
loss: 0.004769  [ 1440/ 1575]
Test Error: 
MSE: 67.942961
RMSE: 8.242752
MAE: 2.632582
R^2: 0.7875874888301729
loss: 0.003191  [    0/ 1575]
loss: 0.002782  [  160/ 1575]
loss: 0.003261  [  320/ 1575]
loss: 0.001660  [  480/ 1575]
loss: 0.004403  [  640/ 1575]
loss: 0.003177  [  800/ 1575]
loss: 0.003235  [  960/ 1575]
loss: 0.003806  [ 1120/ 1575]
loss: 0.003585  [ 1280/ 1575]
loss: 0.002992  [ 1440/ 1575]
Test Error: 
MSE: 31.782642
RMSE: 5.637610
MAE: 2.120911
R^2: 0.900636790593696
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003322  [    0/ 1575]
loss: 0.003784  [  160/ 1575]
loss: 0.002733  [  320/ 1575]
loss: 0.002161  [  480/ 1575]
loss: 0.003113  [  640/ 1575]
loss: 0.002149  [  800/ 1575]
loss: 0.003426  [  960/ 1575]
loss: 0.002918  [ 1120/ 1575]
loss: 0.002444  [ 1280/ 1575]
loss: 0.002407  [ 1440/ 1575]
Test Error: 
MSE: 31.976297
RMSE: 5.654759
MAE: 2.121933
R^2: 0.9000313600744017
loss: 0.002296  [    0/ 1575]
loss: 0.002883  [  160/ 1575]
loss: 0.003247  [  320/ 1575]
loss: 0.004668  [  480/ 1575]
loss: 0.003219  [  640/ 1575]
loss: 0.004512  [  800/ 1575]
loss: 0.002257  [  960/ 1575]
loss: 0.003081  [ 1120/ 1575]
loss: 0.003052  [ 1280/ 1575]
loss: 0.002446  [ 1440/ 1575]
Test Error: 
MSE: 34.356187
RMSE: 5.861415
MAE: 2.173784
R^2: 0.8925910230323125
loss: 0.002426  [    0/ 1575]
loss: 0.006117  [  160/ 1575]
loss: 0.002710  [  320/ 1575]
loss: 0.002424  [  480/ 1575]
loss: 0.003861  [  640/ 1575]
loss: 0.003714  [  800/ 1575]
loss: 0.002680  [  960/ 1575]
loss: 0.004009  [ 1120/ 1575]
loss: 0.002728  [ 1280/ 1575]
loss: 0.003416  [ 1440/ 1575]
Test Error: 
MSE: 31.526319
RMSE: 5.614830
MAE: 2.115155
R^2: 0.901438141359875
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004367  [    0/ 1575]
loss: 0.001871  [  160/ 1575]
loss: 0.002151  [  320/ 1575]
loss: 0.002762  [  480/ 1575]
loss: 0.003234  [  640/ 1575]
loss: 0.003681  [  800/ 1575]
loss: 0.003225  [  960/ 1575]
loss: 0.003097  [ 1120/ 1575]
loss: 0.002777  [ 1280/ 1575]
loss: 0.002079  [ 1440/ 1575]
Test Error: 
MSE: 31.499617
RMSE: 5.612452
MAE: 2.113581
R^2: 0.9015216194068205
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004105  [    0/ 1575]
loss: 0.002429  [  160/ 1575]
loss: 0.003584  [  320/ 1575]
loss: 0.002564  [  480/ 1575]
loss: 0.002919  [  640/ 1575]
loss: 0.002564  [  800/ 1575]
loss: 0.002858  [  960/ 1575]
loss: 0.002375  [ 1120/ 1575]
loss: 0.003115  [ 1280/ 1575]
loss: 0.002590  [ 1440/ 1575]
Test Error: 
MSE: 32.292114
RMSE: 5.682615
MAE: 2.133488
R^2: 0.8990440100474376
loss: 0.003748  [    0/ 1575]
loss: 0.003939  [  160/ 1575]
loss: 0.002849  [  320/ 1575]
loss: 0.002803  [  480/ 1575]
loss: 0.002770  [  640/ 1575]
loss: 0.001610  [  800/ 1575]
loss: 0.003593  [  960/ 1575]
loss: 0.003512  [ 1120/ 1575]
loss: 0.002997  [ 1280/ 1575]
loss: 0.004307  [ 1440/ 1575]
Test Error: 
MSE: 31.414565
RMSE: 5.604870
MAE: 2.113212
R^2: 0.901787521124287
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002818  [    0/ 1575]
loss: 0.004057  [  160/ 1575]
loss: 0.002633  [  320/ 1575]
loss: 0.002959  [  480/ 1575]
loss: 0.002667  [  640/ 1575]
loss: 0.003161  [  800/ 1575]
loss: 0.003225  [  960/ 1575]
loss: 0.003726  [ 1120/ 1575]
loss: 0.003841  [ 1280/ 1575]
loss: 0.002505  [ 1440/ 1575]
Test Error: 
MSE: 31.368078
RMSE: 5.600721
MAE: 2.111750
R^2: 0.9019328565638359
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002614  [    0/ 1575]
loss: 0.003976  [  160/ 1575]
loss: 0.002206  [  320/ 1575]
loss: 0.001757  [  480/ 1575]
loss: 0.003876  [  640/ 1575]
loss: 0.003296  [  800/ 1575]
loss: 0.002231  [  960/ 1575]
loss: 0.003275  [ 1120/ 1575]
loss: 0.003659  [ 1280/ 1575]
loss: 0.003219  [ 1440/ 1575]
Test Error: 
MSE: 31.802068
RMSE: 5.639332
MAE: 2.122649
R^2: 0.9005760578166948
loss: 0.001888  [    0/ 1575]
loss: 0.003962  [  160/ 1575]
loss: 0.002004  [  320/ 1575]
loss: 0.004283  [  480/ 1575]
loss: 0.004670  [  640/ 1575]
loss: 0.001607  [  800/ 1575]
loss: 0.001995  [  960/ 1575]
loss: 0.001431  [ 1120/ 1575]
loss: 0.003377  [ 1280/ 1575]
loss: 0.003726  [ 1440/ 1575]
Test Error: 
MSE: 34.195840
RMSE: 5.847721
MAE: 2.171747
R^2: 0.8930923216148964
loss: 0.003005  [    0/ 1575]
loss: 0.002580  [  160/ 1575]
loss: 0.003425  [  320/ 1575]
loss: 0.003206  [  480/ 1575]
loss: 0.001707  [  640/ 1575]
loss: 0.002807  [  800/ 1575]
loss: 0.003504  [  960/ 1575]
loss: 0.002406  [ 1120/ 1575]
loss: 0.004180  [ 1280/ 1575]
loss: 0.002535  [ 1440/ 1575]
Test Error: 
MSE: 36.137721
RMSE: 6.011466
MAE: 2.208617
R^2: 0.8870213510373707
loss: 0.003489  [    0/ 1575]
loss: 0.002768  [  160/ 1575]
loss: 0.002117  [  320/ 1575]
loss: 0.001814  [  480/ 1575]
loss: 0.002055  [  640/ 1575]
loss: 0.004699  [  800/ 1575]
loss: 0.002329  [  960/ 1575]
loss: 0.002287  [ 1120/ 1575]
loss: 0.002343  [ 1280/ 1575]
loss: 0.003111  [ 1440/ 1575]
Test Error: 
MSE: 31.999875
RMSE: 5.656843
MAE: 2.128239
R^2: 0.8999576463073431
loss: 0.003842  [    0/ 1575]
loss: 0.002551  [  160/ 1575]
loss: 0.003660  [  320/ 1575]
loss: 0.003566  [  480/ 1575]
loss: 0.003316  [  640/ 1575]
loss: 0.005713  [  800/ 1575]
loss: 0.002959  [  960/ 1575]
loss: 0.002468  [ 1120/ 1575]
loss: 0.004889  [ 1280/ 1575]
loss: 0.006349  [ 1440/ 1575]
Test Error: 
MSE: 38.845537
RMSE: 6.232619
MAE: 2.232182
R^2: 0.878555807355895
loss: 0.003754  [    0/ 1575]
loss: 0.002654  [  160/ 1575]
loss: 0.003401  [  320/ 1575]
loss: 0.003933  [  480/ 1575]
loss: 0.002885  [  640/ 1575]
loss: 0.001968  [  800/ 1575]
loss: 0.002899  [  960/ 1575]
loss: 0.001886  [ 1120/ 1575]
loss: 0.003266  [ 1280/ 1575]
loss: 0.002623  [ 1440/ 1575]
Test Error: 
MSE: 31.415174
RMSE: 5.604924
MAE: 2.110237
R^2: 0.9017856172458776
loss: 0.003280  [    0/ 1575]
loss: 0.001757  [  160/ 1575]
loss: 0.002236  [  320/ 1575]
loss: 0.003056  [  480/ 1575]
loss: 0.002399  [  640/ 1575]
loss: 0.001472  [  800/ 1575]
loss: 0.003033  [  960/ 1575]
loss: 0.003589  [ 1120/ 1575]
loss: 0.003148  [ 1280/ 1575]
loss: 0.003054  [ 1440/ 1575]
Test Error: 
MSE: 42.953206
RMSE: 6.553870
MAE: 2.307748
R^2: 0.8657138542102205
loss: 0.002889  [    0/ 1575]
loss: 0.002924  [  160/ 1575]
loss: 0.003306  [  320/ 1575]
loss: 0.001089  [  480/ 1575]
loss: 0.003518  [  640/ 1575]
loss: 0.003273  [  800/ 1575]
loss: 0.003197  [  960/ 1575]
loss: 0.001264  [ 1120/ 1575]
loss: 0.002588  [ 1280/ 1575]
loss: 0.003304  [ 1440/ 1575]
Test Error: 
MSE: 32.851264
RMSE: 5.731602
MAE: 2.147113
R^2: 0.897295919552136
loss: 0.002704  [    0/ 1575]
loss: 0.002950  [  160/ 1575]
loss: 0.002037  [  320/ 1575]
loss: 0.003190  [  480/ 1575]
loss: 0.002618  [  640/ 1575]
loss: 0.003061  [  800/ 1575]
loss: 0.003463  [  960/ 1575]
loss: 0.002851  [ 1120/ 1575]
loss: 0.002392  [ 1280/ 1575]
loss: 0.002414  [ 1440/ 1575]
Test Error: 
MSE: 38.027007
RMSE: 6.166604
MAE: 2.239350
R^2: 0.8811148068273181
loss: 0.002843  [    0/ 1575]
loss: 0.002419  [  160/ 1575]
loss: 0.002952  [  320/ 1575]
loss: 0.001560  [  480/ 1575]
loss: 0.002172  [  640/ 1575]
loss: 0.002280  [  800/ 1575]
loss: 0.003798  [  960/ 1575]
loss: 0.001755  [ 1120/ 1575]
loss: 0.003206  [ 1280/ 1575]
loss: 0.005496  [ 1440/ 1575]
Test Error: 
MSE: 31.288412
RMSE: 5.593605
MAE: 2.112556
R^2: 0.9021819191994239
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003597  [    0/ 1575]
loss: 0.002975  [  160/ 1575]
loss: 0.002823  [  320/ 1575]
loss: 0.002810  [  480/ 1575]
loss: 0.002681  [  640/ 1575]
loss: 0.003044  [  800/ 1575]
loss: 0.002351  [  960/ 1575]
loss: 0.002439  [ 1120/ 1575]
loss: 0.003691  [ 1280/ 1575]
loss: 0.002084  [ 1440/ 1575]
Test Error: 
MSE: 31.013473
RMSE: 5.568974
MAE: 2.105484
R^2: 0.903041470778761
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.001985  [    0/ 1575]
loss: 0.001997  [  160/ 1575]
loss: 0.002688  [  320/ 1575]
loss: 0.003935  [  480/ 1575]
loss: 0.001776  [  640/ 1575]
loss: 0.002746  [  800/ 1575]
loss: 0.001533  [  960/ 1575]
loss: 0.002512  [ 1120/ 1575]
loss: 0.001524  [ 1280/ 1575]
loss: 0.002368  [ 1440/ 1575]
Test Error: 
MSE: 33.305895
RMSE: 5.771126
MAE: 2.142693
R^2: 0.8958745878466771
loss: 0.004000  [    0/ 1575]
loss: 0.002541  [  160/ 1575]
loss: 0.003501  [  320/ 1575]
loss: 0.004396  [  480/ 1575]
loss: 0.003142  [  640/ 1575]
loss: 0.002372  [  800/ 1575]
loss: 0.002443  [  960/ 1575]
loss: 0.003119  [ 1120/ 1575]
loss: 0.003184  [ 1280/ 1575]
loss: 0.002279  [ 1440/ 1575]
Test Error: 
MSE: 34.986829
RMSE: 5.914966
MAE: 2.188997
R^2: 0.8906194258954654
loss: 0.002790  [    0/ 1575]
loss: 0.003089  [  160/ 1575]
loss: 0.002093  [  320/ 1575]
loss: 0.002171  [  480/ 1575]
loss: 0.002128  [  640/ 1575]
loss: 0.003163  [  800/ 1575]
loss: 0.003046  [  960/ 1575]
loss: 0.003220  [ 1120/ 1575]
loss: 0.003128  [ 1280/ 1575]
loss: 0.003714  [ 1440/ 1575]
Test Error: 
MSE: 31.514961
RMSE: 5.613819
MAE: 2.111382
R^2: 0.9014736502025794
loss: 0.003008  [    0/ 1575]
loss: 0.002724  [  160/ 1575]
loss: 0.001367  [  320/ 1575]
loss: 0.002221  [  480/ 1575]
loss: 0.002512  [  640/ 1575]
loss: 0.001977  [  800/ 1575]
loss: 0.004133  [  960/ 1575]
loss: 0.003546  [ 1120/ 1575]
loss: 0.003235  [ 1280/ 1575]
loss: 0.002329  [ 1440/ 1575]
Test Error: 
MSE: 32.545910
RMSE: 5.704902
MAE: 2.141796
R^2: 0.8982505556941668
loss: 0.003150  [    0/ 1575]
loss: 0.002629  [  160/ 1575]
loss: 0.001983  [  320/ 1575]
loss: 0.003629  [  480/ 1575]
loss: 0.002122  [  640/ 1575]
loss: 0.002689  [  800/ 1575]
loss: 0.002986  [  960/ 1575]
loss: 0.003588  [ 1120/ 1575]
loss: 0.001938  [ 1280/ 1575]
loss: 0.002654  [ 1440/ 1575]
Test Error: 
MSE: 32.942891
RMSE: 5.739590
MAE: 2.136254
R^2: 0.8970094597116822
loss: 0.003798  [    0/ 1575]
loss: 0.003549  [  160/ 1575]
loss: 0.002403  [  320/ 1575]
loss: 0.002922  [  480/ 1575]
loss: 0.003523  [  640/ 1575]
loss: 0.002600  [  800/ 1575]
loss: 0.003699  [  960/ 1575]
loss: 0.005105  [ 1120/ 1575]
loss: 0.003988  [ 1280/ 1575]
loss: 0.002889  [ 1440/ 1575]
Test Error: 
MSE: 30.794791
RMSE: 5.549305
MAE: 2.101261
R^2: 0.9037251443403689
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003247  [    0/ 1575]
loss: 0.003245  [  160/ 1575]
loss: 0.001445  [  320/ 1575]
loss: 0.002191  [  480/ 1575]
loss: 0.003631  [  640/ 1575]
loss: 0.002196  [  800/ 1575]
loss: 0.002111  [  960/ 1575]
loss: 0.003231  [ 1120/ 1575]
loss: 0.002815  [ 1280/ 1575]
loss: 0.003515  [ 1440/ 1575]
Test Error: 
MSE: 37.810044
RMSE: 6.148987
MAE: 2.236850
R^2: 0.881793105536386
loss: 0.002179  [    0/ 1575]
loss: 0.002287  [  160/ 1575]
loss: 0.002296  [  320/ 1575]
loss: 0.003410  [  480/ 1575]
loss: 0.003890  [  640/ 1575]
loss: 0.002531  [  800/ 1575]
loss: 0.002293  [  960/ 1575]
loss: 0.001631  [ 1120/ 1575]
loss: 0.002384  [ 1280/ 1575]
loss: 0.003321  [ 1440/ 1575]
Test Error: 
MSE: 32.397990
RMSE: 5.691923
MAE: 2.127751
R^2: 0.8987130040829215
loss: 0.002802  [    0/ 1575]
loss: 0.002615  [  160/ 1575]
loss: 0.002355  [  320/ 1575]
loss: 0.003620  [  480/ 1575]
loss: 0.004056  [  640/ 1575]
loss: 0.003373  [  800/ 1575]
loss: 0.003041  [  960/ 1575]
loss: 0.002186  [ 1120/ 1575]
loss: 0.002907  [ 1280/ 1575]
loss: 0.001906  [ 1440/ 1575]
Test Error: 
MSE: 30.632644
RMSE: 5.534676
MAE: 2.097676
R^2: 0.9042320700844563
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002034  [    0/ 1575]
loss: 0.003192  [  160/ 1575]
loss: 0.003448  [  320/ 1575]
loss: 0.004702  [  480/ 1575]
loss: 0.001438  [  640/ 1575]
loss: 0.002941  [  800/ 1575]
loss: 0.004303  [  960/ 1575]
loss: 0.002586  [ 1120/ 1575]
loss: 0.002088  [ 1280/ 1575]
loss: 0.002949  [ 1440/ 1575]
Test Error: 
MSE: 31.274226
RMSE: 5.592336
MAE: 2.106882
R^2: 0.9022262677453451
loss: 0.002641  [    0/ 1575]
loss: 0.003761  [  160/ 1575]
loss: 0.003950  [  320/ 1575]
loss: 0.001963  [  480/ 1575]
loss: 0.002684  [  640/ 1575]
loss: 0.003864  [  800/ 1575]
loss: 0.002947  [  960/ 1575]
loss: 0.002660  [ 1120/ 1575]
loss: 0.004167  [ 1280/ 1575]
loss: 0.003881  [ 1440/ 1575]
Test Error: 
MSE: 31.205180
RMSE: 5.586160
MAE: 2.105621
R^2: 0.9024421298387701
loss: 0.003120  [    0/ 1575]
loss: 0.003244  [  160/ 1575]
loss: 0.003889  [  320/ 1575]
loss: 0.002273  [  480/ 1575]
loss: 0.002606  [  640/ 1575]
loss: 0.004681  [  800/ 1575]
loss: 0.003493  [  960/ 1575]
loss: 0.001729  [ 1120/ 1575]
loss: 0.003007  [ 1280/ 1575]
loss: 0.002280  [ 1440/ 1575]
Test Error: 
MSE: 30.525376
RMSE: 5.524977
MAE: 2.095997
R^2: 0.904567425515195
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002124  [    0/ 1575]
loss: 0.002057  [  160/ 1575]
loss: 0.002372  [  320/ 1575]
loss: 0.003073  [  480/ 1575]
loss: 0.002889  [  640/ 1575]
loss: 0.003430  [  800/ 1575]
loss: 0.002080  [  960/ 1575]
loss: 0.002907  [ 1120/ 1575]
loss: 0.003669  [ 1280/ 1575]
loss: 0.003292  [ 1440/ 1575]
Test Error: 
MSE: 53.375736
RMSE: 7.305870
MAE: 2.456308
R^2: 0.833129528383183
loss: 0.004771  [    0/ 1575]
loss: 0.002306  [  160/ 1575]
loss: 0.003860  [  320/ 1575]
loss: 0.003301  [  480/ 1575]
loss: 0.002387  [  640/ 1575]
loss: 0.002392  [  800/ 1575]
loss: 0.002648  [  960/ 1575]
loss: 0.005189  [ 1120/ 1575]
loss: 0.002774  [ 1280/ 1575]
loss: 0.002017  [ 1440/ 1575]
Test Error: 
MSE: 30.964347
RMSE: 5.564562
MAE: 2.109179
R^2: 0.9031950538433335
loss: 0.002088  [    0/ 1575]
loss: 0.003638  [  160/ 1575]
loss: 0.002492  [  320/ 1575]
loss: 0.002965  [  480/ 1575]
loss: 0.003258  [  640/ 1575]
loss: 0.003430  [  800/ 1575]
loss: 0.003157  [  960/ 1575]
loss: 0.002658  [ 1120/ 1575]
loss: 0.001785  [ 1280/ 1575]
loss: 0.003341  [ 1440/ 1575]
Test Error: 
MSE: 30.937885
RMSE: 5.562183
MAE: 2.108739
R^2: 0.9032777834294283
loss: 0.002227  [    0/ 1575]
loss: 0.004460  [  160/ 1575]
loss: 0.003250  [  320/ 1575]
loss: 0.004408  [  480/ 1575]
loss: 0.002687  [  640/ 1575]
loss: 0.004119  [  800/ 1575]
loss: 0.003546  [  960/ 1575]
loss: 0.002703  [ 1120/ 1575]
loss: 0.002319  [ 1280/ 1575]
loss: 0.002376  [ 1440/ 1575]
Test Error: 
MSE: 31.523904
RMSE: 5.614615
MAE: 2.122525
R^2: 0.9014456921842208
loss: 0.002846  [    0/ 1575]
loss: 0.003363  [  160/ 1575]
loss: 0.002479  [  320/ 1575]
loss: 0.002537  [  480/ 1575]
loss: 0.004203  [  640/ 1575]
loss: 0.002377  [  800/ 1575]
loss: 0.002122  [  960/ 1575]
loss: 0.002186  [ 1120/ 1575]
loss: 0.003871  [ 1280/ 1575]
loss: 0.003732  [ 1440/ 1575]
Test Error: 
MSE: 30.292707
RMSE: 5.503881
MAE: 2.087860
R^2: 0.9052948259334916
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003301  [    0/ 1575]
loss: 0.003554  [  160/ 1575]
loss: 0.001771  [  320/ 1575]
loss: 0.003032  [  480/ 1575]
loss: 0.002459  [  640/ 1575]
loss: 0.003877  [  800/ 1575]
loss: 0.004777  [  960/ 1575]
loss: 0.002914  [ 1120/ 1575]
loss: 0.003348  [ 1280/ 1575]
loss: 0.002228  [ 1440/ 1575]
Test Error: 
MSE: 30.880896
RMSE: 5.557058
MAE: 2.098743
R^2: 0.9034559515525822
loss: 0.002691  [    0/ 1575]
loss: 0.002630  [  160/ 1575]
loss: 0.001874  [  320/ 1575]
loss: 0.002860  [  480/ 1575]
loss: 0.002075  [  640/ 1575]
loss: 0.001978  [  800/ 1575]
loss: 0.003091  [  960/ 1575]
loss: 0.002440  [ 1120/ 1575]
loss: 0.004065  [ 1280/ 1575]
loss: 0.003183  [ 1440/ 1575]
Test Error: 
MSE: 31.421463
RMSE: 5.605485
MAE: 2.120613
R^2: 0.9017659567731284
loss: 0.002837  [    0/ 1575]
loss: 0.002638  [  160/ 1575]
loss: 0.004021  [  320/ 1575]
loss: 0.002014  [  480/ 1575]
loss: 0.002809  [  640/ 1575]
loss: 0.003486  [  800/ 1575]
loss: 0.002903  [  960/ 1575]
loss: 0.002514  [ 1120/ 1575]
loss: 0.002701  [ 1280/ 1575]
loss: 0.002180  [ 1440/ 1575]
Test Error: 
MSE: 30.242624
RMSE: 5.499329
MAE: 2.090611
R^2: 0.9054514016305303
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003560  [    0/ 1575]
loss: 0.002164  [  160/ 1575]
loss: 0.002896  [  320/ 1575]
loss: 0.002400  [  480/ 1575]
loss: 0.002467  [  640/ 1575]
loss: 0.003166  [  800/ 1575]
loss: 0.003325  [  960/ 1575]
loss: 0.001729  [ 1120/ 1575]
loss: 0.003960  [ 1280/ 1575]
loss: 0.004142  [ 1440/ 1575]
Test Error: 
MSE: 30.344733
RMSE: 5.508605
MAE: 2.094552
R^2: 0.9051321757551571
loss: 0.004846  [    0/ 1575]
loss: 0.003016  [  160/ 1575]
loss: 0.001839  [  320/ 1575]
loss: 0.003604  [  480/ 1575]
loss: 0.002128  [  640/ 1575]
loss: 0.002683  [  800/ 1575]
loss: 0.002605  [  960/ 1575]
loss: 0.001647  [ 1120/ 1575]
loss: 0.002407  [ 1280/ 1575]
loss: 0.001613  [ 1440/ 1575]
Test Error: 
MSE: 34.019735
RMSE: 5.832644
MAE: 2.174289
R^2: 0.8936428852157954
loss: 0.003544  [    0/ 1575]
loss: 0.003997  [  160/ 1575]
loss: 0.003043  [  320/ 1575]
loss: 0.002330  [  480/ 1575]
loss: 0.004250  [  640/ 1575]
loss: 0.002657  [  800/ 1575]
loss: 0.001878  [  960/ 1575]
loss: 0.003797  [ 1120/ 1575]
loss: 0.002521  [ 1280/ 1575]
loss: 0.002021  [ 1440/ 1575]
Test Error: 
MSE: 30.044293
RMSE: 5.481267
MAE: 2.083548
R^2: 0.9060714531558179
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004179  [    0/ 1575]
loss: 0.003051  [  160/ 1575]
loss: 0.002184  [  320/ 1575]
loss: 0.002089  [  480/ 1575]
loss: 0.001936  [  640/ 1575]
loss: 0.002383  [  800/ 1575]
loss: 0.002251  [  960/ 1575]
loss: 0.003325  [ 1120/ 1575]
loss: 0.002338  [ 1280/ 1575]
loss: 0.003532  [ 1440/ 1575]
Test Error: 
MSE: 30.957946
RMSE: 5.563986
MAE: 2.099957
R^2: 0.9032150672206801
loss: 0.003433  [    0/ 1575]
loss: 0.002175  [  160/ 1575]
loss: 0.004228  [  320/ 1575]
loss: 0.002092  [  480/ 1575]
loss: 0.001919  [  640/ 1575]
loss: 0.003064  [  800/ 1575]
loss: 0.004103  [  960/ 1575]
loss: 0.001860  [ 1120/ 1575]
loss: 0.003172  [ 1280/ 1575]
loss: 0.003160  [ 1440/ 1575]
Test Error: 
MSE: 37.311943
RMSE: 6.108350
MAE: 2.230002
R^2: 0.8833503381444014
loss: 0.002509  [    0/ 1575]
loss: 0.004223  [  160/ 1575]
loss: 0.001836  [  320/ 1575]
loss: 0.002317  [  480/ 1575]
loss: 0.003294  [  640/ 1575]
loss: 0.002232  [  800/ 1575]
loss: 0.002659  [  960/ 1575]
loss: 0.001265  [ 1120/ 1575]
loss: 0.003551  [ 1280/ 1575]
loss: 0.002804  [ 1440/ 1575]
Test Error: 
MSE: 35.652120
RMSE: 5.970940
MAE: 2.182468
R^2: 0.888539503140395
loss: 0.001611  [    0/ 1575]
loss: 0.003534  [  160/ 1575]
loss: 0.003862  [  320/ 1575]
loss: 0.002620  [  480/ 1575]
loss: 0.006068  [  640/ 1575]
loss: 0.003344  [  800/ 1575]
loss: 0.002472  [  960/ 1575]
loss: 0.003854  [ 1120/ 1575]
loss: 0.002327  [ 1280/ 1575]
loss: 0.001698  [ 1440/ 1575]
Test Error: 
MSE: 30.021601
RMSE: 5.479197
MAE: 2.087015
R^2: 0.9061423940758555
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.004010  [    0/ 1575]
loss: 0.003167  [  160/ 1575]
loss: 0.002541  [  320/ 1575]
loss: 0.002839  [  480/ 1575]
loss: 0.002231  [  640/ 1575]
loss: 0.001726  [  800/ 1575]
loss: 0.002644  [  960/ 1575]
loss: 0.002385  [ 1120/ 1575]
loss: 0.003451  [ 1280/ 1575]
loss: 0.002214  [ 1440/ 1575]
Test Error: 
MSE: 30.313681
RMSE: 5.505786
MAE: 2.086952
R^2: 0.9052292548076126
loss: 0.002960  [    0/ 1575]
loss: 0.003427  [  160/ 1575]
loss: 0.003135  [  320/ 1575]
loss: 0.004087  [  480/ 1575]
loss: 0.002636  [  640/ 1575]
loss: 0.003129  [  800/ 1575]
loss: 0.002945  [  960/ 1575]
loss: 0.002108  [ 1120/ 1575]
loss: 0.003036  [ 1280/ 1575]
loss: 0.002198  [ 1440/ 1575]
Test Error: 
MSE: 30.768309
RMSE: 5.546919
MAE: 2.107665
R^2: 0.9038079339382501
loss: 0.002096  [    0/ 1575]
loss: 0.002597  [  160/ 1575]
loss: 0.002271  [  320/ 1575]
loss: 0.002926  [  480/ 1575]
loss: 0.002996  [  640/ 1575]
loss: 0.002039  [  800/ 1575]
loss: 0.002904  [  960/ 1575]
loss: 0.002402  [ 1120/ 1575]
loss: 0.002015  [ 1280/ 1575]
loss: 0.002090  [ 1440/ 1575]
Test Error: 
MSE: 31.550840
RMSE: 5.617013
MAE: 2.125859
R^2: 0.9013614808971606
loss: 0.003726  [    0/ 1575]
loss: 0.003423  [  160/ 1575]
loss: 0.003106  [  320/ 1575]
loss: 0.002818  [  480/ 1575]
loss: 0.002540  [  640/ 1575]
loss: 0.001829  [  800/ 1575]
loss: 0.001380  [  960/ 1575]
loss: 0.003063  [ 1120/ 1575]
loss: 0.004681  [ 1280/ 1575]
loss: 0.002034  [ 1440/ 1575]
Test Error: 
MSE: 30.133511
RMSE: 5.489400
MAE: 2.092452
R^2: 0.9057925261390113
loss: 0.001906  [    0/ 1575]
loss: 0.003260  [  160/ 1575]
loss: 0.001811  [  320/ 1575]
loss: 0.002142  [  480/ 1575]
loss: 0.004128  [  640/ 1575]
loss: 0.002667  [  800/ 1575]
loss: 0.002041  [  960/ 1575]
loss: 0.002888  [ 1120/ 1575]
loss: 0.002362  [ 1280/ 1575]
loss: 0.004246  [ 1440/ 1575]
Test Error: 
MSE: 30.583977
RMSE: 5.530278
MAE: 2.103591
R^2: 0.9043842197148254
loss: 0.002976  [    0/ 1575]
loss: 0.002166  [  160/ 1575]
loss: 0.003456  [  320/ 1575]
loss: 0.002566  [  480/ 1575]
loss: 0.003084  [  640/ 1575]
loss: 0.002763  [  800/ 1575]
loss: 0.001773  [  960/ 1575]
loss: 0.001706  [ 1120/ 1575]
loss: 0.002257  [ 1280/ 1575]
loss: 0.003448  [ 1440/ 1575]
Test Error: 
MSE: 35.110730
RMSE: 5.925431
MAE: 2.193978
R^2: 0.8902320694083522
loss: 0.002622  [    0/ 1575]
loss: 0.002356  [  160/ 1575]
loss: 0.003263  [  320/ 1575]
loss: 0.002708  [  480/ 1575]
loss: 0.002077  [  640/ 1575]
loss: 0.001893  [  800/ 1575]
loss: 0.002586  [  960/ 1575]
loss: 0.003044  [ 1120/ 1575]
loss: 0.002254  [ 1280/ 1575]
loss: 0.003779  [ 1440/ 1575]
Test Error: 
MSE: 38.798530
RMSE: 6.228847
MAE: 2.232912
R^2: 0.878702768630003
loss: 0.005452  [    0/ 1575]
loss: 0.003143  [  160/ 1575]
loss: 0.003485  [  320/ 1575]
loss: 0.004650  [  480/ 1575]
loss: 0.003372  [  640/ 1575]
loss: 0.001676  [  800/ 1575]
loss: 0.001655  [  960/ 1575]
loss: 0.002690  [ 1120/ 1575]
loss: 0.001883  [ 1280/ 1575]
loss: 0.002831  [ 1440/ 1575]
Test Error: 
MSE: 31.368758
RMSE: 5.600782
MAE: 2.121989
R^2: 0.9019307281028465
loss: 0.002262  [    0/ 1575]
loss: 0.003408  [  160/ 1575]
loss: 0.002651  [  320/ 1575]
loss: 0.003017  [  480/ 1575]
loss: 0.003199  [  640/ 1575]
loss: 0.002714  [  800/ 1575]
loss: 0.002658  [  960/ 1575]
loss: 0.001547  [ 1120/ 1575]
loss: 0.002657  [ 1280/ 1575]
loss: 0.002649  [ 1440/ 1575]
Test Error: 
MSE: 33.803859
RMSE: 5.814109
MAE: 2.171525
R^2: 0.8943177856312378
loss: 0.003409  [    0/ 1575]
loss: 0.003529  [  160/ 1575]
loss: 0.002381  [  320/ 1575]
loss: 0.002390  [  480/ 1575]
loss: 0.001998  [  640/ 1575]
loss: 0.002465  [  800/ 1575]
loss: 0.002311  [  960/ 1575]
loss: 0.002416  [ 1120/ 1575]
loss: 0.002954  [ 1280/ 1575]
loss: 0.001584  [ 1440/ 1575]
Test Error: 
MSE: 32.453009
RMSE: 5.696754
MAE: 2.145071
R^2: 0.8985409971428596
loss: 0.001852  [    0/ 1575]
loss: 0.002472  [  160/ 1575]
loss: 0.002538  [  320/ 1575]
loss: 0.002060  [  480/ 1575]
loss: 0.003089  [  640/ 1575]
loss: 0.001752  [  800/ 1575]
loss: 0.003181  [  960/ 1575]
loss: 0.003537  [ 1120/ 1575]
loss: 0.001609  [ 1280/ 1575]
loss: 0.002034  [ 1440/ 1575]
Test Error: 
MSE: 29.599500
RMSE: 5.440542
MAE: 2.073334
R^2: 0.9074620230830477
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003145  [    0/ 1575]
loss: 0.001871  [  160/ 1575]
loss: 0.002851  [  320/ 1575]
loss: 0.002181  [  480/ 1575]
loss: 0.001877  [  640/ 1575]
loss: 0.003496  [  800/ 1575]
loss: 0.002334  [  960/ 1575]
loss: 0.002651  [ 1120/ 1575]
loss: 0.002978  [ 1280/ 1575]
loss: 0.003560  [ 1440/ 1575]
Test Error: 
MSE: 29.647730
RMSE: 5.444973
MAE: 2.079912
R^2: 0.9073112406134839
loss: 0.003313  [    0/ 1575]
loss: 0.002723  [  160/ 1575]
loss: 0.003741  [  320/ 1575]
loss: 0.002532  [  480/ 1575]
loss: 0.002293  [  640/ 1575]
loss: 0.002108  [  800/ 1575]
loss: 0.001875  [  960/ 1575]
loss: 0.002602  [ 1120/ 1575]
loss: 0.002395  [ 1280/ 1575]
loss: 0.002673  [ 1440/ 1575]
Test Error: 
MSE: 31.852794
RMSE: 5.643828
MAE: 2.133359
R^2: 0.900417469548403
loss: 0.003005  [    0/ 1575]
loss: 0.003899  [  160/ 1575]
loss: 0.002964  [  320/ 1575]
loss: 0.003597  [  480/ 1575]
loss: 0.003807  [  640/ 1575]
loss: 0.002082  [  800/ 1575]
loss: 0.002216  [  960/ 1575]
loss: 0.003171  [ 1120/ 1575]
loss: 0.002873  [ 1280/ 1575]
loss: 0.003415  [ 1440/ 1575]
Test Error: 
MSE: 29.883621
RMSE: 5.466591
MAE: 2.087783
R^2: 0.9065737655143649
loss: 0.003131  [    0/ 1575]
loss: 0.002160  [  160/ 1575]
loss: 0.002909  [  320/ 1575]
loss: 0.002480  [  480/ 1575]
loss: 0.003875  [  640/ 1575]
loss: 0.002442  [  800/ 1575]
loss: 0.001593  [  960/ 1575]
loss: 0.002748  [ 1120/ 1575]
loss: 0.003852  [ 1280/ 1575]
loss: 0.004459  [ 1440/ 1575]
Test Error: 
MSE: 30.045122
RMSE: 5.481343
MAE: 2.080704
R^2: 0.9060688613579579
loss: 0.002623  [    0/ 1575]
loss: 0.001589  [  160/ 1575]
loss: 0.003256  [  320/ 1575]
loss: 0.002872  [  480/ 1575]
loss: 0.003641  [  640/ 1575]
loss: 0.002116  [  800/ 1575]
loss: 0.002419  [  960/ 1575]
loss: 0.002893  [ 1120/ 1575]
loss: 0.001832  [ 1280/ 1575]
loss: 0.002297  [ 1440/ 1575]
Test Error: 
MSE: 39.990602
RMSE: 6.323812
MAE: 2.268898
R^2: 0.8749759501640028
loss: 0.001916  [    0/ 1575]
loss: 0.003426  [  160/ 1575]
loss: 0.003975  [  320/ 1575]
loss: 0.002422  [  480/ 1575]
loss: 0.003499  [  640/ 1575]
loss: 0.002632  [  800/ 1575]
loss: 0.003553  [  960/ 1575]
loss: 0.002640  [ 1120/ 1575]
loss: 0.001814  [ 1280/ 1575]
loss: 0.002263  [ 1440/ 1575]
Test Error: 
MSE: 29.694777
RMSE: 5.449291
MAE: 2.074315
R^2: 0.9071641562435634
loss: 0.001829  [    0/ 1575]
loss: 0.002872  [  160/ 1575]
loss: 0.003505  [  320/ 1575]
loss: 0.003156  [  480/ 1575]
loss: 0.003105  [  640/ 1575]
loss: 0.002419  [  800/ 1575]
loss: 0.003217  [  960/ 1575]
loss: 0.003087  [ 1120/ 1575]
loss: 0.003209  [ 1280/ 1575]
loss: 0.002728  [ 1440/ 1575]
Test Error: 
MSE: 29.362003
RMSE: 5.418672
MAE: 2.072068
R^2: 0.908204518914247
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.001834  [    0/ 1575]
loss: 0.003160  [  160/ 1575]
loss: 0.002826  [  320/ 1575]
loss: 0.003598  [  480/ 1575]
loss: 0.003044  [  640/ 1575]
loss: 0.002525  [  800/ 1575]
loss: 0.004634  [  960/ 1575]
loss: 0.002146  [ 1120/ 1575]
loss: 0.001909  [ 1280/ 1575]
loss: 0.001831  [ 1440/ 1575]
Test Error: 
MSE: 29.959373
RMSE: 5.473516
MAE: 2.091215
R^2: 0.9063369389322568
loss: 0.002466  [    0/ 1575]
loss: 0.002938  [  160/ 1575]
loss: 0.002287  [  320/ 1575]
loss: 0.003214  [  480/ 1575]
loss: 0.002170  [  640/ 1575]
loss: 0.002610  [  800/ 1575]
loss: 0.002303  [  960/ 1575]
loss: 0.002194  [ 1120/ 1575]
loss: 0.003184  [ 1280/ 1575]
loss: 0.003541  [ 1440/ 1575]
Test Error: 
MSE: 29.602401
RMSE: 5.440809
MAE: 2.072486
R^2: 0.907452953322985
loss: 0.002305  [    0/ 1575]
loss: 0.004596  [  160/ 1575]
loss: 0.002100  [  320/ 1575]
loss: 0.002276  [  480/ 1575]
loss: 0.003332  [  640/ 1575]
loss: 0.003861  [  800/ 1575]
loss: 0.002865  [  960/ 1575]
loss: 0.003608  [ 1120/ 1575]
loss: 0.001313  [ 1280/ 1575]
loss: 0.002691  [ 1440/ 1575]
Test Error: 
MSE: 29.596140
RMSE: 5.440233
MAE: 2.081934
R^2: 0.9074725276992792
loss: 0.002125  [    0/ 1575]
loss: 0.003511  [  160/ 1575]
loss: 0.002105  [  320/ 1575]
loss: 0.002354  [  480/ 1575]
loss: 0.003279  [  640/ 1575]
loss: 0.003608  [  800/ 1575]
loss: 0.002601  [  960/ 1575]
loss: 0.002201  [ 1120/ 1575]
loss: 0.001898  [ 1280/ 1575]
loss: 0.003446  [ 1440/ 1575]
Test Error: 
MSE: 38.860132
RMSE: 6.233790
MAE: 2.252693
R^2: 0.8785101790314491
loss: 0.001803  [    0/ 1575]
loss: 0.003047  [  160/ 1575]
loss: 0.002683  [  320/ 1575]
loss: 0.003507  [  480/ 1575]
loss: 0.003932  [  640/ 1575]
loss: 0.003493  [  800/ 1575]
loss: 0.002494  [  960/ 1575]
loss: 0.002485  [ 1120/ 1575]
loss: 0.003319  [ 1280/ 1575]
loss: 0.002202  [ 1440/ 1575]
Test Error: 
MSE: 38.069020
RMSE: 6.170010
MAE: 2.241793
R^2: 0.880983461911089
loss: 0.002727  [    0/ 1575]
loss: 0.001938  [  160/ 1575]
loss: 0.002939  [  320/ 1575]
loss: 0.001911  [  480/ 1575]
loss: 0.002189  [  640/ 1575]
loss: 0.002419  [  800/ 1575]
loss: 0.003048  [  960/ 1575]
loss: 0.002648  [ 1120/ 1575]
loss: 0.004030  [ 1280/ 1575]
loss: 0.002050  [ 1440/ 1575]
Test Error: 
MSE: 35.477186
RMSE: 5.956273
MAE: 2.179646
R^2: 0.8890864056892409
loss: 0.003236  [    0/ 1575]
loss: 0.003206  [  160/ 1575]
loss: 0.003149  [  320/ 1575]
loss: 0.002328  [  480/ 1575]
loss: 0.002359  [  640/ 1575]
loss: 0.001436  [  800/ 1575]
loss: 0.002341  [  960/ 1575]
loss: 0.001883  [ 1120/ 1575]
loss: 0.003403  [ 1280/ 1575]
loss: 0.002511  [ 1440/ 1575]
Test Error: 
MSE: 30.241511
RMSE: 5.499228
MAE: 2.098669
R^2: 0.9054548837216968
loss: 0.002106  [    0/ 1575]
loss: 0.002800  [  160/ 1575]
loss: 0.003190  [  320/ 1575]
loss: 0.003692  [  480/ 1575]
loss: 0.002911  [  640/ 1575]
loss: 0.002018  [  800/ 1575]
loss: 0.002064  [  960/ 1575]
loss: 0.002261  [ 1120/ 1575]
loss: 0.001840  [ 1280/ 1575]
loss: 0.002158  [ 1440/ 1575]
Test Error: 
MSE: 32.541655
RMSE: 5.704529
MAE: 2.147749
R^2: 0.8982638586796271
loss: 0.002889  [    0/ 1575]
loss: 0.003636  [  160/ 1575]
loss: 0.001511  [  320/ 1575]
loss: 0.003377  [  480/ 1575]
loss: 0.002258  [  640/ 1575]
loss: 0.002758  [  800/ 1575]
loss: 0.004318  [  960/ 1575]
loss: 0.001665  [ 1120/ 1575]
loss: 0.004176  [ 1280/ 1575]
loss: 0.004105  [ 1440/ 1575]
Test Error: 
MSE: 36.490329
RMSE: 6.040723
MAE: 2.197642
R^2: 0.8859189780559842
loss: 0.004432  [    0/ 1575]
loss: 0.004205  [  160/ 1575]
loss: 0.002569  [  320/ 1575]
loss: 0.004458  [  480/ 1575]
loss: 0.002851  [  640/ 1575]
loss: 0.002434  [  800/ 1575]
loss: 0.002432  [  960/ 1575]
loss: 0.002184  [ 1120/ 1575]
loss: 0.002463  [ 1280/ 1575]
loss: 0.002744  [ 1440/ 1575]
Test Error: 
MSE: 36.336276
RMSE: 6.027958
MAE: 2.213644
R^2: 0.886400601150425
loss: 0.002522  [    0/ 1575]
loss: 0.002577  [  160/ 1575]
loss: 0.002560  [  320/ 1575]
loss: 0.002938  [  480/ 1575]
loss: 0.001542  [  640/ 1575]
loss: 0.002242  [  800/ 1575]
loss: 0.003074  [  960/ 1575]
loss: 0.002311  [ 1120/ 1575]
loss: 0.002216  [ 1280/ 1575]
loss: 0.002926  [ 1440/ 1575]
Test Error: 
MSE: 29.573284
RMSE: 5.438132
MAE: 2.071275
R^2: 0.9075439856751456
loss: 0.004347  [    0/ 1575]
loss: 0.002971  [  160/ 1575]
loss: 0.002101  [  320/ 1575]
loss: 0.005864  [  480/ 1575]
loss: 0.002487  [  640/ 1575]
loss: 0.003002  [  800/ 1575]
loss: 0.002739  [  960/ 1575]
loss: 0.003608  [ 1120/ 1575]
loss: 0.001926  [ 1280/ 1575]
loss: 0.002389  [ 1440/ 1575]
Test Error: 
MSE: 29.047042
RMSE: 5.389531
MAE: 2.063474
R^2: 0.9091891927444924
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003353  [    0/ 1575]
loss: 0.003040  [  160/ 1575]
loss: 0.003001  [  320/ 1575]
loss: 0.002878  [  480/ 1575]
loss: 0.004019  [  640/ 1575]
loss: 0.002473  [  800/ 1575]
loss: 0.001470  [  960/ 1575]
loss: 0.003682  [ 1120/ 1575]
loss: 0.001822  [ 1280/ 1575]
loss: 0.002631  [ 1440/ 1575]
Test Error: 
MSE: 29.494816
RMSE: 5.430913
MAE: 2.069899
R^2: 0.9077893007758561
loss: 0.003060  [    0/ 1575]
loss: 0.003292  [  160/ 1575]
loss: 0.003814  [  320/ 1575]
loss: 0.002085  [  480/ 1575]
loss: 0.002911  [  640/ 1575]
loss: 0.003137  [  800/ 1575]
loss: 0.002840  [  960/ 1575]
loss: 0.002839  [ 1120/ 1575]
loss: 0.002562  [ 1280/ 1575]
loss: 0.002837  [ 1440/ 1575]
Test Error: 
MSE: 29.076858
RMSE: 5.392296
MAE: 2.069365
R^2: 0.9090959791196422
loss: 0.001695  [    0/ 1575]
loss: 0.003195  [  160/ 1575]
loss: 0.002454  [  320/ 1575]
loss: 0.003843  [  480/ 1575]
loss: 0.003374  [  640/ 1575]
loss: 0.002699  [  800/ 1575]
loss: 0.003589  [  960/ 1575]
loss: 0.001926  [ 1120/ 1575]
loss: 0.002797  [ 1280/ 1575]
loss: 0.003417  [ 1440/ 1575]
Test Error: 
MSE: 29.918066
RMSE: 5.469741
MAE: 2.077813
R^2: 0.9064660788676234
loss: 0.002143  [    0/ 1575]
loss: 0.004861  [  160/ 1575]
loss: 0.002408  [  320/ 1575]
loss: 0.002588  [  480/ 1575]
loss: 0.002213  [  640/ 1575]
loss: 0.003055  [  800/ 1575]
loss: 0.003126  [  960/ 1575]
loss: 0.003002  [ 1120/ 1575]
loss: 0.002437  [ 1280/ 1575]
loss: 0.004485  [ 1440/ 1575]
Test Error: 
MSE: 38.816179
RMSE: 6.230263
MAE: 2.251850
R^2: 0.8786475904586776
loss: 0.003491  [    0/ 1575]
loss: 0.002911  [  160/ 1575]
loss: 0.002023  [  320/ 1575]
loss: 0.002299  [  480/ 1575]
loss: 0.002022  [  640/ 1575]
loss: 0.002173  [  800/ 1575]
loss: 0.001912  [  960/ 1575]
loss: 0.001823  [ 1120/ 1575]
loss: 0.003128  [ 1280/ 1575]
loss: 0.003346  [ 1440/ 1575]
Test Error: 
MSE: 29.300928
RMSE: 5.413033
MAE: 2.077443
R^2: 0.9083954592928588
loss: 0.001676  [    0/ 1575]
loss: 0.001859  [  160/ 1575]
loss: 0.002101  [  320/ 1575]
loss: 0.001808  [  480/ 1575]
loss: 0.003577  [  640/ 1575]
loss: 0.002875  [  800/ 1575]
loss: 0.002787  [  960/ 1575]
loss: 0.003538  [ 1120/ 1575]
loss: 0.002014  [ 1280/ 1575]
loss: 0.002799  [ 1440/ 1575]
Test Error: 
MSE: 28.809565
RMSE: 5.367454
MAE: 2.060310
R^2: 0.9099316250201216
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002878  [    0/ 1575]
loss: 0.002008  [  160/ 1575]
loss: 0.003018  [  320/ 1575]
loss: 0.002425  [  480/ 1575]
loss: 0.002927  [  640/ 1575]
loss: 0.002973  [  800/ 1575]
loss: 0.001819  [  960/ 1575]
loss: 0.002692  [ 1120/ 1575]
loss: 0.002315  [ 1280/ 1575]
loss: 0.002291  [ 1440/ 1575]
Test Error: 
MSE: 34.325279
RMSE: 5.858778
MAE: 2.182810
R^2: 0.8926876511499334
loss: 0.002654  [    0/ 1575]
loss: 0.003491  [  160/ 1575]
loss: 0.003354  [  320/ 1575]
loss: 0.002307  [  480/ 1575]
loss: 0.003319  [  640/ 1575]
loss: 0.002445  [  800/ 1575]
loss: 0.001926  [  960/ 1575]
loss: 0.002110  [ 1120/ 1575]
loss: 0.003294  [ 1280/ 1575]
loss: 0.002603  [ 1440/ 1575]
Test Error: 
MSE: 29.321548
RMSE: 5.414937
MAE: 2.066582
R^2: 0.9083309950618251
loss: 0.002489  [    0/ 1575]
loss: 0.002865  [  160/ 1575]
loss: 0.003079  [  320/ 1575]
loss: 0.002633  [  480/ 1575]
loss: 0.002680  [  640/ 1575]
loss: 0.002509  [  800/ 1575]
loss: 0.001941  [  960/ 1575]
loss: 0.001800  [ 1120/ 1575]
loss: 0.002482  [ 1280/ 1575]
loss: 0.004716  [ 1440/ 1575]
Test Error: 
MSE: 34.727939
RMSE: 5.893042
MAE: 2.188933
R^2: 0.8914288010846774
loss: 0.002076  [    0/ 1575]
loss: 0.003494  [  160/ 1575]
loss: 0.003258  [  320/ 1575]
loss: 0.002885  [  480/ 1575]
loss: 0.002353  [  640/ 1575]
loss: 0.003764  [  800/ 1575]
loss: 0.002809  [  960/ 1575]
loss: 0.002696  [ 1120/ 1575]
loss: 0.001978  [ 1280/ 1575]
loss: 0.002552  [ 1440/ 1575]
Test Error: 
MSE: 28.662408
RMSE: 5.353728
MAE: 2.058656
R^2: 0.9103916879916027
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003593  [    0/ 1575]
loss: 0.003039  [  160/ 1575]
loss: 0.001748  [  320/ 1575]
loss: 0.003175  [  480/ 1575]
loss: 0.002752  [  640/ 1575]
loss: 0.003958  [  800/ 1575]
loss: 0.002819  [  960/ 1575]
loss: 0.003784  [ 1120/ 1575]
loss: 0.002788  [ 1280/ 1575]
loss: 0.002705  [ 1440/ 1575]
Test Error: 
MSE: 29.599600
RMSE: 5.440551
MAE: 2.085927
R^2: 0.9074617125821052
loss: 0.002733  [    0/ 1575]
loss: 0.001379  [  160/ 1575]
loss: 0.003683  [  320/ 1575]
loss: 0.003103  [  480/ 1575]
loss: 0.004849  [  640/ 1575]
loss: 0.004213  [  800/ 1575]
loss: 0.003390  [  960/ 1575]
loss: 0.004239  [ 1120/ 1575]
loss: 0.003232  [ 1280/ 1575]
loss: 0.005590  [ 1440/ 1575]
Test Error: 
MSE: 53.701890
RMSE: 7.328157
MAE: 2.471075
R^2: 0.8321098600007346
loss: 0.004317  [    0/ 1575]
loss: 0.002370  [  160/ 1575]
loss: 0.002634  [  320/ 1575]
loss: 0.003966  [  480/ 1575]
loss: 0.002103  [  640/ 1575]
loss: 0.002602  [  800/ 1575]
loss: 0.003135  [  960/ 1575]
loss: 0.002414  [ 1120/ 1575]
loss: 0.003471  [ 1280/ 1575]
loss: 0.001904  [ 1440/ 1575]
Test Error: 
MSE: 28.861916
RMSE: 5.372329
MAE: 2.068079
R^2: 0.9097679594129106
loss: 0.002130  [    0/ 1575]
loss: 0.003265  [  160/ 1575]
loss: 0.002730  [  320/ 1575]
loss: 0.003315  [  480/ 1575]
loss: 0.002429  [  640/ 1575]
loss: 0.003050  [  800/ 1575]
loss: 0.003370  [  960/ 1575]
loss: 0.003699  [ 1120/ 1575]
loss: 0.002644  [ 1280/ 1575]
loss: 0.002758  [ 1440/ 1575]
Test Error: 
MSE: 28.803415
RMSE: 5.366881
MAE: 2.056793
R^2: 0.9099508530612281
loss: 0.002327  [    0/ 1575]
loss: 0.002559  [  160/ 1575]
loss: 0.001710  [  320/ 1575]
loss: 0.002118  [  480/ 1575]
loss: 0.002989  [  640/ 1575]
loss: 0.003218  [  800/ 1575]
loss: 0.002480  [  960/ 1575]
loss: 0.003065  [ 1120/ 1575]
loss: 0.003482  [ 1280/ 1575]
loss: 0.003298  [ 1440/ 1575]
Test Error: 
MSE: 28.533041
RMSE: 5.341633
MAE: 2.056996
R^2: 0.9107961337299887
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002755  [    0/ 1575]
loss: 0.002174  [  160/ 1575]
loss: 0.002413  [  320/ 1575]
loss: 0.002546  [  480/ 1575]
loss: 0.002431  [  640/ 1575]
loss: 0.001839  [  800/ 1575]
loss: 0.002389  [  960/ 1575]
loss: 0.001428  [ 1120/ 1575]
loss: 0.004458  [ 1280/ 1575]
loss: 0.002345  [ 1440/ 1575]
Test Error: 
MSE: 29.947433
RMSE: 5.472425
MAE: 2.095809
R^2: 0.9063742691702235
loss: 0.002354  [    0/ 1575]
loss: 0.002832  [  160/ 1575]
loss: 0.003173  [  320/ 1575]
loss: 0.002941  [  480/ 1575]
loss: 0.002178  [  640/ 1575]
loss: 0.001995  [  800/ 1575]
loss: 0.004547  [  960/ 1575]
loss: 0.003294  [ 1120/ 1575]
loss: 0.001064  [ 1280/ 1575]
loss: 0.003485  [ 1440/ 1575]
Test Error: 
MSE: 28.497961
RMSE: 5.338348
MAE: 2.054380
R^2: 0.9109058039112998
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002112  [    0/ 1575]
loss: 0.002712  [  160/ 1575]
loss: 0.002250  [  320/ 1575]
loss: 0.001999  [  480/ 1575]
loss: 0.003726  [  640/ 1575]
loss: 0.004037  [  800/ 1575]
loss: 0.002952  [  960/ 1575]
loss: 0.002502  [ 1120/ 1575]
loss: 0.003559  [ 1280/ 1575]
loss: 0.002698  [ 1440/ 1575]
Test Error: 
MSE: 28.490625
RMSE: 5.337661
MAE: 2.053992
R^2: 0.9109287406293413
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.001871  [    0/ 1575]
loss: 0.001920  [  160/ 1575]
loss: 0.002884  [  320/ 1575]
loss: 0.001557  [  480/ 1575]
loss: 0.001473  [  640/ 1575]
loss: 0.002948  [  800/ 1575]
loss: 0.002607  [  960/ 1575]
loss: 0.002080  [ 1120/ 1575]
loss: 0.003816  [ 1280/ 1575]
loss: 0.001421  [ 1440/ 1575]
Test Error: 
MSE: 29.016073
RMSE: 5.386657
MAE: 2.073181
R^2: 0.9092860143143358
loss: 0.002149  [    0/ 1575]
loss: 0.001976  [  160/ 1575]
loss: 0.002394  [  320/ 1575]
loss: 0.002576  [  480/ 1575]
loss: 0.003897  [  640/ 1575]
loss: 0.002390  [  800/ 1575]
loss: 0.005224  [  960/ 1575]
loss: 0.001728  [ 1120/ 1575]
loss: 0.002894  [ 1280/ 1575]
loss: 0.002403  [ 1440/ 1575]
Test Error: 
MSE: 28.533977
RMSE: 5.341720
MAE: 2.059600
R^2: 0.910793206831468
loss: 0.003542  [    0/ 1575]
loss: 0.001914  [  160/ 1575]
loss: 0.002445  [  320/ 1575]
loss: 0.002456  [  480/ 1575]
loss: 0.002570  [  640/ 1575]
loss: 0.003324  [  800/ 1575]
loss: 0.002470  [  960/ 1575]
loss: 0.001789  [ 1120/ 1575]
loss: 0.002201  [ 1280/ 1575]
loss: 0.002657  [ 1440/ 1575]
Test Error: 
MSE: 35.523938
RMSE: 5.960196
MAE: 2.201678
R^2: 0.8889402430168732
loss: 0.003469  [    0/ 1575]
loss: 0.001981  [  160/ 1575]
loss: 0.002602  [  320/ 1575]
loss: 0.004025  [  480/ 1575]
loss: 0.001715  [  640/ 1575]
loss: 0.001683  [  800/ 1575]
loss: 0.004817  [  960/ 1575]
loss: 0.001706  [ 1120/ 1575]
loss: 0.002334  [ 1280/ 1575]
loss: 0.003656  [ 1440/ 1575]
Test Error: 
MSE: 36.328593
RMSE: 6.027321
MAE: 2.214797
R^2: 0.8864246192863097
loss: 0.003711  [    0/ 1575]
loss: 0.003187  [  160/ 1575]
loss: 0.003160  [  320/ 1575]
loss: 0.001974  [  480/ 1575]
loss: 0.002690  [  640/ 1575]
loss: 0.001991  [  800/ 1575]
loss: 0.002625  [  960/ 1575]
loss: 0.003387  [ 1120/ 1575]
loss: 0.002434  [ 1280/ 1575]
loss: 0.002187  [ 1440/ 1575]
Test Error: 
MSE: 32.010734
RMSE: 5.657803
MAE: 2.140709
R^2: 0.8999236970391369
loss: 0.002272  [    0/ 1575]
loss: 0.002511  [  160/ 1575]
loss: 0.002931  [  320/ 1575]
loss: 0.003087  [  480/ 1575]
loss: 0.002945  [  640/ 1575]
loss: 0.002335  [  800/ 1575]
loss: 0.002434  [  960/ 1575]
loss: 0.002309  [ 1120/ 1575]
loss: 0.001708  [ 1280/ 1575]
loss: 0.002587  [ 1440/ 1575]
Test Error: 
MSE: 30.481058
RMSE: 5.520965
MAE: 2.108740
R^2: 0.9047059784757192
loss: 0.003504  [    0/ 1575]
loss: 0.002405  [  160/ 1575]
loss: 0.001927  [  320/ 1575]
loss: 0.001881  [  480/ 1575]
loss: 0.002696  [  640/ 1575]
loss: 0.001306  [  800/ 1575]
loss: 0.002147  [  960/ 1575]
loss: 0.003040  [ 1120/ 1575]
loss: 0.001376  [ 1280/ 1575]
loss: 0.003646  [ 1440/ 1575]
Test Error: 
MSE: 28.753420
RMSE: 5.362222
MAE: 2.067567
R^2: 0.9101071548960692
loss: 0.001851  [    0/ 1575]
loss: 0.002990  [  160/ 1575]
loss: 0.002037  [  320/ 1575]
loss: 0.002066  [  480/ 1575]
loss: 0.001675  [  640/ 1575]
loss: 0.003175  [  800/ 1575]
loss: 0.002091  [  960/ 1575]
loss: 0.002299  [ 1120/ 1575]
loss: 0.002428  [ 1280/ 1575]
loss: 0.001828  [ 1440/ 1575]
Test Error: 
MSE: 30.021695
RMSE: 5.479206
MAE: 2.098126
R^2: 0.9061420994102803
loss: 0.002174  [    0/ 1575]
loss: 0.002041  [  160/ 1575]
loss: 0.001897  [  320/ 1575]
loss: 0.000817  [  480/ 1575]
loss: 0.002422  [  640/ 1575]
loss: 0.003476  [  800/ 1575]
loss: 0.002441  [  960/ 1575]
loss: 0.003643  [ 1120/ 1575]
loss: 0.003160  [ 1280/ 1575]
loss: 0.002324  [ 1440/ 1575]
Test Error: 
MSE: 28.634611
RMSE: 5.351132
MAE: 2.052364
R^2: 0.9104785902197581
loss: 0.003407  [    0/ 1575]
loss: 0.002437  [  160/ 1575]
loss: 0.004002  [  320/ 1575]
loss: 0.002773  [  480/ 1575]
loss: 0.002288  [  640/ 1575]
loss: 0.003251  [  800/ 1575]
loss: 0.002296  [  960/ 1575]
loss: 0.003203  [ 1120/ 1575]
loss: 0.003491  [ 1280/ 1575]
loss: 0.001919  [ 1440/ 1575]
Test Error: 
MSE: 29.129019
RMSE: 5.397131
MAE: 2.077428
R^2: 0.9089329062469962
loss: 0.002328  [    0/ 1575]
loss: 0.003704  [  160/ 1575]
loss: 0.002196  [  320/ 1575]
loss: 0.002349  [  480/ 1575]
loss: 0.003047  [  640/ 1575]
loss: 0.002303  [  800/ 1575]
loss: 0.002915  [  960/ 1575]
loss: 0.001976  [ 1120/ 1575]
loss: 0.002709  [ 1280/ 1575]
loss: 0.003015  [ 1440/ 1575]
Test Error: 
MSE: 29.399280
RMSE: 5.422110
MAE: 2.083869
R^2: 0.9080879777356161
loss: 0.002412  [    0/ 1575]
loss: 0.002542  [  160/ 1575]
loss: 0.002844  [  320/ 1575]
loss: 0.002960  [  480/ 1575]
loss: 0.002925  [  640/ 1575]
loss: 0.004060  [  800/ 1575]
loss: 0.002316  [  960/ 1575]
loss: 0.002424  [ 1120/ 1575]
loss: 0.001695  [ 1280/ 1575]
loss: 0.002562  [ 1440/ 1575]
Test Error: 
MSE: 28.178134
RMSE: 5.308308
MAE: 2.049102
R^2: 0.9119056907488545
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002448  [    0/ 1575]
loss: 0.000877  [  160/ 1575]
loss: 0.002610  [  320/ 1575]
loss: 0.001653  [  480/ 1575]
loss: 0.004162  [  640/ 1575]
loss: 0.002906  [  800/ 1575]
loss: 0.001960  [  960/ 1575]
loss: 0.002159  [ 1120/ 1575]
loss: 0.001711  [ 1280/ 1575]
loss: 0.002722  [ 1440/ 1575]
Test Error: 
MSE: 29.982568
RMSE: 5.475634
MAE: 2.078782
R^2: 0.9062644259348271
loss: 0.002766  [    0/ 1575]
loss: 0.003664  [  160/ 1575]
loss: 0.002478  [  320/ 1575]
loss: 0.002900  [  480/ 1575]
loss: 0.002624  [  640/ 1575]
loss: 0.002697  [  800/ 1575]
loss: 0.002592  [  960/ 1575]
loss: 0.002275  [ 1120/ 1575]
loss: 0.002606  [ 1280/ 1575]
loss: 0.002305  [ 1440/ 1575]
Test Error: 
MSE: 30.458185
RMSE: 5.518894
MAE: 2.108729
R^2: 0.9047774850753348
loss: 0.002876  [    0/ 1575]
loss: 0.003967  [  160/ 1575]
loss: 0.002021  [  320/ 1575]
loss: 0.001668  [  480/ 1575]
loss: 0.001499  [  640/ 1575]
loss: 0.002671  [  800/ 1575]
loss: 0.003296  [  960/ 1575]
loss: 0.002563  [ 1120/ 1575]
loss: 0.003887  [ 1280/ 1575]
loss: 0.002402  [ 1440/ 1575]
Test Error: 
MSE: 29.437745
RMSE: 5.425656
MAE: 2.084786
R^2: 0.9079677230852851
loss: 0.004200  [    0/ 1575]
loss: 0.002889  [  160/ 1575]
loss: 0.001882  [  320/ 1575]
loss: 0.001743  [  480/ 1575]
loss: 0.003006  [  640/ 1575]
loss: 0.001976  [  800/ 1575]
loss: 0.002254  [  960/ 1575]
loss: 0.002286  [ 1120/ 1575]
loss: 0.003167  [ 1280/ 1575]
loss: 0.001803  [ 1440/ 1575]
Test Error: 
MSE: 29.302175
RMSE: 5.413148
MAE: 2.064375
R^2: 0.9083915611240713
loss: 0.002532  [    0/ 1575]
loss: 0.002831  [  160/ 1575]
loss: 0.003307  [  320/ 1575]
loss: 0.002292  [  480/ 1575]
loss: 0.003502  [  640/ 1575]
loss: 0.003003  [  800/ 1575]
loss: 0.001907  [  960/ 1575]
loss: 0.003471  [ 1120/ 1575]
loss: 0.004246  [ 1280/ 1575]
loss: 0.003388  [ 1440/ 1575]
Test Error: 
MSE: 28.092881
RMSE: 5.300272
MAE: 2.046455
R^2: 0.912172221519065
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002011  [    0/ 1575]
loss: 0.003114  [  160/ 1575]
loss: 0.003611  [  320/ 1575]
loss: 0.002763  [  480/ 1575]
loss: 0.003142  [  640/ 1575]
loss: 0.001719  [  800/ 1575]
loss: 0.002545  [  960/ 1575]
loss: 0.002299  [ 1120/ 1575]
loss: 0.002741  [ 1280/ 1575]
loss: 0.001434  [ 1440/ 1575]
Test Error: 
MSE: 28.553033
RMSE: 5.343504
MAE: 2.063867
R^2: 0.9107336312983374
loss: 0.003943  [    0/ 1575]
loss: 0.001962  [  160/ 1575]
loss: 0.002774  [  320/ 1575]
loss: 0.002882  [  480/ 1575]
loss: 0.001403  [  640/ 1575]
loss: 0.002014  [  800/ 1575]
loss: 0.002915  [  960/ 1575]
loss: 0.003187  [ 1120/ 1575]
loss: 0.004127  [ 1280/ 1575]
loss: 0.002270  [ 1440/ 1575]
Test Error: 
MSE: 39.094796
RMSE: 6.252583
MAE: 2.258642
R^2: 0.8777765411634645
loss: 0.003317  [    0/ 1575]
loss: 0.002175  [  160/ 1575]
loss: 0.002588  [  320/ 1575]
loss: 0.002155  [  480/ 1575]
loss: 0.001837  [  640/ 1575]
loss: 0.002692  [  800/ 1575]
loss: 0.003197  [  960/ 1575]
loss: 0.002749  [ 1120/ 1575]
loss: 0.003216  [ 1280/ 1575]
loss: 0.001922  [ 1440/ 1575]
Test Error: 
MSE: 28.075671
RMSE: 5.298648
MAE: 2.048471
R^2: 0.9122260258031726
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002496  [    0/ 1575]
loss: 0.002088  [  160/ 1575]
loss: 0.002273  [  320/ 1575]
loss: 0.003193  [  480/ 1575]
loss: 0.002065  [  640/ 1575]
loss: 0.002081  [  800/ 1575]
loss: 0.003371  [  960/ 1575]
loss: 0.002932  [ 1120/ 1575]
loss: 0.002749  [ 1280/ 1575]
loss: 0.003269  [ 1440/ 1575]
Test Error: 
MSE: 34.205118
RMSE: 5.848514
MAE: 2.156389
R^2: 0.8930633167625353
loss: 0.003333  [    0/ 1575]
loss: 0.003570  [  160/ 1575]
loss: 0.002875  [  320/ 1575]
loss: 0.003986  [  480/ 1575]
loss: 0.003577  [  640/ 1575]
loss: 0.002800  [  800/ 1575]
loss: 0.003091  [  960/ 1575]
loss: 0.001926  [ 1120/ 1575]
loss: 0.001985  [ 1280/ 1575]
loss: 0.001429  [ 1440/ 1575]
Test Error: 
MSE: 28.676340
RMSE: 5.355029
MAE: 2.053303
R^2: 0.9103481321591658
loss: 0.003168  [    0/ 1575]
loss: 0.002489  [  160/ 1575]
loss: 0.002679  [  320/ 1575]
loss: 0.001794  [  480/ 1575]
loss: 0.001685  [  640/ 1575]
loss: 0.003148  [  800/ 1575]
loss: 0.001684  [  960/ 1575]
loss: 0.002226  [ 1120/ 1575]
loss: 0.002695  [ 1280/ 1575]
loss: 0.002051  [ 1440/ 1575]
Test Error: 
MSE: 29.543760
RMSE: 5.435417
MAE: 2.087671
R^2: 0.907636285649683
loss: 0.002654  [    0/ 1575]
loss: 0.002273  [  160/ 1575]
loss: 0.002518  [  320/ 1575]
loss: 0.002120  [  480/ 1575]
loss: 0.002068  [  640/ 1575]
loss: 0.002999  [  800/ 1575]
loss: 0.002711  [  960/ 1575]
loss: 0.002431  [ 1120/ 1575]
loss: 0.003190  [ 1280/ 1575]
loss: 0.003511  [ 1440/ 1575]
Test Error: 
MSE: 35.900215
RMSE: 5.991679
MAE: 2.207286
R^2: 0.8877638731537465
loss: 0.002824  [    0/ 1575]
loss: 0.003315  [  160/ 1575]
loss: 0.003678  [  320/ 1575]
loss: 0.001823  [  480/ 1575]
loss: 0.001901  [  640/ 1575]
loss: 0.001178  [  800/ 1575]
loss: 0.002482  [  960/ 1575]
loss: 0.002334  [ 1120/ 1575]
loss: 0.002201  [ 1280/ 1575]
loss: 0.001693  [ 1440/ 1575]
Test Error: 
MSE: 42.858448
RMSE: 6.546636
MAE: 2.319352
R^2: 0.8660100998002652
loss: 0.003242  [    0/ 1575]
loss: 0.004733  [  160/ 1575]
loss: 0.002899  [  320/ 1575]
loss: 0.003400  [  480/ 1575]
loss: 0.002890  [  640/ 1575]
loss: 0.002263  [  800/ 1575]
loss: 0.001809  [  960/ 1575]
loss: 0.002713  [ 1120/ 1575]
loss: 0.001870  [ 1280/ 1575]
loss: 0.002529  [ 1440/ 1575]
Test Error: 
MSE: 27.905989
RMSE: 5.282612
MAE: 2.044066
R^2: 0.9127565068620602
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.001920  [    0/ 1575]
loss: 0.002515  [  160/ 1575]
loss: 0.002061  [  320/ 1575]
loss: 0.001766  [  480/ 1575]
loss: 0.002849  [  640/ 1575]
loss: 0.001589  [  800/ 1575]
loss: 0.002127  [  960/ 1575]
loss: 0.001416  [ 1120/ 1575]
loss: 0.001944  [ 1280/ 1575]
loss: 0.003216  [ 1440/ 1575]
Test Error: 
MSE: 28.223685
RMSE: 5.312597
MAE: 2.055820
R^2: 0.9117632848170242
loss: 0.001937  [    0/ 1575]
loss: 0.002647  [  160/ 1575]
loss: 0.002296  [  320/ 1575]
loss: 0.000804  [  480/ 1575]
loss: 0.002723  [  640/ 1575]
loss: 0.002596  [  800/ 1575]
loss: 0.001903  [  960/ 1575]
loss: 0.001963  [ 1120/ 1575]
loss: 0.002726  [ 1280/ 1575]
loss: 0.002970  [ 1440/ 1575]
Test Error: 
MSE: 27.855693
RMSE: 5.277849
MAE: 2.043231
R^2: 0.9129137494242758
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003090  [    0/ 1575]
loss: 0.002621  [  160/ 1575]
loss: 0.002097  [  320/ 1575]
loss: 0.002041  [  480/ 1575]
loss: 0.002985  [  640/ 1575]
loss: 0.002696  [  800/ 1575]
loss: 0.002641  [  960/ 1575]
loss: 0.002664  [ 1120/ 1575]
loss: 0.003162  [ 1280/ 1575]
loss: 0.001523  [ 1440/ 1575]
Test Error: 
MSE: 28.041257
RMSE: 5.295400
MAE: 2.050822
R^2: 0.912333616016799
loss: 0.002019  [    0/ 1575]
loss: 0.002236  [  160/ 1575]
loss: 0.002595  [  320/ 1575]
loss: 0.002409  [  480/ 1575]
loss: 0.002077  [  640/ 1575]
loss: 0.003578  [  800/ 1575]
loss: 0.003005  [  960/ 1575]
loss: 0.001866  [ 1120/ 1575]
loss: 0.003384  [ 1280/ 1575]
loss: 0.002821  [ 1440/ 1575]
Test Error: 
MSE: 28.682052
RMSE: 5.355563
MAE: 2.068746
R^2: 0.910330274402473
loss: 0.001736  [    0/ 1575]
loss: 0.001458  [  160/ 1575]
loss: 0.002855  [  320/ 1575]
loss: 0.002171  [  480/ 1575]
loss: 0.003643  [  640/ 1575]
loss: 0.002592  [  800/ 1575]
loss: 0.002621  [  960/ 1575]
loss: 0.002268  [ 1120/ 1575]
loss: 0.002105  [ 1280/ 1575]
loss: 0.002635  [ 1440/ 1575]
Test Error: 
MSE: 27.842222
RMSE: 5.276573
MAE: 2.040652
R^2: 0.9129558648277989
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002119  [    0/ 1575]
loss: 0.001258  [  160/ 1575]
loss: 0.002582  [  320/ 1575]
loss: 0.002958  [  480/ 1575]
loss: 0.002589  [  640/ 1575]
loss: 0.002584  [  800/ 1575]
loss: 0.002395  [  960/ 1575]
loss: 0.003560  [ 1120/ 1575]
loss: 0.002929  [ 1280/ 1575]
loss: 0.001543  [ 1440/ 1575]
Test Error: 
MSE: 29.610409
RMSE: 5.441545
MAE: 2.090361
R^2: 0.9074279181202837
loss: 0.002697  [    0/ 1575]
loss: 0.002138  [  160/ 1575]
loss: 0.002542  [  320/ 1575]
loss: 0.002279  [  480/ 1575]
loss: 0.003455  [  640/ 1575]
loss: 0.003081  [  800/ 1575]
loss: 0.003152  [  960/ 1575]
loss: 0.001638  [ 1120/ 1575]
loss: 0.003076  [ 1280/ 1575]
loss: 0.003220  [ 1440/ 1575]
Test Error: 
MSE: 30.468772
RMSE: 5.519853
MAE: 2.109284
R^2: 0.9047443866064441
loss: 0.001823  [    0/ 1575]
loss: 0.001859  [  160/ 1575]
loss: 0.003785  [  320/ 1575]
loss: 0.003645  [  480/ 1575]
loss: 0.002365  [  640/ 1575]
loss: 0.002350  [  800/ 1575]
loss: 0.003223  [  960/ 1575]
loss: 0.001490  [ 1120/ 1575]
loss: 0.001778  [ 1280/ 1575]
loss: 0.002407  [ 1440/ 1575]
Test Error: 
MSE: 28.301123
RMSE: 5.319880
MAE: 2.059150
R^2: 0.9115211865233335
loss: 0.002521  [    0/ 1575]
loss: 0.002829  [  160/ 1575]
loss: 0.003602  [  320/ 1575]
loss: 0.002293  [  480/ 1575]
loss: 0.002059  [  640/ 1575]
loss: 0.002951  [  800/ 1575]
loss: 0.002566  [  960/ 1575]
loss: 0.002407  [ 1120/ 1575]
loss: 0.002202  [ 1280/ 1575]
loss: 0.001830  [ 1440/ 1575]
Test Error: 
MSE: 29.878307
RMSE: 5.466105
MAE: 2.096724
R^2: 0.9065903804556086
loss: 0.002325  [    0/ 1575]
loss: 0.002428  [  160/ 1575]
loss: 0.001731  [  320/ 1575]
loss: 0.002594  [  480/ 1575]
loss: 0.001538  [  640/ 1575]
loss: 0.004090  [  800/ 1575]
loss: 0.001762  [  960/ 1575]
loss: 0.002920  [ 1120/ 1575]
loss: 0.003842  [ 1280/ 1575]
loss: 0.002846  [ 1440/ 1575]
Test Error: 
MSE: 33.937905
RMSE: 5.825625
MAE: 2.175219
R^2: 0.8938987147249071
loss: 0.003651  [    0/ 1575]
loss: 0.002067  [  160/ 1575]
loss: 0.002716  [  320/ 1575]
loss: 0.003265  [  480/ 1575]
loss: 0.001850  [  640/ 1575]
loss: 0.001434  [  800/ 1575]
loss: 0.002695  [  960/ 1575]
loss: 0.002190  [ 1120/ 1575]
loss: 0.003560  [ 1280/ 1575]
loss: 0.001854  [ 1440/ 1575]
Test Error: 
MSE: 29.879950
RMSE: 5.466256
MAE: 2.077878
R^2: 0.9065852423513806
loss: 0.003763  [    0/ 1575]
loss: 0.002120  [  160/ 1575]
loss: 0.003534  [  320/ 1575]
loss: 0.001636  [  480/ 1575]
loss: 0.002280  [  640/ 1575]
loss: 0.002077  [  800/ 1575]
loss: 0.002844  [  960/ 1575]
loss: 0.002645  [ 1120/ 1575]
loss: 0.002571  [ 1280/ 1575]
loss: 0.003801  [ 1440/ 1575]
Test Error: 
MSE: 28.090268
RMSE: 5.300025
MAE: 2.042261
R^2: 0.9121803907706454
loss: 0.003055  [    0/ 1575]
loss: 0.001946  [  160/ 1575]
loss: 0.001537  [  320/ 1575]
loss: 0.002632  [  480/ 1575]
loss: 0.002520  [  640/ 1575]
loss: 0.003687  [  800/ 1575]
loss: 0.002942  [  960/ 1575]
loss: 0.002938  [ 1120/ 1575]
loss: 0.001838  [ 1280/ 1575]
loss: 0.001944  [ 1440/ 1575]
Test Error: 
MSE: 32.833067
RMSE: 5.730015
MAE: 2.155963
R^2: 0.8973528090047972
loss: 0.003025  [    0/ 1575]
loss: 0.004386  [  160/ 1575]
loss: 0.002637  [  320/ 1575]
loss: 0.002126  [  480/ 1575]
loss: 0.001947  [  640/ 1575]
loss: 0.002362  [  800/ 1575]
loss: 0.001815  [  960/ 1575]
loss: 0.002345  [ 1120/ 1575]
loss: 0.002361  [ 1280/ 1575]
loss: 0.003537  [ 1440/ 1575]
Test Error: 
MSE: 27.600976
RMSE: 5.253663
MAE: 2.037661
R^2: 0.9137100808804695
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.001224  [    0/ 1575]
loss: 0.002143  [  160/ 1575]
loss: 0.002638  [  320/ 1575]
loss: 0.002986  [  480/ 1575]
loss: 0.001305  [  640/ 1575]
loss: 0.002541  [  800/ 1575]
loss: 0.001446  [  960/ 1575]
loss: 0.002842  [ 1120/ 1575]
loss: 0.001540  [ 1280/ 1575]
loss: 0.001944  [ 1440/ 1575]
Test Error: 
MSE: 29.409370
RMSE: 5.423041
MAE: 2.086978
R^2: 0.9080564335225142
loss: 0.003478  [    0/ 1575]
loss: 0.003400  [  160/ 1575]
loss: 0.004276  [  320/ 1575]
loss: 0.002653  [  480/ 1575]
loss: 0.002730  [  640/ 1575]
loss: 0.003012  [  800/ 1575]
loss: 0.002495  [  960/ 1575]
loss: 0.003073  [ 1120/ 1575]
loss: 0.003457  [ 1280/ 1575]
loss: 0.002710  [ 1440/ 1575]
Test Error: 
MSE: 28.478790
RMSE: 5.336552
MAE: 2.065049
R^2: 0.9109657396649364
loss: 0.002405  [    0/ 1575]
loss: 0.001862  [  160/ 1575]
loss: 0.004331  [  320/ 1575]
loss: 0.002199  [  480/ 1575]
loss: 0.003156  [  640/ 1575]
loss: 0.002123  [  800/ 1575]
loss: 0.002688  [  960/ 1575]
loss: 0.002603  [ 1120/ 1575]
loss: 0.001612  [ 1280/ 1575]
loss: 0.001516  [ 1440/ 1575]
Test Error: 
MSE: 28.065183
RMSE: 5.297658
MAE: 2.041302
R^2: 0.9122588149371529
loss: 0.002575  [    0/ 1575]
loss: 0.003025  [  160/ 1575]
loss: 0.002645  [  320/ 1575]
loss: 0.001609  [  480/ 1575]
loss: 0.002355  [  640/ 1575]
loss: 0.003110  [  800/ 1575]
loss: 0.003488  [  960/ 1575]
loss: 0.002218  [ 1120/ 1575]
loss: 0.003518  [ 1280/ 1575]
loss: 0.001634  [ 1440/ 1575]
Test Error: 
MSE: 35.875534
RMSE: 5.989619
MAE: 2.184529
R^2: 0.8878410331853199
loss: 0.003306  [    0/ 1575]
loss: 0.001933  [  160/ 1575]
loss: 0.002423  [  320/ 1575]
loss: 0.001905  [  480/ 1575]
loss: 0.002605  [  640/ 1575]
loss: 0.002801  [  800/ 1575]
loss: 0.002062  [  960/ 1575]
loss: 0.002242  [ 1120/ 1575]
loss: 0.001067  [ 1280/ 1575]
loss: 0.001863  [ 1440/ 1575]
Test Error: 
MSE: 28.794755
RMSE: 5.366074
MAE: 2.073480
R^2: 0.9099779272443067
loss: 0.001284  [    0/ 1575]
loss: 0.002859  [  160/ 1575]
loss: 0.003476  [  320/ 1575]
loss: 0.002965  [  480/ 1575]
loss: 0.001349  [  640/ 1575]
loss: 0.002661  [  800/ 1575]
loss: 0.002387  [  960/ 1575]
loss: 0.002730  [ 1120/ 1575]
loss: 0.001543  [ 1280/ 1575]
loss: 0.001873  [ 1440/ 1575]
Test Error: 
MSE: 27.734789
RMSE: 5.266383
MAE: 2.044897
R^2: 0.9132917353733937
loss: 0.003513  [    0/ 1575]
loss: 0.001285  [  160/ 1575]
loss: 0.001993  [  320/ 1575]
loss: 0.002531  [  480/ 1575]
loss: 0.001928  [  640/ 1575]
loss: 0.002309  [  800/ 1575]
loss: 0.002915  [  960/ 1575]
loss: 0.003309  [ 1120/ 1575]
loss: 0.003431  [ 1280/ 1575]
loss: 0.002342  [ 1440/ 1575]
Test Error: 
MSE: 28.064668
RMSE: 5.297610
MAE: 2.055073
R^2: 0.9122604246306082
loss: 0.002373  [    0/ 1575]
loss: 0.002473  [  160/ 1575]
loss: 0.002040  [  320/ 1575]
loss: 0.002474  [  480/ 1575]
loss: 0.001741  [  640/ 1575]
loss: 0.002056  [  800/ 1575]
loss: 0.003331  [  960/ 1575]
loss: 0.001596  [ 1120/ 1575]
loss: 0.003822  [ 1280/ 1575]
loss: 0.002386  [ 1440/ 1575]
Test Error: 
MSE: 27.922100
RMSE: 5.284137
MAE: 2.051165
R^2: 0.9127061399096286
loss: 0.002189  [    0/ 1575]
loss: 0.002625  [  160/ 1575]
loss: 0.001996  [  320/ 1575]
loss: 0.002617  [  480/ 1575]
loss: 0.002282  [  640/ 1575]
loss: 0.002768  [  800/ 1575]
loss: 0.002665  [  960/ 1575]
loss: 0.001344  [ 1120/ 1575]
loss: 0.002003  [ 1280/ 1575]
loss: 0.002052  [ 1440/ 1575]
Test Error: 
MSE: 27.641600
RMSE: 5.257528
MAE: 2.034538
R^2: 0.913583078272199
loss: 0.003616  [    0/ 1575]
loss: 0.001879  [  160/ 1575]
loss: 0.002868  [  320/ 1575]
loss: 0.002157  [  480/ 1575]
loss: 0.003019  [  640/ 1575]
loss: 0.002266  [  800/ 1575]
loss: 0.002346  [  960/ 1575]
loss: 0.003196  [ 1120/ 1575]
loss: 0.001605  [ 1280/ 1575]
loss: 0.003273  [ 1440/ 1575]
Test Error: 
MSE: 28.213966
RMSE: 5.311682
MAE: 2.059163
R^2: 0.9117936685305529
loss: 0.002393  [    0/ 1575]
loss: 0.001967  [  160/ 1575]
loss: 0.002300  [  320/ 1575]
loss: 0.002496  [  480/ 1575]
loss: 0.002282  [  640/ 1575]
loss: 0.002545  [  800/ 1575]
loss: 0.002221  [  960/ 1575]
loss: 0.002892  [ 1120/ 1575]
loss: 0.001954  [ 1280/ 1575]
loss: 0.001917  [ 1440/ 1575]
Test Error: 
MSE: 28.989849
RMSE: 5.384222
MAE: 2.078141
R^2: 0.9093679991669292
loss: 0.002885  [    0/ 1575]
loss: 0.003466  [  160/ 1575]
loss: 0.001813  [  320/ 1575]
loss: 0.002032  [  480/ 1575]
loss: 0.002686  [  640/ 1575]
loss: 0.001920  [  800/ 1575]
loss: 0.002416  [  960/ 1575]
loss: 0.001558  [ 1120/ 1575]
loss: 0.003131  [ 1280/ 1575]
loss: 0.002386  [ 1440/ 1575]
Test Error: 
MSE: 35.777393
RMSE: 5.981421
MAE: 2.206039
R^2: 0.8881478557073332
loss: 0.002197  [    0/ 1575]
loss: 0.001521  [  160/ 1575]
loss: 0.002016  [  320/ 1575]
loss: 0.003847  [  480/ 1575]
loss: 0.001415  [  640/ 1575]
loss: 0.003080  [  800/ 1575]
loss: 0.003055  [  960/ 1575]
loss: 0.004946  [ 1120/ 1575]
loss: 0.002773  [ 1280/ 1575]
loss: 0.003321  [ 1440/ 1575]
Test Error: 
MSE: 53.144546
RMSE: 7.290031
MAE: 2.469956
R^2: 0.8338523049081548
loss: 0.004695  [    0/ 1575]
loss: 0.002453  [  160/ 1575]
loss: 0.002378  [  320/ 1575]
loss: 0.002254  [  480/ 1575]
loss: 0.002029  [  640/ 1575]
loss: 0.002128  [  800/ 1575]
loss: 0.002146  [  960/ 1575]
loss: 0.003256  [ 1120/ 1575]
loss: 0.002161  [ 1280/ 1575]
loss: 0.002340  [ 1440/ 1575]
Test Error: 
MSE: 41.704526
RMSE: 6.457904
MAE: 2.304311
R^2: 0.869617646847084
loss: 0.002872  [    0/ 1575]
loss: 0.002842  [  160/ 1575]
loss: 0.003040  [  320/ 1575]
loss: 0.003492  [  480/ 1575]
loss: 0.002647  [  640/ 1575]
loss: 0.002051  [  800/ 1575]
loss: 0.002200  [  960/ 1575]
loss: 0.002463  [ 1120/ 1575]
loss: 0.002419  [ 1280/ 1575]
loss: 0.002974  [ 1440/ 1575]
Test Error: 
MSE: 27.513002
RMSE: 5.245284
MAE: 2.038468
R^2: 0.913985117432274
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003177  [    0/ 1575]
loss: 0.003474  [  160/ 1575]
loss: 0.002573  [  320/ 1575]
loss: 0.002682  [  480/ 1575]
loss: 0.003066  [  640/ 1575]
loss: 0.002325  [  800/ 1575]
loss: 0.002687  [  960/ 1575]
loss: 0.002001  [ 1120/ 1575]
loss: 0.000974  [ 1280/ 1575]
loss: 0.002298  [ 1440/ 1575]
Test Error: 
MSE: 31.769212
RMSE: 5.636418
MAE: 2.136090
R^2: 0.9006787743877864
loss: 0.002636  [    0/ 1575]
loss: 0.002943  [  160/ 1575]
loss: 0.003054  [  320/ 1575]
loss: 0.002655  [  480/ 1575]
loss: 0.002133  [  640/ 1575]
loss: 0.002228  [  800/ 1575]
loss: 0.002706  [  960/ 1575]
loss: 0.002300  [ 1120/ 1575]
loss: 0.001496  [ 1280/ 1575]
loss: 0.002163  [ 1440/ 1575]
Test Error: 
MSE: 36.973814
RMSE: 6.080610
MAE: 2.226160
R^2: 0.8844074411670647
loss: 0.003403  [    0/ 1575]
loss: 0.004383  [  160/ 1575]
loss: 0.002274  [  320/ 1575]
loss: 0.003297  [  480/ 1575]
loss: 0.003131  [  640/ 1575]
loss: 0.003362  [  800/ 1575]
loss: 0.001966  [  960/ 1575]
loss: 0.001492  [ 1120/ 1575]
loss: 0.001696  [ 1280/ 1575]
loss: 0.001942  [ 1440/ 1575]
Test Error: 
MSE: 27.611832
RMSE: 5.254696
MAE: 2.034144
R^2: 0.9136761424369264
loss: 0.002626  [    0/ 1575]
loss: 0.002404  [  160/ 1575]
loss: 0.003274  [  320/ 1575]
loss: 0.002524  [  480/ 1575]
loss: 0.002594  [  640/ 1575]
loss: 0.002533  [  800/ 1575]
loss: 0.001899  [  960/ 1575]
loss: 0.002751  [ 1120/ 1575]
loss: 0.003229  [ 1280/ 1575]
loss: 0.001835  [ 1440/ 1575]
Test Error: 
MSE: 27.526185
RMSE: 5.246540
MAE: 2.033084
R^2: 0.91394390436232
loss: 0.002479  [    0/ 1575]
loss: 0.002707  [  160/ 1575]
loss: 0.001807  [  320/ 1575]
loss: 0.001414  [  480/ 1575]
loss: 0.002318  [  640/ 1575]
loss: 0.001997  [  800/ 1575]
loss: 0.002673  [  960/ 1575]
loss: 0.004418  [ 1120/ 1575]
loss: 0.002368  [ 1280/ 1575]
loss: 0.002592  [ 1440/ 1575]
Test Error: 
MSE: 27.630038
RMSE: 5.256428
MAE: 2.034281
R^2: 0.9136192250603292
loss: 0.003346  [    0/ 1575]
loss: 0.002607  [  160/ 1575]
loss: 0.002859  [  320/ 1575]
loss: 0.001629  [  480/ 1575]
loss: 0.001794  [  640/ 1575]
loss: 0.002677  [  800/ 1575]
loss: 0.002842  [  960/ 1575]
loss: 0.002071  [ 1120/ 1575]
loss: 0.001780  [ 1280/ 1575]
loss: 0.002666  [ 1440/ 1575]
Test Error: 
MSE: 30.977065
RMSE: 5.565704
MAE: 2.120865
R^2: 0.9031552938158632
loss: 0.003818  [    0/ 1575]
loss: 0.002383  [  160/ 1575]
loss: 0.002734  [  320/ 1575]
loss: 0.002671  [  480/ 1575]
loss: 0.002846  [  640/ 1575]
loss: 0.003364  [  800/ 1575]
loss: 0.001642  [  960/ 1575]
loss: 0.002522  [ 1120/ 1575]
loss: 0.003170  [ 1280/ 1575]
loss: 0.001743  [ 1440/ 1575]
Test Error: 
MSE: 27.479545
RMSE: 5.242094
MAE: 2.039655
R^2: 0.9140897145618789
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.003134  [    0/ 1575]
loss: 0.001982  [  160/ 1575]
loss: 0.002685  [  320/ 1575]
loss: 0.002181  [  480/ 1575]
loss: 0.002565  [  640/ 1575]
loss: 0.002072  [  800/ 1575]
loss: 0.003027  [  960/ 1575]
loss: 0.003324  [ 1120/ 1575]
loss: 0.001852  [ 1280/ 1575]
loss: 0.003632  [ 1440/ 1575]
Test Error: 
MSE: 27.788243
RMSE: 5.271455
MAE: 2.049306
R^2: 0.913124621765758
loss: 0.001830  [    0/ 1575]
loss: 0.001856  [  160/ 1575]
loss: 0.003427  [  320/ 1575]
loss: 0.002418  [  480/ 1575]
loss: 0.003488  [  640/ 1575]
loss: 0.003037  [  800/ 1575]
loss: 0.003319  [  960/ 1575]
loss: 0.004490  [ 1120/ 1575]
loss: 0.002180  [ 1280/ 1575]
loss: 0.002459  [ 1440/ 1575]
Test Error: 
MSE: 27.787507
RMSE: 5.271386
MAE: 2.048944
R^2: 0.9131269238986808
loss: 0.002126  [    0/ 1575]
loss: 0.002525  [  160/ 1575]
loss: 0.001740  [  320/ 1575]
loss: 0.004132  [  480/ 1575]
loss: 0.003610  [  640/ 1575]
loss: 0.002686  [  800/ 1575]
loss: 0.001564  [  960/ 1575]
loss: 0.002440  [ 1120/ 1575]
loss: 0.003265  [ 1280/ 1575]
loss: 0.003086  [ 1440/ 1575]
Test Error: 
MSE: 28.230346
RMSE: 5.313224
MAE: 2.045269
R^2: 0.9117424597084084
loss: 0.002925  [    0/ 1575]
loss: 0.001516  [  160/ 1575]
loss: 0.002882  [  320/ 1575]
loss: 0.002517  [  480/ 1575]
loss: 0.003094  [  640/ 1575]
loss: 0.003343  [  800/ 1575]
loss: 0.002602  [  960/ 1575]
loss: 0.002182  [ 1120/ 1575]
loss: 0.003072  [ 1280/ 1575]
loss: 0.002544  [ 1440/ 1575]
Test Error: 
MSE: 28.987514
RMSE: 5.384005
MAE: 2.079558
R^2: 0.9093752972764126
loss: 0.002370  [    0/ 1575]
loss: 0.003510  [  160/ 1575]
loss: 0.001897  [  320/ 1575]
loss: 0.001548  [  480/ 1575]
loss: 0.002650  [  640/ 1575]
loss: 0.002935  [  800/ 1575]
loss: 0.001730  [  960/ 1575]
loss: 0.002352  [ 1120/ 1575]
loss: 0.003792  [ 1280/ 1575]
loss: 0.002020  [ 1440/ 1575]
Test Error: 
MSE: 31.884430
RMSE: 5.646630
MAE: 2.138427
R^2: 0.900318566912536
loss: 0.002423  [    0/ 1575]
loss: 0.002327  [  160/ 1575]
loss: 0.001661  [  320/ 1575]
loss: 0.002188  [  480/ 1575]
loss: 0.001999  [  640/ 1575]
loss: 0.002496  [  800/ 1575]
loss: 0.003424  [  960/ 1575]
loss: 0.001610  [ 1120/ 1575]
loss: 0.001904  [ 1280/ 1575]
loss: 0.001789  [ 1440/ 1575]
Test Error: 
MSE: 27.518064
RMSE: 5.245766
MAE: 2.032144
R^2: 0.9139692923226972
loss: 0.003135  [    0/ 1575]
loss: 0.001741  [  160/ 1575]
loss: 0.001928  [  320/ 1575]
loss: 0.002848  [  480/ 1575]
loss: 0.002484  [  640/ 1575]
loss: 0.002820  [  800/ 1575]
loss: 0.003168  [  960/ 1575]
loss: 0.002141  [ 1120/ 1575]
loss: 0.001768  [ 1280/ 1575]
loss: 0.001388  [ 1440/ 1575]
Test Error: 
MSE: 28.809627
RMSE: 5.367460
MAE: 2.056400
R^2: 0.9099314333769469
loss: 0.002729  [    0/ 1575]
loss: 0.001685  [  160/ 1575]
loss: 0.002648  [  320/ 1575]
loss: 0.002019  [  480/ 1575]
loss: 0.001696  [  640/ 1575]
loss: 0.003347  [  800/ 1575]
loss: 0.001593  [  960/ 1575]
loss: 0.002275  [ 1120/ 1575]
loss: 0.002550  [ 1280/ 1575]
loss: 0.002103  [ 1440/ 1575]
Test Error: 
MSE: 27.297417
RMSE: 5.224693
MAE: 2.035432
R^2: 0.9146591083720687
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002164  [    0/ 1575]
loss: 0.002343  [  160/ 1575]
loss: 0.002027  [  320/ 1575]
loss: 0.001759  [  480/ 1575]
loss: 0.003024  [  640/ 1575]
loss: 0.002263  [  800/ 1575]
loss: 0.002334  [  960/ 1575]
loss: 0.002148  [ 1120/ 1575]
loss: 0.003245  [ 1280/ 1575]
loss: 0.001782  [ 1440/ 1575]
Test Error: 
MSE: 27.142808
RMSE: 5.209876
MAE: 2.028964
R^2: 0.9151424692029588
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002413  [    0/ 1575]
loss: 0.002850  [  160/ 1575]
loss: 0.002251  [  320/ 1575]
loss: 0.002679  [  480/ 1575]
loss: 0.002891  [  640/ 1575]
loss: 0.004175  [  800/ 1575]
loss: 0.002139  [  960/ 1575]
loss: 0.004755  [ 1120/ 1575]
loss: 0.003780  [ 1280/ 1575]
loss: 0.003014  [ 1440/ 1575]
Test Error: 
MSE: 30.728547
RMSE: 5.543334
MAE: 2.117110
R^2: 0.9039322433884335
loss: 0.003080  [    0/ 1575]
loss: 0.004182  [  160/ 1575]
loss: 0.003138  [  320/ 1575]
loss: 0.001908  [  480/ 1575]
loss: 0.003037  [  640/ 1575]
loss: 0.001848  [  800/ 1575]
loss: 0.002419  [  960/ 1575]
loss: 0.002357  [ 1120/ 1575]
loss: 0.001834  [ 1280/ 1575]
loss: 0.001569  [ 1440/ 1575]
Test Error: 
MSE: 35.995735
RMSE: 5.999645
MAE: 2.211557
R^2: 0.8874652467908741
loss: 0.002794  [    0/ 1575]
loss: 0.002179  [  160/ 1575]
loss: 0.003993  [  320/ 1575]
loss: 0.003218  [  480/ 1575]
loss: 0.002066  [  640/ 1575]
loss: 0.001985  [  800/ 1575]
loss: 0.002071  [  960/ 1575]
loss: 0.003299  [ 1120/ 1575]
loss: 0.001808  [ 1280/ 1575]
loss: 0.002406  [ 1440/ 1575]
Test Error: 
MSE: 27.127969
RMSE: 5.208452
MAE: 2.028897
R^2: 0.9151888597128444
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002455  [    0/ 1575]
loss: 0.002370  [  160/ 1575]
loss: 0.001653  [  320/ 1575]
loss: 0.003302  [  480/ 1575]
loss: 0.003144  [  640/ 1575]
loss: 0.002087  [  800/ 1575]
loss: 0.002013  [  960/ 1575]
loss: 0.002985  [ 1120/ 1575]
loss: 0.002817  [ 1280/ 1575]
loss: 0.002797  [ 1440/ 1575]
Test Error: 
MSE: 27.419485
RMSE: 5.236362
MAE: 2.029300
R^2: 0.9142774816147697
loss: 0.001792  [    0/ 1575]
loss: 0.002481  [  160/ 1575]
loss: 0.002150  [  320/ 1575]
loss: 0.002330  [  480/ 1575]
loss: 0.001927  [  640/ 1575]
loss: 0.002408  [  800/ 1575]
loss: 0.003489  [  960/ 1575]
loss: 0.002369  [ 1120/ 1575]
loss: 0.002432  [ 1280/ 1575]
loss: 0.003583  [ 1440/ 1575]
Test Error: 
MSE: 30.626988
RMSE: 5.534165
MAE: 2.115286
R^2: 0.9042497525876447
loss: 0.002375  [    0/ 1575]
loss: 0.002052  [  160/ 1575]
loss: 0.004093  [  320/ 1575]
loss: 0.002678  [  480/ 1575]
loss: 0.002500  [  640/ 1575]
loss: 0.002431  [  800/ 1575]
loss: 0.002515  [  960/ 1575]
loss: 0.002100  [ 1120/ 1575]
loss: 0.001716  [ 1280/ 1575]
loss: 0.002079  [ 1440/ 1575]
Test Error: 
MSE: 27.152660
RMSE: 5.210821
MAE: 2.031331
R^2: 0.9151116671036145
loss: 0.003078  [    0/ 1575]
loss: 0.001596  [  160/ 1575]
loss: 0.002257  [  320/ 1575]
loss: 0.002638  [  480/ 1575]
loss: 0.002916  [  640/ 1575]
loss: 0.002416  [  800/ 1575]
loss: 0.002984  [  960/ 1575]
loss: 0.003466  [ 1120/ 1575]
loss: 0.001855  [ 1280/ 1575]
loss: 0.002282  [ 1440/ 1575]
Test Error: 
MSE: 28.706214
RMSE: 5.357818
MAE: 2.074520
R^2: 0.9102547357238561
loss: 0.002245  [    0/ 1575]
loss: 0.003069  [  160/ 1575]
loss: 0.002450  [  320/ 1575]
loss: 0.001387  [  480/ 1575]
loss: 0.001688  [  640/ 1575]
loss: 0.001466  [  800/ 1575]
loss: 0.001436  [  960/ 1575]
loss: 0.001741  [ 1120/ 1575]
loss: 0.003387  [ 1280/ 1575]
loss: 0.002310  [ 1440/ 1575]
Test Error: 
MSE: 29.445645
RMSE: 5.426384
MAE: 2.090972
R^2: 0.9079430265092627
loss: 0.001984  [    0/ 1575]
loss: 0.002745  [  160/ 1575]
loss: 0.002349  [  320/ 1575]
loss: 0.002312  [  480/ 1575]
loss: 0.002382  [  640/ 1575]
loss: 0.002803  [  800/ 1575]
loss: 0.002561  [  960/ 1575]
loss: 0.001585  [ 1120/ 1575]
loss: 0.003012  [ 1280/ 1575]
loss: 0.001300  [ 1440/ 1575]
Test Error: 
MSE: 27.184328
RMSE: 5.213859
MAE: 2.033328
R^2: 0.9150126619293611
loss: 0.003105  [    0/ 1575]
loss: 0.001786  [  160/ 1575]
loss: 0.001856  [  320/ 1575]
loss: 0.002367  [  480/ 1575]
loss: 0.001989  [  640/ 1575]
loss: 0.002262  [  800/ 1575]
loss: 0.002009  [  960/ 1575]
loss: 0.002714  [ 1120/ 1575]
loss: 0.002702  [ 1280/ 1575]
loss: 0.002617  [ 1440/ 1575]
Test Error: 
MSE: 32.258863
RMSE: 5.679689
MAE: 2.145028
R^2: 0.8991479617873726
loss: 0.002465  [    0/ 1575]
loss: 0.003561  [  160/ 1575]
loss: 0.002231  [  320/ 1575]
loss: 0.002170  [  480/ 1575]
loss: 0.002446  [  640/ 1575]
loss: 0.001476  [  800/ 1575]
loss: 0.002779  [  960/ 1575]
loss: 0.002074  [ 1120/ 1575]
loss: 0.004148  [ 1280/ 1575]
loss: 0.002346  [ 1440/ 1575]
Test Error: 
MSE: 27.009338
RMSE: 5.197051
MAE: 2.023582
R^2: 0.915559740554322
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_BEST.pt
loss: 0.002505  [    0/ 1575]
loss: 0.002268  [  160/ 1575]
loss: 0.002456  [  320/ 1575]
loss: 0.001247  [  480/ 1575]
loss: 0.001241  [  640/ 1575]
loss: 0.002717  [  800/ 1575]
loss: 0.001921  [  960/ 1575]
loss: 0.001432  [ 1120/ 1575]
loss: 0.002495  [ 1280/ 1575]
loss: 0.003002  [ 1440/ 1575]
Test Error: 
MSE: 28.308359
RMSE: 5.320560
MAE: 2.064310
R^2: 0.9114985634795378
loss: 0.002348  [    0/ 1575]
loss: 0.001712  [  160/ 1575]
loss: 0.002901  [  320/ 1575]
loss: 0.002166  [  480/ 1575]
loss: 0.001815  [  640/ 1575]
loss: 0.002086  [  800/ 1575]
loss: 0.001536  [  960/ 1575]
loss: 0.002121  [ 1120/ 1575]
loss: 0.001621  [ 1280/ 1575]
loss: 0.002067  [ 1440/ 1575]
Test Error: 
MSE: 33.290931
RMSE: 5.769829
MAE: 2.163815
R^2: 0.8959213725324734
loss: 0.003713  [    0/ 1575]
loss: 0.001733  [  160/ 1575]
loss: 0.001952  [  320/ 1575]
loss: 0.002554  [  480/ 1575]
loss: 0.001565  [  640/ 1575]
loss: 0.002260  [  800/ 1575]
loss: 0.002270  [  960/ 1575]
loss: 0.001993  [ 1120/ 1575]
loss: 0.003404  [ 1280/ 1575]
loss: 0.002650  [ 1440/ 1575]
Test Error: 
MSE: 29.930510
RMSE: 5.470878
MAE: 2.101006
R^2: 0.9064271756243558
loss: 0.002876  [    0/ 1575]
loss: 0.003097  [  160/ 1575]
loss: 0.002458  [  320/ 1575]
loss: 0.003123  [  480/ 1575]
loss: 0.003242  [  640/ 1575]
loss: 0.003099  [  800/ 1575]
loss: 0.002992  [  960/ 1575]
loss: 0.002318  [ 1120/ 1575]
loss: 0.001843  [ 1280/ 1575]
loss: 0.002970  [ 1440/ 1575]
Test Error: 
MSE: 40.467393
RMSE: 6.361399
MAE: 2.288851
R^2: 0.8734853419184876
loss: 0.003386  [    0/ 1575]
loss: 0.002756  [  160/ 1575]
loss: 0.003377  [  320/ 1575]
loss: 0.003124  [  480/ 1575]
loss: 0.002548  [  640/ 1575]
loss: 0.002313  [  800/ 1575]
loss: 0.002538  [  960/ 1575]
loss: 0.002418  [ 1120/ 1575]
loss: 0.002317  [ 1280/ 1575]
loss: 0.002060  [ 1440/ 1575]
Test Error: 
MSE: 28.521031
RMSE: 5.340508
MAE: 2.050344
R^2: 0.9108336805283745
loss: 0.002337  [    0/ 1575]
loss: 0.002841  [  160/ 1575]
loss: 0.002979  [  320/ 1575]
loss: 0.002507  [  480/ 1575]
loss: 0.002695  [  640/ 1575]
loss: 0.001722  [  800/ 1575]
loss: 0.002060  [  960/ 1575]
loss: 0.002023  [ 1120/ 1575]
loss: 0.001578  [ 1280/ 1575]
loss: 0.002530  [ 1440/ 1575]
Test Error: 
MSE: 29.061435
RMSE: 5.390866
MAE: 2.082665
R^2: 0.9091441969467725
Done!
Best layer weights found were: [0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04
 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04 0.04]
Layer Weights: tensor([0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,
        0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,
        0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400],
       device='cuda:0', grad_fn=<SoftmaxBackward0>)
Layer Weights (Unnormalized): tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0.], device='cuda:0', grad_fn=<ToCopyBackward0>)
Saved PyTorch Model State to dimension_models/model_objects/morgan_emotional_speech_set_valence_whisper_medium_encoder_1666739965_FINAL.pt
